[
    "Definition 0.1 (Galton–Watson branching process). Let (Xn,r)n,r⩾1 be an infinite array of independent identically\ndistributed random variables, each with the same distribution as X, where\n\nP[X = k] = pk,\n\nk = 0, 1, 2, . . .\n\nThe sequence (Zn)n⩾0 of random variables defined by\n\n1. Z0 = 1,\n\n2. Zn = Xn,1 + · · · + Xn,Zn−1 for n ⩾ 1\n\nis the Galton–Watson branching process (started from a single ancestor) with offspring distribution X.\n\nIn the original setting, the random variable Zn models the number of male descendants of a single male\nancestor after n generations. However this model is applicable to a much wider set of scenarios. You could, for\nexample, see it as a very rudimentary model for spreading a virus, such as Covid-19. Here, each ‘generation’\nlasts maybe 2 weeks and Zn is the current number of infected individuals. Each of them, independently of the\nothers and in the same manner, then infects further individuals.\n\nIn analyzing this process, key roles are played by the expectation m = E[X] = ∑∞\n\nsume to be finite, and by the probability generating function f = fX of X, defined by f (θ ) = E[θ X ] = ∑∞\n\nk=0 kpk, which we shall as-\nk=0 pkθ k.\nClaim 0.2. Let fn(θ ) = E[θ Zn]. Then fn is the n-fold composition of f with itself (where by convention a 0-fold\ncomposition is the identity).\n\n‘Proof’\n\nWe proceed by induction. First note that f0(θ ) = θ , so f0 is the identity. Assume that n ⩾ 1 and fn−1 =\n\nf ◦ · · · ◦ f is the (n − 1)-fold composition of f with itself. To compute fn, first note that\n\nE (cid:2) θ Zn(cid:12)\n\n(cid:12) Zn−1 = k(cid:3) = E (cid:2)θ Xn,1+···+Xn,k (cid:3)\n\n= E (cid:2)θ Xn,1(cid:3) · · · E (cid:2)θ Xn,k (cid:3)\n= f (θ )k,\n\n(independence)\n\nPage 6\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n(since each Xn,i has the same distribution as X). Hence\n\nE (cid:2) θ Zn(cid:12)\n\n(cid:12) Zn−1\n\n(cid:3) = f (θ )Zn−1.\n\n(1)\n\nThis is our first example of a conditional expectation, studied in section 6. Notice that the right hand side of (1)\nis a random variable. Now\n\nfn(θ ) = E (cid:2)θ Zn(cid:3) = E (cid:2)E (cid:2) θ Zn(cid:12)\n\n(cid:12) Zn−1\n\n= E (cid:2) f (θ )Zn−1(cid:3)\n= fn−1 ( f (θ )) ,\n\n(cid:3)(cid:3)\n\n(2)\n\nand the claim follows by induction.\n\n(cid:50)\nIn (2) we have used what is called the tower property of conditional expectations. In this example you can\nmake all this work with the Partition Theorem of Prelims (because the events {Zn = k} form a countable partition\nof the sample space). In the general theory that follows, we’ll see how to replace the Partition Theorem when\nthe sample space is more complicated, for example when considering continuous random variables.\n\nWatson wanted to establish the extinction probability of the branching process, i.e., the probability that\n\nZn = 0 for some n.\n\nClaim 0.3. Let q = P[Zn = 0 for some n]. Then q is the smallest root in [0, 1] of the equation θ = f (θ ). In\nparticular, assuming p1 = P[X = 1] < 1,\n\n• if m = E[X] ⩽ 1, then q = 1,\n\n• if m = E[X] > 1, then q < 1.\n\n‘Proof’\n\nLet qn = P[Zn = 0] = fn(0). Since {Zn = 0} ⊆ {Zn+1 = 0} we see that qn is an increasing function of n and,\n\nintuitively,\n\nq = lim\nn→∞\n\nqn = lim\nn→∞\n\nfn(0).\n\n(3)\n\nSince fn+1(0) = f ( fn(0)) and f is continuous, (3) implies that q satisfies q = f (q).\n\nNow observe that f is convex (i.e., f ′′ ⩾ 0) and f (1) = 1, so only two things can happen, depending upon\n\nthe value of m = f ′(1):\n\nf (θ )\n\n1\n\nf (θ )\n\n1\n\n0\n\n0\n\nµ ⩽ 1\n\nθ\n\n1\n\n0\n\n0\n\nθ0\n\nµ > 1\n\nθ\n\n1\n\nIn the case m > 1, to see that q must be the smaller root θ0, note that f is increasing, and 0 = q0 ⩽ θ0. It follows\n(cid:50)\nby induction that qn ⩽ θ0 for all n, so q ⩽ θ0.\n\nIt’s not hard to guess the result above for m > 1 and m < 1, but the case m = 1 is far from obvious.\n\nPage 7\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nThe extinction probability is only one statistic that we might care about. For example, we might ask whether\n\nwe can say anything about the way in which the population grows or declines. Consider\n\nE [Zn+1 | Zn = k] = E [Xn+1,1 + · · · + Xn+1,k] = km (linearity of expectation).\n\n(4)\n\nIn other words E[Zn+1 | Zn] = mZn (another conditional expectation). Now write\n\nThen\n\nIn fact, more is true:\n\nMn =\n\nZn\nmn .\n\nE [Mn+1 | Mn] = Mn.\n\nE [Mn+1 | M0, M1, . . . , Mn] = Mn.\n\nA process (Mn)n⩾0 with this property is called a martingale. We introduce and study martingales in section 8.\n\nIt is natural to ask whether Mn has a limit as n → ∞ and, if so, can we say anything about that limit? We’re\ngoing to develop the tools to answer these questions, but for now, notice that for m ⩽ 1 we have ‘proved’ that\nM∞ = limn→∞ Mn = 0 with probability one, so\n\n0 = E[M∞] ̸= lim\nn→∞\n\nE[Mn] = 1.\n\n(5)\n\nWe’re going to have to be careful in passing to limits, just as we discovered in Part A Integration. Indeed (5)\nmay remind you of Fatou’s Lemma from Part A.\n\nOne of the main aims of this course is to provide the tools needed to make arguments such as that presented\nabove precise. Other key aims are to make sense of, and study, martingales in more general contexts. This\ninvolves defining conditional expectation when conditioning on a continuous random variable.\n\nBefore we go into theory, let us study the limiting behaviour of processes on one more, more familiar,\n\nexample.\n\nPage 8\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n0.4 Simple Symmetric Random Walk\n\nConsider a sequence of independent random variables (Xn)n⩾1, all with the same distribution\n\nNote that E[Xn] = 0 and Var(Xn) = E[X 2\n\nn ] = 1. Let S0 = 0,\n\nP(Xn = −1) = P(Xn = 1) = 1\n2.\n\nSn =\n\nn\n∑\nk=1\n\nXk,\n\nn ⩾ 1,\n\ndenote their cumulative sums. This process is known as the simple symmetric random walk. Again, it should be\nintuitively clear that our best prediction of the state at time n, given the history, is Sn−1 itself as the increment\nhas mean 0:\n\nE[Sn|Sn−1] = E[Sn|Sn−1, . . . , S0] = Sn−1 + E[Xn] = Sn−1.\n\nFrom the weak law of large numbers we know that\n\nSn\nn\n\n−→ 0\n\nin probability. In Theorem 9.3, we will show that this convergence actually takes place almost surely. This is a\nnon-trivial extension: it took mathematicians over 300 years to prove it!\n\nYou also have seen that the speed of this convergence can be described using the Gaussian distribution,\n\nnamely\n\nSn√\nn\n\nd−→ N (0, 1).\n\nPut differently, if I run 100 simulations of my SSRW then, for a large n, and I plot Sn/\npaths or so to breach the interval (−2.326, 2.326).\n\n√\n\nn then I expect only 2\n\nSo, can we say something more about those two paths? Those rare paths, how do they behave? This is\n\ngoverned by the law of the iterated logarithm. It turns out, see section 9.4, that\n\nlim sup\nn→∞\n\nSn√\n\nn log log n\n\n=\n\n√\n\n2 and\n\nlim inf\nn→∞\n\nSn√\n\nn log log n\n\n√\n\n= −\n\n2,\n\na.s.\n\n0.5 Mathematical Finance\n\nSuppose (Sn)n⩾0 is sequence of random variables modelling the price process of some risky asset, i.e., Sn is the\nshare price at time n. A trader is buying and selling the stock. At time n, they have wealth Vn and decide to\nbuy/sell Hn = Hn(S0, S1, . . . , Sn) shares. At time n + 1, they will have HnSn+1 in shares while their remaining\ncapital/debt grew at rate r:\n\nVn+1 = HnSn+1 + (Vn − HnSn)(1 + r) = Hn(Sn+1 − (1 + r)Sn) +Vn(1 + r).\n\nIf we introduce discounted quantities\n\n˜Vn := (1 + r)−nVn,\n\nand\n\n˜Sn := (1 + r)−nSn\n\nthen the above is re-written as\n\n˜Vn+1 = Hn( ˜Sn+1 − ˜Sn) + ˜Vn = . . . = V0 +\n\nn\n∑\nt=1\n\nHt( ˜St+1 − ˜St),\n\nPage 9\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nSSRW paths\n\nSn\nn\n\nSn√\nn on the (−2.326, 2.326) interval\n\nSn√\nn log log n on the interval (−\n\n√\n\n2,\n\nFigure 1: Limiting behaviour of a SSRW\n\n√\n\n2)\n\nPage 10\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nan object we will study under the name of discrete stochastic integral or a martingale transform, see Theorem\n8.12.\n\nSuppose at time t = 0 someone wants to purchase from the trader a financial product which, at time t = N,\nwill have payoff f (S0, S1, . . . , SN). What price should the trader set for this product? If they can find a trading\nstrategy H such that f = VN above, then clearly V0 is the fair price as it allows the trader to reproduce (hedge)\nthe associated risk fully. But when is this possible and how to find V0? One example is given by the binomial\nmodel.",
    "Proposition 0.4 (Binomial Model pricing). Suppose there exist two constants u, d such that 0 < 1 − d < 1 <\n1 + r < 1 + u and Sn+1 ∈ {(1 + u)Sn, (1 − d)Sn} a.s., for all n ⩾ 0. Then for any f , there exists V0, H such that\nf = VN a.s. In addition, there exists a unique probability measure Q such that ( ˜Sn)n⩾0 is a Q-martingale and\nV0 = (1 + r)−NEQ[ f (S0, . . . , SN)].\n\nPage 11\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n1 Measurable sets and functions, a.k.a. events and random variables\n\nWhereof one cannot speak, thereof one must be silent.\nThe limits of my language mean the limits of my world.\n\nLudwig Wittgenstein\n\nOur fundamental interest in this course is in endowing a space of outcomes with a measure which describes\nthe relative likelihood of these outcomes and in understanding how this translates into (random) behaviour of\nfunctions depending on these outcomes. To achieve this abstract goal we have to invest some time and effort in\ndeveloping suitable language to speak of sets and functions. This section will appear somewhat arid at the first\nreading. It may please some readers, those are invited to study it, and its appendix, in detail. Others might be\nbored by it, those are invited to skim through and then come back when a given notion is needed. You can then\nstudy the particular notion knowing that it is actually useful and has its deeper purpose. Nevertheless, an initial\nreading will equip you with a basic vocabulary without which it is difficult to proceed.\n\n1.1 Events and σ -algebras\n\nFor a set Ω, we let P(Ω) be the power set of Ω, i.e., the set of all subsets of Ω.",
    "Definition 1.1 (Algebras and σ -algebras). Let Ω be a set and let A ⊆ P(Ω) be a collection of subsets of Ω.\n\n1. We say that A is an algebra if /0 ∈ A and for all A, B ∈ A , Ac = Ω \\ A ∈ A and A ∪ B ∈ A .\n\n2. We say that A is a σ -algebra (or a σ -field) if /0 ∈ A , A ∈ A implies Ac ∈ A , and for all sequences\n\n(An)n⩾1 of elements of A , (cid:83)∞\n\nn=1 An ∈ A .\n\nSince intersections can be built up from complements and unions, an algebra is a collections of sets which\nis closed under finite set operations. A σ -algebra is a collection of sets which is closed under countable set\noperations. Note that the notions of algebra and σ -algebra are relative to Ω since Ac makes sense only if we\nspecify the “parent” set Ω we have in mind. A σ -algebra will be most often denoted by F .\n\nThe couple (Ω, F ), a set with a σ -algebra of its subsets, is called a measurable space. We may refer to Ω\nas the space, or set, of elementary outcomes. The subsets of Ω in F are called events. We may say that an event\nA occurs to simply indicate A and that two events A and B occur simultaneously to indicate A ∩ B = {ω ∈ Ω :\nω ∈ A and ω ∈ B}. The collection F is made up of those sets which are regular enough that we will be able to\nmeasure their likelihood, i.e., assign them a probability of happening. While it is helpful to think of Ω as the set\nof elementary outcomes of some experiments, you should be cautious as many arguments may not be carried\nout “ω by ω”.",
    "Example 1.2. Here are some examples of σ -algebras:\n\n(i) { /0, Ω} is a σ -algebra. It is often referred to as the trivial σ -algebra and it is the smallest possible σ -algebra\n\nsince, by definition, { /0, Ω} ⊆ F for any σ -algebra F .\n\n(ii) The power set P(Ω) is a σ -algebra but is usually too large to work with.\n\n(iii) Let E ⊂ Ω be any set and F be a σ -algebra. Then {E ∩ A : A ∈ F } is a σ -algebra. It is sometimes called\n\nthe trace σ -algebra.\n\n(iv) The collection of all sets A ∈ P(Ω) such that either A or Ac is countable is a σ -algebra.\n\n(v) For a nontrivial set A ⊆ Ω, i.e., A is neither empty nor the full space, σ (A) := { /0, Ω, A, Ac} is a σ -algebra.\n\nIt just allows us to say if the event A happened or not but nothing else.\n\nPage 12\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nThe last example above hints at the crucial property, or interpretation, of σ -algebras: they are conveyors\nof information. They capture the richness, or poorness, of our ability to distinguish between events, to classify\nelementary outcomes into events. The richer the σ -algebra the better our ability to classify the elements of Ω.\nTo generalise the above example, we need the following property.",
    "Lemma 1.3. Let I be an index set and {Fi : i ∈ I} a collection of σ -algebras. Then\n\nF := (cid:92)\ni∈I\n\nFi = {A ⊆ Ω : A ∈ Fi for all i ∈ I}\n\nis a σ -algebra.\n\nProof. Exercise.",
    "Definition 1.4. Let A be a collection of subsets of Ω. The smallest σ -algebra containing all the sets in A is\ndenoted σ (A ) and is called the σ -algebra generated by A .\n\nNote that Lemma 1.3 ensures that σ (A ) is well defined and is simply given by the intersection of all the\nσ -algebras F such that A ⊆ F , a non-empty collection since A ⊆ P(Ω). This result allows us instantly to\ngenerate many more interesting σ -algebras. We give now two important examples.",
    "Definition 1.5 (Borel σ -algebra). Let E be a topological space with topology (i.e., collection of open sets) T .\nThe σ -algebra generated by the open sets in E is called the Borel σ -algebra on E and is denoted B(E) = σ (T ).",
    "Example 1.6 (Borel σ -algebra on R). The following collections of sets\n\n• open sets in R,\n\n• open intervals in R,\n\n• {(−∞, a] : a ∈ R},\n\n• {(−∞, a) : a ∈ R}\n\nall generate the same σ -algebra, namely B(R).",
    "Definition 1.7 (Product space). Let I be an index set and (Ωi, Fi)i∈I a collection of measurable spaces. Let\nΩ = ∏i∈I Ωi and F be the σ -algebra generated by cylinder sets A = ∏i∈I Ai, where Ai ∈ Fi for all i ∈ I and\nAi = Ωi except for finitely many i ∈ I. The measurable space (Ω, F ) is called the product space. The σ -algebra\nF is called the product σ -algebra and is sometimes denoted ×i∈IFi.\n\nWhen I = {1, 2}, we simply write Ω = Ω1 × Ω2 and F = F1 × F2. Note that ‘×‘ has a different meaning\nfor these ‘products‘: Ω is the Cartesian product of Ω1 and Ω2 but F is not the Cartesian product of F1 and F2.\nIt is often the case that the same σ (A ) may be generated by many different classes of sets A . For example,\nthe product σ -algebra is already generated by sets where Ai ̸= Ωi for only one coordinate i ∈ I. This is obvious\nsince σ -algebras are closed under finite intersections so we may get the more general cylinder sets from these\nsimple ones. Example 1.6 was also an instance of this phenomena. This example in fact extends to higher\ndimensions, i.e., to products of R. Indeed, each open subset of Rn is a countable union of open hypercubes\n(products of open intervals) and hence B(Rd) is generated by d-fold products of open intervals. It follows that\nB(R) = B(Rd) and properties of product spaces will allow us to just focus on real-valued objects. While\n×d\nthis will carry over to countable product spaces, it may fail for more general index sets.\n\ni=1\n\nHere is a familiar example of a product space, already encountered in Part A Probability.\n\nPage 13\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales",
    "Example 1.8 (Repeated coin tossing). Consider the experiment consisting in repeated coin tossing. Each toss is\nnaturally represented by (Ωtoss, Ftoss) with Ωtoss = {H, T } and\n\nFtoss = σ ({H}) = σ ({T }) = { /0, Ωtoss, {H}, {T }} = P(Ωtoss).\n\nn=1 Ωn, ×∞\n\nFn) where each (Ωn, Fn) =\nRepeated coin tossing is then captured by the product space (Ω, F ) = (∏∞\n(Ωtoss, Ftoss). Put differently, Ω = {H, T }N and ω = (ω1, ω2, . . .) ∈ Ω encodes the outcomes of successive\ntosses. The product σ -algebra F on Ω is generated by events which only depend on the outcomes of finitely\nmany tosses. As observed above, it is in fact generated by the events An = {ω ∈ Ω : ωn = H}, i.e., by events\nwhich allows us to encode the result of the nth toss, n ∈ N. It is clear that for our measurable space to describe\nour experiment we have to have these in F . It turns out we can not have much more: F is strictly smaller than\nP(Ω) and it may be impossible to understand and codify the likelihood of evens from outside of F . However,\nF proves already to be (perhaps surprisingly) rich. In particular the event A that the asymptotic frequency of\nheads is equal to 1\n\nn=1\n\n2, or more formally\n\n(cid:26)\n\nA =\n\nω ∈ Ω :\n\n|{k ⩽ n : ωk = H}|\nn\n\n(cid:27)\n\n→ 1\n2\n\nis an element in F , see the problem sheet.\n\nTime and again, we will need to establish that a certain property holds for all sets in a given σ -algebra. This\n\nmight often be tedious and/or difficult to do directly. The following notions and results offer an alternative.",
    "Definition 1.9 (π- and λ - systems).\n\n• A collection of sets A is called a π-system if it is stable under intersections, i.e., A, B ∈ A implies\n\nA ∩ B ∈ A .\n\n• A collection of sets M is called a λ -system if\n\n– Ω ∈ M ,\n– if A, B ∈ M with A ⊆ B then B \\ A ∈ M ,\n– if {An}n⩾1 ⊆ M with An ⊆ An+1 for all n ⩾ 1 then (cid:83)\n\nn⩾1 An ∈ M .",
    "Example 1.10. The collection\n\nforms a π-system and σ (π(R)) = B(R) by Example 1.6 above.\n\nπ(R) = {(−∞, x] : x ∈ R}\n\nIn some sense, the notions of π- and λ - systems split the properties of a σ -algebra into two, as the following\n\nlemma demonstrates.",
    "Lemma 1.11. A collection of sets F is a σ -algebra if and only if F is both a π-system and a λ -system.\n\nProof. Clearly a σ -algebra is both a π-system and a λ -system so it remains to establish the converse. Let F be\nboth a π-system and a λ -system. Let A, B ∈ F . Then, since Ω ∈ F , we also have Ac = Ω \\ A ∈ F and further\n\nA ∪ B = Ω \\ (Ac ∩ Bc) ∈ F .\n\nFinally, let {An}n⩾1 ⊆ F be a sequence of sets in F . Then\nn\n(cid:91)\n\n(cid:91)\n\nAn = (cid:91)\nn⩾1\n\nn⩾1\n\nk=1\n\nAk ∈ F\n\nby the properties of λ -sets as the sequence Bn = (cid:83)n\n\nk=1 Ak is increasing.\n\nPage 14\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nWhile π-system is a universally adopted terminology, λ -systems are also called d-systems, Dynkin classes\nor monotone classes. The notions of π- and λ - systems may appear rather artificial at first. In fact, they are very\nuseful. So useful that at some point you may start using them implicitly without thinking much about it. This is\nbecause quite often the (abstract) collection of sets which satisfy a certain property Γ is a λ -system. At the same\ntime, it is often easy to verify that Γ holds for all sets in a given π-system A . The following (fundemental!)\nlemma then says that Γ holds on F = σ (A ). We shall use it time and again.",
    "Lemma 1.12 (π − λ systems lemma). Let M be a λ -system and A be a π-system. Then,\n\nA ⊆ M =⇒ σ (A ) ⊆ M .\n\nProof. Let λ (A ) denote the intersection of all λ -systems containing A . Then, in analogy to Lemma 1.3, λ (A )\nitself is a λ -system, it is the smallest λ -system containing A . In particular, λ (A ) ⊆ M . Naturally, a σ -algebra\nis by definition a λ -system. If we show that λ (A ) is itself a σ -algebra it will imply that λ (A ) = σ (A ) and the\nproof will be complete. By Lemma 1.11, it suffices to show that λ (A ) is a π-system.\n\nLet C = {A ∈ λ (A ) : A ∩ C ∈ λ (A ) ∀C ∈ A }. We first show that C is a λ -system. Clearly, Ω ∈ C . Let\nA, B ∈ C with A ⊆ B. Then (B \\ A) ∩C = B ∩C \\ A ∩C ∈ λ (A ) for all C ∈ A so that B \\ A ∈ C . Finally, if An\nn⩾1 An then A ∩ C = (cid:83)\nis an increasing sequence in C and A = (cid:83)\nn⩾1 An ∩ C ∈ λ (A ) for all C ∈ A and hence\nA ∈ C . By definition, C ⊆ λ (A ) and, since A is a π-system, also A ⊆ C . It follows that C = λ (A ).\n\nNow let D = {A ∈ λ (A ) : A ∩C ∈ λ (A ) ∀C ∈ λ (A )}. As above, we can easily show that D inherits the\nλ -system structure from λ (A ). Further, C = λ (A ) above implies that A ⊆ D. Minimality of λ (A ) again\nimplies that D = λ (A ) and hence λ (A ) is a π-system.\n\nOne of the most important application of the above result will be to assert that if two measures coincide\non a π-system then they coincide on the σ -algebra it generates. In particular, a measure on B(R) is uniquely\nspecified by its distribution function, i.e., its values on π(R) in Example 1.10, see 2.16. The π-λ systems lemma\nwill be used in many other contexts, starting from simple exercises like the following one.\n\nExercise 1.13. Let Ω = Ω1 × Ω2 and F = F1 × F2 be a product space. Fix D ∈ F and denote D(ω1) := {ω2 :\n(ω1, ω2) ∈ D} be its section for a fixed ω1 ∈ Ω1. Show that D(ω1) ∈ F2.\n\n1.2 Random variables\n\nSo far, we have developed the basic language to speak of sets and collections of sets. We now want to do the\nsame for functions.",
    "Definition 1.14 (Measurable function). Let (Ω, F ) and (E, E ) be measurable spaces. A function f : Ω → E is\nsaid to be measurable, or a random variable, if\n\nf −1(A) = {ω ∈ Ω : f (ω) ∈ A} ∈ F ∀A ∈ E .\n\nIf this is not clear from the context, we shall say more precisely that f is an E-valued random variable and\nwe may specify the σ -algebras F , E with respect to which the measurability is taken. The terms measurable\nfunction and random variable are used interchangeably. Similarly, we will use both f and X as our generic\nnotation for a function (one being canonical in analysis and the other in probability) and switch between the two\nat will. The following is clear:",
    "Proposition 1.15. Let (Ω, F ), (E, E ) and (H, H ) be three measurable spaces. Let f : Ω → E and g : E → H\nbe two random variables. Then g ◦ f is a random variable from (Ω, F ) to (H, H ).\n\nProof. For A ∈ H , g−1(A) ∈ E by measurability of g and (g ◦ f )−1(A) = f −1(g−1(A)) ∈ F by measurability\nof f .\n\nPage 15\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales",
    "Example 1.16. Let E = {0, 1} and E = P(E). A subset A ⊂ Ω is an event if and only if its characteristic\nfunction 1A (equal to 1 for ω ∈ A and 0 otherwise) is a random variable.\n\nIn this way, random variables generalise events. Several notions developed for events can be transcribed to\n\nthe context of random variables in a straightforward fashion.",
    "Definition 1.17. Let Ω be a set and ( fi)i∈I a collection of functions from Ω to measurable spaces (Ei, Ei)i∈I. The\nσ -algebra generated by functions ( fi)i∈I, denoted σ ( fi : i ∈ I), is the smallest σ -algebra on Ω with respect to\nwhich all fi, i ∈ I, are measurable.\n\nThe above is well-posed thanks to Lemma 1.3. Further, it extends Definition 1.4. Indeed, if A = {Ai : i ∈ I}\nis a collection of subsets of Ω then σ (A ) = σ (1Ai : i ∈ I). As a way of example, let us specify a bit more the\nσ -algebra generated by a single random variable.",
    "Lemma 1.18. Let X be a random variable from (Ω, F ) to (E, E ) and suppose E = σ (A ). Then\n\nσ (X) = {X −1(A) : A ∈ E } = σ (X −1(A) : A ∈ A ).\n\nProof. It is easy to verify that the inverse A → X −1(A) preserves all the set operations. In particular, {X −1(A) :\nA ∈ E } is a σ -algebra. By definition, it is contained in σ (X) and by the minimality of the latter, the two are\nequal. Denote σ (X; A ) = σ (X −1(A) : A ∈ A ). The inclusion σ (X; A ) ⊆ σ (X) is clear. For the reverse, let\nG = {A ⊆ E : X −1(A) ∈ σ (X; A )}. We verify easily that G is a σ -algebra and since A ⊆ G we conclude that\nE ⊆ G . It follows that σ (X) ⊆ σ (X; A ) and hence we have an equality.\n\nFrom Lemma 1.18 and Example 1.6 we have the following simple property.",
    "Corollary 1.19. A function f : Ω → R or f : Ω → R is measurable with respect to F (and B(R) or B(R)) if\nand only if {x : f (x) ⩽ t} ∈ F for every t ∈ R.",
    "Example 1.20. Consider the product space notation from Definition 1.7. Let Xi denote the coordinate mappings,\ni.e., Xi : Ω → Ωi is given by Xi(ω) = ωi. Then the product σ -algebra is generated by these coordinate mappings,\nF = ×i∈IFi = σ (Xi : i ∈ I). In particular, all Xi are measurable. On the other hand, if (E, E ) is a measurable\nspace and Yi : (E, E ) → (Ωi, Fi) are measurable then the mapping Y : E → Ω given by Y = (Yi : i ∈ I) is\nmeasurable (with respect to F ).\n\nWe give one more simple example of an abstract random variable.",
    "Example 1.21. Let G ⊆ F . Then the identity mapping of (Ω, F ) onto (Ω, G ) is a random variable.",
    "Example 1.22. Recall the model for repetitive coin tossing described in Example 1.8. It involved a careful\nchoice of Ω which, in an intuitive sense, was minimal for our purposes. If we wanted to expand our experiment\nand toss a coin and a dice simultaneously we would not be able to do so using Ω. For this reason, it is usually a\nmuch better practice to work with a fixed large (Ω, F ) and to encode our experiments using random variables\non Ω. For example, we could take ([0, 1], B([0, 1])) and let Xn(ω) = 1⌊2nω⌋ is even, n ⩾ 1, where 0 is even. It is\neasy to check that Xn is a random variable and Xn ∈ {0, 1}. We shall see these are just as good a way to express\nthe coin tossing experiment.\n\nRemark. The above example makes it clear that σ -algebra may be thought of as a representation of our infor-\nmation, as already mentioned in the discussion following Example 1.2. Think of a probability space (Ω, F , P)\nas an abstract carrier for randomness. Random variables on Ω represent outcomes of experiments, random things\nhappening. In Example 1.22, (Xn)n⩾1 represented successive coin tosses. Then Gn = σ (Xk : 1 ⩽ k ⩽ n) is the\nσ -algebra corresponding to the information about the first n tosses. It is the smallest σ -algebra which allows us\nto recognise the outcomes of these tosses. G = σ (Xn : n ⩾ 1) is the σ -algebra generated by all the sequence of\ntosses but it will typically be much smaller than F , which represents “the ultimate knowledge”.\n\nPage 16\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nFrom now on, unless explicitly stated otherwise, we shall consider random variables with values in E = R\nor R = [−∞, ∞]. In this case we always consider measurability relative to the Borel sets: E = B(R) or B(R).",
    "Example 1.23. Let (E, d) be a metric space and let B(E) be the Borel σ -algebra generated by its open sets.\nThen the Borel σ -algebra on E is equal to the Baire σ -algebra on E:\n\nB(E) = σ ( f : E → R| f continuous).\n\nAs in Corollary 1.19, for f to be measurable it is enough to check that f −1(O) ∈ B(E) for an open interval O and\nthis follows from continuity. In particular, the “⊇” inclusion follows. For a closed set F ⊆ E, let fF (x) = d(x, F)\nbe the distance of x to F. Then f is continuous and F = f −1\nF ({0}) is an element of the right hand side. This\ngives the reverse inclusion “⊆” and hence the equality.\n\nRecall that\n\nlim sup\nn→∞\n\nxn = lim\nn→∞\n\nsup\nm⩾n\n\nxm and\n\nlim inf\nn→∞\n\nxn = lim\nn→∞\n\ninf\nm⩾n\n\nxm.\n\nThe following result was proved in Part A (in some cases only for functions taking finite values, but the extension\nis no problem).",
    "Proposition 1.24. Let ( fn) be a sequence of measurable functions on (Ω, F ) taking values in R, and let h :\nR → R be Borel measurable. Then, whenever they make sense1, the following are also measurable functions on\n(Ω, F ):\n\nf1 + f2,\n\nf1 f2, max{ f1, f2}, min{ f1, f2},\n\nf1/ f2,\n\nh ◦ f",
    "Definition 1.25. A measurable function f on (Ω, F ) is called a simple function if\n\nfn,\n\nsup\nn\n\nfn,\n\ninf\nn\n\nlim sup\nn→∞\n\nfn,\n\nlim inf\nn→∞\n\nfn.\n\nf =\n\nn\n∑\nk=1\n\nak1Ek\n\n(6)\n\nfor some n ⩾ 1 and where each Ek ∈ F and each ak ∈ R. The canonical form of f is the unique decomposition\nas in (6) where the numbers ak are distinct and non-zero and the sets Ek are disjoint and non-empty.\n\nClearly, a simple function is measurable. Conversely, any measurable function can be obtained as a limit of\n\nsimple functions. This gives us:",
    "Lemma 1.26. Let (Ω, F ) be a measurable space. A function X : Ω → R is measurable if and only if it is a limit\nof simple functions. Further, if f is bounded from below (resp. bounded), the limit can be taken to be increasing\n(resp. uniform).\n\nProof. That a limit of simple functions is a measurable function follows from Proposition 1.24. Now let X be a\nrandom variable and define\n\nXn = −2n1X⩽ −4n+1\n\n2n\n\n+\n\n∑\nk∈Z∩[−4n+1,4n−1]\n\nk\n2n 1 k\n\n2n <X⩽ k+1\n2n\n\n+ 2n12n<X ,\n\nn ⩾ 1.\n\n(7)\n\nn := {ω ∈ Ω : X(ω) ⩽ 2n}, Ω−\n\nn := {ω ∈ Ω : X(ω) > −2n} and Ωn = Ω−\n\nn ∩ Ω+\n\nn . The result follows by\n\nLet Ω+\nnoting that supω∈Ωn\n\n|Xn(ω) − X(ω)| ⩽ 2−n and Xn ⩽ Xn+1 on Ω−\nn .\n\n1For example, ∞ − ∞ is not defined.\n\nPage 17\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nWe give a simple example of a result where approximating a general random variable with simple ones is\nused in the proof. This result also highlights further the information interpretation of a σ -algebra and shows that\nthe abstract measurability definition agrees with a more intuitive one of ‘being a function of’.",
    "Theorem 1.27. Let X be a random variable on (Ω, F ) with values in a measurable space (E, E ) and let g\nbe a real-valued random variable on (Ω, F ). Then g is σ (X)-measurable if and only if g = h ◦ X for some\nreal-valued random variable on (E, E ).\n\nDeep Dive\n\nProof. One direction is clear: g = h ◦ X is a real-valued random variable. For the other direction, start with g\nand suppose it takes at most countably many distinct values (an)n⩾1. The sets An = g−1({an}) are pairwise\ndisjoint and each is an element of σ (X) and hence, by Lemma 1.18, An = X −1(Bn) for some Bn ∈ E . Note that\nwe might have Bn ∩ Bm ̸= /0 but the points in the intersection are not in the range of values of X. Consequently,\nif we set Cn := Bn \\ (cid:83)n−1\nk=1 Bk then Cn ∈ E are pairwise disjoint and X −1(Cn) = An \\ (cid:83)n−1\nk=1 Ak = An. If we put\nh = ∑n⩾1 an1Cn then g = h ◦ X as required.\n\nFor a general g, let gn ↑ g be the sequence of simple random variables converging to g given by Lemma\n1.26. By the above, we can write each gn = hn ◦ X. Let H = {e ∈ E : hn(e) converges}. Recall that both\nlim sup hn and lim inf hn are measurable and so H = {lim sup hn = lim inf hn} is measurable. Further, X(Ω) ⊆ H\nsince gn ↑ g. It follows that h(ω) := (limn→∞ hn(ω))1H(ω) is measurable and satisfies g = h ◦ X .\n\nA lot of results, e.g., when developing the integration theory, can be shown using a “bare hands method”\npowered by Lemma 1.18. The schematic is as follows: to establish a “linear” result for all functions in a given\nclass, say for all bounded measurable functions, we proceed in steps:\n\n• first establish the result for indicators of a measurable set, where it usually holds by definition;\n\n• by linearity extend this to all simple functions or all positive simple functions;\n\n• take limits, using a suitable convergence theorem, extend the result to all functions, or all positive func-\n\ntions;\n\n• if needed, write X = X + − X − and use the above to pass from positive to all functions.\n\nSuch an approach allows one to see the theory “grow” and demystifies it. It is useful to go through the steps\nabove once in detail but later one can apply these semi-automatically. However, sometimes it is very difficult to\nuse the above bare-hands approach and it becomes necessary to turn to a functional equivalent of Lemma 1.12.\nThis is known as the Monotone Class Theorem. It comes in many variants and flavours and we state just one. It\nusually gives a quick and elegant proof but may at first appear to be a magic trick of sorts.",
    "Theorem 1.28 (Monotone Class Theorem). Let H be a class of bounded functions from Ω to R satisfying the\nfollowing conditions:\n\n(i) H is a vector space over R,\n\n(ii) the constant function 1 is in H ,\n\n(iii) if ( fn)n⩾1 ⊆ H such that fn ↗ f for a bounded function f , then f ∈ H .\nIf C ⊆ H is stable under pointwise multiplication then H contains all bounded σ (C )-measurable functions.\n\nPage 18\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nDeep Dive\n\nWe outline now the proof of the above important result. First, we make the following simple observation.\n\nLemma. In the setup of Theorem 1.28, H is closed under uniform limits.\n\nProof. Let fn be a sequence of functions in H converging uniformly to some f . Passing to a subsequence,\nwe can assume that ∥ fn − f ∥sup ⩽ 2−n, where ∥ f ∥sup = supω∈Ω | f (ω)|. Now we can modify the sequence so\nthat it is increasing. Set gn = fn − 21−n. Then gn − gn−1 = fn − fn−1 + 21−n ⩾ 2−n ⩾ 0. Also,\n\n∥gn∥sup = ∥ f1 +\n\nn\n∑\nk=2\n\nfk − fk−1 − 21−n∥sup ⩽ ∥ f1∥sup + 3\n\nthe sequence is uniformly bounded so that its limit is also bounded and hence H ∋ lim gn = lim fn = f .\n\nProof of Theorem 1.28 – special case. Consider first the case when C = {1A : A ∈ A } for a π-system A .\nHere Theorem 1.28 is a functional equivalent of Lemma 1.12. To see this, simply check that the properties of\nH mean that the family of sets E ⊆ Ω for which 1E ∈ H forms a λ -system. Lemma 1.12 now shows that\n1E ∈ H for all E ∈ σ (A ) and Lemma 1.26 tells us that any bounded measurable function is a uniform limit\nof simple functions and hence, by the above lemma, is also in H , as required.\n\nProof of Theorem 1.28 – reduction to the special case. We prove the general statement by reducing it to the\nspecial case treated above. Note that without any loss of generality we can assume that 1 ∈ C . Let A0 be the\nalgebra of functions generated by C . Given that C is already closed under multiplication, A0 is simply the\nlinear span of C . Let A be the closure of A0 under uniform convergence. By the above lemma, A ⊂ H\nand we check that A is still an algebra of functions. Take f ∈ A and since it is a bounded function we can\ntake a closed interval R ⊆ R with f (ω) ∈ R, ω ∈ Ω. On R, by the Weierstrass approximation theorem, we can\napproximate the function x → |x| uniformly using a sequence of polynomials pn. Note that pn ◦ f ∈ A and\nhence also its uniform limit | f |. It then follows that A is closed under ∧ and ∨ (observe that f + = (| f | + f )/2\nand f ∨ g = f + (g − f )+ etc.). Now, for any f ∈ A and any a ∈ R we have\n\nA ∋ n( f − a)+ ∧ 1 ↑ 1 f −1((a,∞))\n\nand hence the limit is in H , i.e., {1D : D ∈ D} ⊆ H , where D = { f −1((a, ∞)) : f ∈ A , a ∈ R}. Note that\n{ f > a} ∩ {g > b} = {( f − a)+(g − b)+ > 0} so that D is a π-system and by Lemma 1.18, σ (D) = σ ( f :\nf ∈ A ). This reduces the general result to the special case previously considered.\n\nRemark. Following the ideas of the proof, one can devise other statements and variants of the Monotone\nClass Theorem. For example, instead of supposing that C is stable under multiplication, one can consider\ncones of non-negative functions stable under taking minimum: f , g ∈ C then a f ∧ bg ∈ C for a, b ∈ R+. Then\nthe uniform closure of A = { f − g : f , g ∈ C } is a vector space stable under ∧, ∨ and one can show it is also\nstable under multiplication, first approximating x → x2 and hence showing that f 2 ∈ A for f ∈ A .\n\nAn important common example is the special case of C = {1A : A ∈ A } for a π-system A . In this case,",
    "Theorem 1.28 can be deduced from Lemma 1.12 and Lemma 1.26. Let us give now one application of the above\nresult and use it to highlight this relationship with the π-λ systems lemma.",
    "Lemma 1.29. Let (Ω, F ) be the product space of two measurable spaces (Ωi, Fi), i = 1, 2. If f : Ω → R is\nmeasurable then\n\n• for each ω1 ∈ Ω1, Ω2 ∋ ω2 → f (ω1, ω2) is F2-measurable and\n\nPage 19\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n• for each ω2 ∈ Ω2, Ω1 ∋ ω1 → f (ω1, ω2) is F1-measurable.\n\nThe first proof: using the Monotone Class Theorem. Let H be the class of bounded functions h : Ω → R which\nsatisfy the assertion of the lemma. Clearly H satisfies the assumptions of the Monotone Class Theorem (The-\norem 1.28) and contains the functions h = 1A1×A2 for Ai ∈ Fi, i = 1, 2. These rectangles generate F and\nwe conclude that H contains all bounded measurable functions. For an unbounded f , we use the result for\nfn = ( f ∨ −n) ∧ n, which is bounded, and use that limits of measurable functions are measurable.\n\nThe second proof: using π-λ systems lemma. An application of π-λ systems lemma shows that the statement\nholds for f = 1D for D ∈ F , see Exercise 1.13. It thus also holds for simple functions. It remains to apply",
    "Lemma 1.26 and note that limits of measurable functions are measurable.\n\nThe third (and the simplest) proof. Fix ω1 ∈ Ω2. Let ι : Ω2 → Ω be given by ι(ω2) = (ω1, ω2). For Ai ∈ Fi,\ni = 1, 2, we have ι −1(A1 × A2) = A2 if ω1 ∈ A1 and /0 otherwise. It follows by Lemma 1.18 that ι is measurable.\nThe map Ω2 ∋ ω2 → f (ω1, ω2) is a composition of measurable functions, namely f ◦ ι, and is hence F2-\nmeasurable by Proposition 1.15.\n\nPage 20\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n2 Measures\n\nNow that we have the basic ingredients, we shall start to measure them! In Part A Integration we conceptualised\nthe idea of length (or volume) and saw that there is a good way to construct a measure of length, the Lebesgue\nmeasure Leb, which can be assigned in a consistent way to any set in B(R), or in MLeb more generally. We\nwant to now take a more abstract view and develop an abstract theory of measuring sets. We formalise the idea\nof assigning a likelihood or a probability to a set and of doing this in a consistent manner.\n\n2.1 Measures and Measurable spaces",
    "Definition 2.1 (Set functions). Let A be a collection of subsets of Ω containing the empty set /0. A set function\non A is a function µ : A → [0, ∞] with µ( /0) = 0. We say that µ is countably additive, or σ -additive, if for all\nsequences (An) of disjoint sets in A with (cid:83)∞\n\nn=1 An ∈ A\n(cid:33)\n(cid:32) ∞\n(cid:91)\n\nAn\n\nµ\n\nn=1\n\n=\n\n∞\n∑\nn=1\n\nµ(An).\n\nRecall that a measurable space is a pair (Ω, F ) where F is a σ -algebra on Ω.",
    "Definition 2.2 (Measure space). A measure space is a triple (Ω, F , µ) where Ω is a set, F is a σ -algebra on Ω\nand µ : F → [0, ∞] is a countably additive set function. Then µ is a measure on (Ω, F ).\n\nIn short, a measure space is a set Ω equipped with a σ -algebra F and a countably additive set function µ\non F . Note that any measure µ is also additive and increasing. Being a measure is relative to the context of the\ngiven measurable space hence we say, as above, that µ is a measure on (Ω, F ). However, for simplicity, when\nthe choice of (Ω, F ) is unambiguous, we will often just say that µ is a measure on F or on Ω. We summarise\nnow some easy properties of measures.",
    "Proposition 2.3. Let (Ω, F , µ) be a measure space and A, B, An, Bn ∈ F , n ⩾ 1. Then\n\n(i) A ∩ B = /0 =⇒ µ(A ∪ B) = µ(A) + µ(B)\n\n(ii) A ⊆ B =⇒ µ(A) ⩽ µ(B)\n\n(iii) µ(A ∪ B) + µ(A ∩ B) = µ(A) + µ(B)\n\n(iv) An ↑ A, then µ(An) ↑ µ(A) as n → ∞\n\n(v) Bn ↓ B, µ(Bk) < ∞ for some k ∈ N, then µ(Bn) ↓ µ(B) as n → ∞\n(vi) µ (cid:0)(cid:83)\n\n(cid:1) ⩽ ∑n⩾1 µ(An)\n\nn⩾1 An\n\n(additive)\n\n(increasing)\n\n(continuous from below)\n\n(continuous from above)\n\n(σ -subadditive)\n\nProof. The proof is mostly a direct consequence of the defining properties of a measure and is left as an exercise.\nWe just show (iv). Define sets D1 := A1 and Dn := An \\ An−1 for n ⩾ 1 and note these are pairwise disjoint since\nAn−1 ⊆ An. Further, An = (cid:83)\n\nk⩽n Dk. It follows that\n\nµ(A) = µ\n\n(cid:32)\n\n(cid:91)\n\nn⩾1\n\n(cid:33)\n\n(cid:32)\n\nAn\n\n= µ\n\n(cid:33)\n\n(cid:91)\n\nDn\n\nn⩾1\n\n= ∑\nn⩾1\n\nµ(Dn) = lim\nn→∞\n\nn\n∑\nk=1\n\nµ(Dk) = lim\nn→∞\n\nµ(An),\n\nwhere the third equality is by countable additivity of µ and the last equality is by finite additivity of µ.\n\nPage 21\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nNote that µ(Bk) < ∞ is essential in (v): for a counter-example take Bn = (n, ∞) ⊆ R and Lebesgue measure.\nThe following lemma adds a converse to (iv) above and asserts that an additive set function is countably additive\nif and only if it is continuous from above.",
    "Lemma 2.4. Let µ : A → [0, ∞) be an additive set function on an algebra A taking only finite values. Then µ\nis countably additive iff for every sequence (An) of sets in A with An ↓ /0 we have µ(An) → 0.\n\nProof. One implication follows (essentially) from Proposition 2.3; the other is an exercise.",
    "Definition 2.5 (Types of measure space). Let (Ω, F , µ) be a measure space.\n\n1. We say that µ is finite if µ(Ω) < ∞.\n\n2. If there is a sequence (Kn)n⩾1 of sets from F with µ(Kn) < ∞ for all n and (cid:83)∞\n\nn=1 Kn = Ω, then µ is said\n\nto be σ -finite.\n\n3. In the special case when µ(Ω) = 1, we say that µ is a probability measure and (Ω, F , µ) is a probability\n\nspace; we often use the notation (Ω, F , P) to emphasize this.",
    "Definition 2.6 (Null sets, a.e.). Let (Ω, F , µ) be a measure space. We say that a set A is null if µ(A) = 0. We\nsay that a property holds almost everywhere (a.e.), or for almost every ω ∈ Ω, if it holds outside of a null set.\n\nIf P is a probability measure we typically say that a property holds almost surely (a.s.) instead of almost\neverywhere. For instance, we will say that two events are a.s. equal, A = B a.s., if P(A△B) = 0. Similarly, for\ntwo random variables X,Y we say that X = Y a.s., if P(X ̸= Y ) = 0. If the reference measure is not obvious we\nshall indicate it explicitly, e.g., by saying µ-null or P-a.s.\n\nThe structure of its null sets tells us a lot about a given measure. Intuitively speaking, if two measures have\nthe same null sets, then one is a re-weighted version of the other. If their null sets differ then one can not go\nfrom one measure to another – no re-weighting will resurrect zero into a positive number. This intuition will be\nmade precise in Theorem 4.9 but we can already define the relevant concept.",
    "Definition 2.7. Let µ, ν be two measures on a measurable space (Ω, F ). We say that ν is absolutely continuous\nwith respect to µ, and write ν ≪ µ, if µ(A) = 0 for some A ∈ F implies ν(A) = 0.\nWe say that µ and ν are equivalent, and write µ ∼ ν, if ν ≪ µ and µ ≪ ν.\n\nLet us now specify some easy examples of measures.",
    "Example 2.8.\n\n(i) Let (Ω, F ) be a measurable space. The zero function, µ(A) = 0 for all A ∈ F , defines a\nmeasure. Likewise, ν given by ν( /0) = 0, ν(A) = +∞ for all /0 ̸= A ∈ F also defines a measure. Clearly\nboth are trivial examples and are well defined for any σ -algebra F .\n\n(ii) Let (Ω, F ) be a measurable space and fix ω ∈ Ω. Then δω defined via δω (A) = 1ω∈A defines a measure.\n\nIt is called the Dirac measure in ω or the point mass in ω.\n\n(iii) On R consider the σ -algebra A of sets which are either countable or have a countable complement, see",
    "Example 1.2 (iv). Then µ(A) = 0 for countable A and µ(A) = 1 otherwise, A ∈ A , defines a probability\nmeasure on A .\n\n(iv) Let (Ω, F ) be a measurable space. For A ∈ F , set µ(A) = |A|, the number of elements in A, if A is finite\n\nand µ(A) = +∞ if A is infinite. Then µ is the counting measure on Ω.\n\nIt is difficult to construct explicitly, in a manner similar to the above, less trivial examples. We shall develop\nmore systematic ways to build measures later. Here, we give one more example which connects our abstract\nnotions with the intuitive counting notions.\n\nPage 22\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales",
    "Example 2.9 (Discrete measure theory). Let Ω be a countable set. A mass function on Ω is any function\np : Ω → [0, ∞]. Given such a p we can define a measure on (Ω, P(Ω)) by setting µ(A) = ∑x∈A p(x). In the\nnotation of Example 2.8 (ii), µ = ∑x∈Ω p(x)δx.\n\nConversely, given a measure µ on (Ω, P(Ω)) we can define the corresponding mass function by p(x) =\nµ({x}). Consequently, for a countable Ω, there is a one-to-one correspondence between measures on (Ω, P(Ω))\nand mass functions on Ω.\n\nNote also, that if µ, ν are two measures with their respective mass functions p, r then ν ≪ µ if and only if\n\np(x) = 0 implies r(x) = 0.\n\nThese discrete measure spaces provide a ‘toy’ version of the general theory, but in general they are not enough.\nDiscrete measure theory is essentially the only context in which one can define the measure explicitly and work\n“ω by ω”. This is because σ -algebras are not in general amenable to an explicit presentation, and it is not in\ngeneral the case that for an arbitrary set Ω all subsets of Ω can be assigned a measure – recall from Part A\nIntegration the construction of a non-Lebesgue measurable subset of R. Instead one shows the existence of a\nmeasure defined on a ‘large enough’ collection of sets, with the properties we want. To do this, we follow a\nvariant of the approach you saw in Part A; the idea is to specify the values to be taken by the measure on a\nsmaller class of subsets of Ω that ‘generate’ the σ -algebra (as the singletons did in Example 2.9). This leads\nto two problems. First we need to know that it is possible to extend the measure that we specify to the whole\nσ -algebra. This construction problem is often handled with Carath´eodory’s Extension Theorem (Theorem 2.11\nbelow). The second problem is to know that there is only one measure on the σ -algebra that is consistent with\nour specification. This uniqueness problem is resolved using the π-λ systems Lemma (Lemma 1.12).",
    "Theorem 2.10 (Uniqueness of extension). Let µ1 and µ2 be measures on a measurable space (Ω, F ) and let\nA ⊆ F be a π-system with σ (A ) = F . If µ1(Ω) = µ2(Ω) < ∞ and µ1 = µ2 on A , then µ1 = µ2.\nProof. In view of Lemma 1.12 it suffices to verify that {A ∈ F : µ1(A) = µ2(A)} is a λ -system, which is left as\nan exercise.\n\nDeep Dive\n\nNote that the assumption µ1(Ω) = µ2(Ω) < ∞ is an important one. The result, as usual, extends to σ -finite\nmeasures with a common sequence of sets Kn with µ1(Kn) = µ2(Kn) < ∞. However, it may fail for infinite\nmeasures. Consider, for example, µ1(A) is zero or infinity according to whether the set A has no rational\npoints or at least one rational point, and let µ2(A) = ∞ for all A ̸= /0. Taking A the family of open intervals,\nwe have µ1(A) = µ2(A) for A ∈ A but the two measures are not equal.\n\nWe can rephrase Theorem 2.10 simply saying that two probability measures which coincide on a π-system also\nagree on the σ -algebra generated by that π-system. That deals with uniqueness, but what about existence?",
    "Theorem 2.11 (Carath´eodory Extension Theorem). Let Ω be a set and A an algebra on Ω, and let F = σ (A ).\nLet µ0 : A → [0, ∞] be a countably additive set function. Then there exists a measure µ on (Ω, F ) such that\nµ = µ0 on A .\n\nRemark 2.12. If µ0(Ω) < ∞, then Theorem 2.10 tells us that µ is unique, since an algebra is certainly a π-\nsystem. This extends to the σ -finite case if we can take Kn ∈ A in Definition 2.5. Indeed, we then obtain\nuniqueness of extension of µ0 to a measure on {A ∩ Kn : A ∈ F }, for n ⩾ 1, and hence also on F .\n\nThe Carath´eodory Extension Theorem doesn’t quite solve the problem of constructing measures on σ -\nalgebras – it reduces it to constructing countably additive set functions on algebras; we shall see several ex-\namples. The idea of proof of the Carath´eodory Extension Theorem is rather simple, even if the details are\n\nPage 23\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\ntedious. First one defines the outer measure µ ∗(B) of any B ⊆ Ω by\n\nµ ∗(B) = inf\n\n(cid:110) ∞\n∑\nj=1\n\nµ0(A j) : A j ∈ A ,\n\nA j ⊇ B\n\n(cid:111)\n.\n\n∞\n(cid:91)\n\nj=1\n\nThen define a set B to be measurable if for all sets E,\n\nµ ∗(E) = µ ∗(E ∩ B) + µ ∗(E ∩ Bc).\n\n[Alternatively, if µ0(Ω) is finite, then one can define B to be measurable if µ ∗(B) + µ ∗(Bc) = µ0(Ω); this more\nintuitive definition expresses that it is possible to cover B and Bc ‘efficiently’ with sets from A .] One must check\nthat µ ∗ defines a countably additive set function on the collection of measurable sets extending µ0, and that the\nmeasurable sets form a σ -algebra that contains A . For details see Appendix A.1 of Williams, or Varadhan and\nthe references therein.\n\nWe comment now on two generic ways to construct measures: through restrictions and by finite sums. Sub-\nsequent sections will develop in detail other methods. First, the following is immediate and allows to construct\nmeasure spaces by restricting the σ -algebra.",
    "Lemma 2.13. Let (Ω, F , µ) be a measure space and G ⊆ F a σ -algebra. Then (Ω, G , µ|G ), where µ|G is the\nrestriction of µ to G , is a measure space.\n\nThe reverse direction however is unclear and often untrue: given a measure space (Ω, F , µ) and a larger\nσ -algebra H ⊇ F it may be possible or impossible to extend µ to H and, if possible, such an extension does\nnot have to be unique. Clearly, Carath´eodory Extension Theorem is not useful here since σ (F ) = F . Second,\nsums of measures are measures.",
    "Lemma 2.14. Let (Ω, F ) be a measurable space and (µn)n⩾1 a sequence of probability measures on F . Fix\na sequence of positive numbers (an)n⩾0 with ∑n⩾1 an = 1. Then µ, defined by µ(A) = ∑n⩾1 anµn(A) is also a\nprobability measure on F .\n\nThe above lemma follows once we know we can exchange the order of summation in a double (countable)\nsum of positive numbers. This will in particular follow from (generalised) Fubini’s theorem (Theorem 4.24)\nwhich we will see later in these lectures.\n\nIf µ is a finite measure then P(A) := µ(A)/µ(Ω) is a probability measure.\n\nIt is therefore with no loss\nof generality that in the remainder of this course, we shall mostly work with probability measures. We will\ncomment when these results extend to the σ -finite case.\n\n2.2 Conditional probability\n\nLet (Ω, F , P) be a probability space and B ∈ F a set with P(B) > 0. Define a new measure µ, also denoted\nP(·|B) on F by\n\nµ(A) = P(A|B) =\n\n, A ∈ F .\n\n(8)\n\nP(A ∩ B)\nP(B)\n\nThen it is an easy exercise to check that µ is a probability measure on F . Alternatively, we could define µ as a\nprobability measure on (B, G ) with G = {A ∩ B : A ∈ F } by simply putting µ(A) = P(A)/P(B) for A ∈ G .\n\nThe above definition agrees with what you have seen in Prelims and Part A probability courses. Here we\nwill want to get more serious about conditioning. Conditioning should be relative to information one has and\nwe saw earlier that σ -algebra were the natural carriers or descriptions for information content. We would thus\nlike to condition on a σ -algebra. In the example above, we could replace B by its complement Bc and obtain a\nnew measure P(A|Bc). Now, for any ω ∈ Ω, we have either ω ∈ B or ω ∈ Bc so it is natural to define\n\nP(A|σ (B))(ω) := P(A|B)1B(ω) + P(A|Bc)1Bc(ω).\n\n(9)\n\nPage 24\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nIn this way, for a fixed ω ∈ Ω, P(·|σ (B))(ω) is a probability measure but for a fixed A ∈ F , P(A|σ (B))(·) is a\nrandom variable (taking two values). It is the latter point of view which will prove very powerful and will set\nprobability alive (and apart from analysis) as we will see in §6.\n\n2.3 Measures on (R, B(R))\n\nRecall that in our ‘toy example’ of discrete measure theory there was a one-to-one correspondence between\nmeasures and mass functions. Can we say anything similar for Borel measures on R?",
    "Definition 2.15. Let µ be a probability measure on B(R). The distribution function of µ is the function\nFµ : R → R defined by Fµ (x) = µ((−∞, x]).\n\nThe function Fµ has the following properties:\n\n(i) Fµ is increasing, i.e., x < y implies Fµ (x) ⩽ Fµ (y),\n\n(ii) Fµ (x) → 0 as x → −∞ and Fµ (x) → 1 as x → ∞, and\n\n(iii) Fµ is right continuous: y ↓ x implies Fµ (y) → Fµ (x).\n\nTo see the last, suppose that yn ↓ x and let An = (−∞, yn]. Then An ↓ A = (−∞, x]. Thus, by Proposition 2.3,\nFµ (yn) = µ(An) ↓ µ(A) = Fµ (x). We often write Fµ (−∞) = 0 and Fµ (∞) = 1 as shorthand for the second\nproperty.\n\nAny function F : R → R which satisfies the same three properties as Fµ above will be called a distribution\nfunction on R. Using the Carath´eodory Extension Theorem, we can construct all Borel probability measures on\nR (i.e., probability measures on (R, B(R))): there is one for each distribution function. Since finite measures can\nall be obtained from probability measures (by multiplying by a constant), this characterizes all finite measures\non B(R).",
    "Theorem 2.16 (Lebesgue). Let F : R → R be a distribution function, i.e., F is an increasing, right continuous\nfunction with F(−∞) = 0 and F(∞) = 1. Then there is a unique Borel probability measure µ = µF on R such\nthat µ((−∞, x]) = F(x) for every x. Every Borel probability measure µ on R arises in this way.\n\nIn other words, there is a 1-1 correspondence between distribution functions and Borel probability measures\n\non R. Before proving this result let us state an immediate corollary.",
    "Corollary 2.17. There exists a unique Borel measure Leb on R such that for all a, b ∈ R with a < b, Leb ((a, b]) =\nb − a. The measure Leb is the Lebesgue measure on B(R).\n\nProof. The statement with R replaced by (0, 1] follows from Theorem 2.16 with F(x) = 0 on (−∞, 0], F(x) = x\non [0, 1] and F(x) = 1 on [1, ∞). This gives us the Lebesgue measure Lebk on any (k, k + 1]. We set Leb(A) =\n∑k∈Z Lebk(A ∩ (k, k + 1]) and easily check it defines a measure on B(R) with the right properties. Uniqueness\nfollows from Remark 2.12.\n\nRemark. In Part A Integration, the Lebesgue measure was defined on a σ -algebra MLeb that contains, but is\nstrictly larger than, B(R). It turns out (exercise) that MLeb consists of all sets that differ from a Borel set on a\nnull set. In this course we shall work with B(R) rather than MLeb: the Borel σ -algebra will be ‘large enough’\nfor us. (This changes later when studying continuous-time martingales.) An advantage of B(R) is that it has a\nsimple definition independent of the measure; recall that which sets are null depends on which measure is being\nconsidered.\n\nPage 25\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nProof of Theorem 2.16. Suppose for the moment that the existence statement holds. Since π(R) = {(−∞, x] :\nx ∈ R} is a π-system which generates the σ -algebra B(R), uniqueness follows by Theorem 2.10. Also, to see\nthe final part, let µ be any Borel probability measure on R, and let F be its distribution function. Then F has\nthe properties required for the first part of the theorem, and we obtain a measure µF which by uniqueness is the\nmeasure µ we started with.\n\nFor existence we shall apply Theorem 2.11, so first we need a suitable algebra. For −∞ ⩽ a ⩽ b < ∞, let\nIa,b = (a, b], and set Ia,∞ = (a, ∞). Let I = {Ia,b : −∞ ⩽ a ⩽ b ⩽ ∞} be the collection of intervals that are open\non the left and closed on the right. Let A be the set of finite disjoint unions of elements of I ; then A is an\nalgebra, and σ (A ) = σ (I ) = B(R).\n\nWe can define a set function µ0 on A by setting\n\nµ0(Ia,b) = F(b) − F(a)\n\nfor intervals and then extending it to A by defining it as the sum for disjoint unions from I . It is an easy\nexercise to show that µ0 is well defined and finitely additive. Carath´eodory’s Extension Theorem tells us that µ0\nextends to a probability measure on B(R) provided that µ0 is countably additive on A . Proving this is slightly\ntricky. Note that we will have to use right continuity at some point.\n\nFirst note that by Lemma 2.4, since µ0 is finite and additive on A , it is countably additive if and only if, for\n\nany sequence (An) of sets from A with An ↓ /0, µ0(An) ↓ 0.\n\nSuppose that F has the stated properties but, for a contradiction, that there exist A1, A2, . . . ∈ A with An ↓ /0\nbut µ0(An) ̸→ 0. Since µ0(An) is a decreasing sequence, there is some δ > 0 (namely, lim µ0(An)) such that\nµ0(An) ⩾ δ for all n. We look for a descending sequence of compact sets; since if all the sets in such a sequence\nare non-empty, so is their intersection.\n\nStep 1: Replace An by Bn = An ∩ (−l, l]. Since\n\nµ0(An \\ Bn) ⩽ µ0\n\n(cid:0)(−∞, l] ∪ (l, ∞)(cid:1) = F(−l) + 1 − F(l),\n\nif we take l large enough then we have µ0(Bn) ⩾ δ /2 for all n.\n\nStep 2: Suppose that Bn = (cid:83)kn\n\ni=1 Ian,i,bn,i. Let Cn = (cid:83)kn\n\ncontinuity of F to do this in such a way that\n\ni=1 I ˜an,i,bn,i where an,i < ˜an,i < bn,i and we use right\n\nµ0(Bn\\Cn) <\n\nδ\n2n+2\n\nfor each n.\n\nLet Cn be the closure of Cn (obtained by adding the points ˜an,i to Cn).\nStep 3: The sequence (Cn) need not be decreasing, so set Dn = (cid:84)n\n\ni=1 Ci, and En = (cid:84)n\n\ni=1 Ci. Since\n\nµ0(Dn) ⩾ µ0(Bn) −\n\nn\n∑\ni=1\n\nµ0(Bi\\Ci) ⩾ δ\n2\n\n−\n\nn\n∑\ni=1\n\nδ\n2i+2\n\n⩾ δ\n4\n\n,\n\nDn is non-empty. Thus En ⊇ Dn is non-empty.\n\nEach En is closed and bounded, and so compact. Also, each En is non-empty, and En ⊇ En+1. Hence, by a\nbasic result from topology, there is some x such that x ∈ En for all n. Since En ⊆ Cn ⊆ Bn ⊆ An, we have x ∈ An\nfor all n, contradicting An ↓ /0.\n\nWe now have a very rich class of measures to work with. The measures µ described in Theorem 2.16 are\nsometimes called Lebesgue–Stieltjes measures. The function F(x) is the distribution function corresponding to\nthe probability measure µ. In the case when F is continuously differentiable, say, it is precisely the cumulative\ndistribution function of a continuous random variable with probability density function f (x) = F ′(x) that we\nencountered in Prelims.\n\nPage 26\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nMore generally, if f (x) ⩾ 0 is measurable and (Lebesgue) integrable – as defined in the next section – with\n\n(cid:82) ∞\n−∞ f (x)dx = 1, then we can use f as a density function to construct a measure µ on (R, B(R)) by setting\n(cid:90)\n\nµ(A) =\n\nf (x)dx.\n\nA\n\nThis measure has distribution function F(x) = (cid:82) x\n−∞ f (y)dy. (It is not necessarily true that F ′(x) = f (x) for all x,\nbut this will hold for almost all x.) For example, taking f (x) = 1 on (0, 1), or on [0, 1], and f (x) = 0 otherwise,\nwe obtain the distribution function F with F(x) = 0, x < 0, F(x) = x, 0 ⩽ x ⩽ 1 and F(x) = 1 for x > 1,\ncorresponding to the uniform distribution on [0, 1].\n\nFor a very different example, if x1, x2, . . . is a sequence of points (for example the non-negative integers),\n\nand we have probabilities pn > 0 at these points with ∑n pn = 1, then for the discrete probability measure\n\nwe have the distribution function\n\nµ(A) = ∑\nn : xn∈A\n\npn,\n\nF(x) = ∑\nn : xn⩽x\n\npn,\n\nwhich increases by jumps, the jump at xn being of height pn.\nexample if there is a jump at every rational.)\n\n(The picture can be complicated though, for\n\nThere are examples of continuous distribution functions F that don’t come from any density f , e.g., the\n\nDevil’s staircase, corresponding (roughly speaking) to the uniform distribution on the Cantor set.\n\n2.4 Pushforward (image) measure\n\nSo far we saw how to construct measures by specifying their action on a generating algebra of sets. This works\nin general, as Theorem 2.11 shows, and led to a complete description of probability measures on R. We now\nintroduce a second fundamental way measures can be built: they are transported between spaces via functions.",
    "Definition 2.18. Let (Ω, F , P) be a probability space and let X be a random variable from (Ω, F ) to (E, E ).\nThen\n\nQ(A) = P(X −1(A)), A ∈ E ,\n\ndefines a measure on (E, E ), the image measure of P via X, or the pushforward measure. We write Q = P ◦ X −1\nand also call it the law or the distribution of X.\n\nPut differently, to measure a set in E, we transport it back into Ω via X −1 and then measure it there using P.\nIt is a matter of a simple exercise to verify that Q is a measure. This follows since X −1 preserves set operations.",
    "Example 2.19. Let X be a real-valued random variable on a probability space (Ω, F , P). Then P ◦ X −1 is a\nprobability measure on R, the distribution or the law of the variable X, and we often denote it by µX . We have\nµX ((−∞, a]) = P(X ⩽ a) =: FX (a) is the distribution function of X, or of the measure P ◦ X −1. Note that µX is\nthe Lebesgue-Stieltjes measure associated to FX through Theorem 2.16.\n\nLet F be a distribution function on R and µF the Lebesgue-Stieltjes measure associated to F through The-\norem 2.16. Then the identity mapping on (R, B(R), µF ), i.e., X(ω) = ω, is a random variable distributed\naccording to µF . The following example gives another, more canonical, way for such a construction.",
    "Example 2.20. Let F be a distribution function on R. Define its right-continuous inverse F −1(z) = inf{y :\nF(y) > z}, which is also known as the quantile function. Then a random variable X on ([0, 1], B([0, 1]), Leb),\ngiven by X(ω) = F −1(ω) is distributed according to µF , µX = µF .\n\nPage 27\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nTo show this, first note that F −1 is increasing and hence measurable. Then note that\n\n{ω : ω < F(x)} ⊆ {ω : F −1(ω) ⩽ x} ⊆ {ω : ω ⩽ F(x)}\n\nand the outer sets both have the same Leb measure F(x). It thus follows that\n\nFX (x) = Leb(X ⩽ x) = Leb(F −1 ⩽ x) = Leb({ω : F −1(ω) ⩽ x}) = Leb({ω : ω < F(x)}) = F(x).\n\nThis tells us that we can always construct random variables with a given distribution. For two random\nvariables X,Y , defined possibly on different probability spaces, we shall often write X ∼ Y to denote µX = µY ,\ni.e., that X and Y have the same distribution. A lot of properties of random variables will in fact just functions\nof their distribution and not their particular definition.",
    "Example 2.21 (Marginal measure). Consider a probability measure P on a product space from Definition 1.7,\n(Ω, F ) = (∏i∈I Ωi, ×i∈IFi). Let Xi(ω) = ωi, 1 ⩽ i ⩽ d, be random variables given by coordinate projections,\nsee Example 1.20. Then µi := µXi is called the ith marginal measure of µ. Note that µi is a probability measure\non (Ωi, Fi) and\n\nµi(A) = µ (Ω1 × . . . Ωi−1 × A × Ωi+1 × . . . Ωn) , A ∈ Fi.\nNote that µ determines its marginals but that the marginal distributions do not determine µ. Indeed, it is easy\nto construct examples of µ ̸= ν with the same marginals. One way to do this is to use the method of the next\nexample.",
    "Example 2.22 (Joint distribution). Let X,Y be real-valued random variables on a probability space (Ω, F , P).\nThen, by Example 1.20, (X,Y ) is an R2-valued random variable. Its distribution, µ(X,Y ) is called the the joint law\nof X and Y . It is easy to verify (and follows instantly from Lemma 2.23 below) that its marginals are given by\nµX and µY , the distributions of X and Y respectively. However the joint law encodes also how the two variables\nbehave jointly, i.e., their (in)dependence.\n\n(10)\n\nLet us finally note that the operation of taking the image law is transitive.",
    "Lemma 2.23. Let (Ω, F , P) be a probability space, (E, E ) and (G, G ) two measurable spaces and X : Ω → E,\nY : E → G random variables. Then the image measure of µX via Y is the image measure of µ via Y ◦ X.\n\nProof. This is instantly seen with a simple drawing. More formally, we have\n\nµX ◦Y −1(A) = µX (Y −1(A)) = µX ({e ∈ E : Y (e) ∈ A}) = µ(X −1({e ∈ E : Y (e) ∈ A}))\n= µ({ω ∈ Ω : Y (X(ω)) ∈ A}) = µ((Y ◦ X)−1(A)) = µY ◦X (A)\n\nas required.\n\nDeep Dive\n\nLet us comment on some anomalies which may happen when you work with general spaces in relation to",
    "Example 2.22 above. Suppose X1, X2 are two random variables on a probability space (Ω, F , P) with values in\nmeasurable spaces (E1, E1) and (E2, E2) respectively. Then X = (X1, X1) is a random variable on Ω with values\nin the product space (E1 × E2, E1 × E2) (exercise). However, in general, we can not make sense of P(X1 = X2)\nas the diagonal does not need to be in the product σ -algebra and hence the set {ω : X1(ω) = X2(ω)} does not\nhave to measurable.\n\nSuppose now that E1, E2 are metrisable topological space endowed with their Borel σ -algebras. We can\nconsider the product topology on E1 × E2 and take the Borel σ -algebra it generates, denoted B(E1 × E2). If\nfurther both E1, E2 are separable (i.e., have a countable dense subset) then B(E1 × E2) = B(E1) × B(E2) and\neverything works as in the real-valued case. Otherwise however, B(E1 × E2) (which includes the diagonal)\n\nPage 28\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nmay be strictly larger than B(E1) × B(E2) and the joint law of (X1, X2) on (E1 × E2, B(E1 × E2)) may not\nB(R) relied on the fact that an open subset of Rn is a\nexist. Note that our argument for B(Rd) = ×d\ncountable union of open hypercubes which uses separability of R.\n\ni=1\n\n2.5 Product measure\n\nWe saw above how to define new measures via restrictions, summation and images. We now come to taking\nproducts of measure. Recall the product space and the product σ -algebra from Definition 1.7.",
    "Theorem 2.24. Let (Ωi, Fi, Pi), i = 1, . . . , N, be probability measures. Then there exists a unique measure P on\nthe product space (Ω, F ) = (∏N\n\nFi) such that\n\ni=1 Ωi, ×N\ni=1\n\nP(E1 × . . . × EN) = P1(E1) · . . . · PN(EN), Ei ∈ Fi, 1 ⩽ i ⩽ N.\n\n(11)\n\nP is called the product measure and is also denoted (cid:78)\n\ni⩽N\n\nPi or P1 ⊗ . . . ⊗ PN.\n\nProof. We show the statement for N = 2. The general case then follows by induction since a general N product\ncan be see as product of two spaces: Ω1 and Ω2 × . . . × ΩN.\n\nSuppose N = 2. A set in F of the form A × B for A ∈ F1, B ∈ F2 is called a measurable rectangle. These\nsets form a π-system which, by Definition 1.7, generates F . Let A denote the collection of finite unions of\nmutually disjoint measurable rectangles. Then A is an algebra and we can define a set function P on A by\n\nP(A1 × B1 ∪ . . . ∪ An × Bn) :=\n\nn\n∑\ni=1\n\nP1(Ai)P2(Bi), Ai ∈ F1, Bi ∈ F2, Ai × Bi ∩ A j × B j = /0,\n\n1 ⩽ i, j ⩽ n, i ̸= j,\n\nfor n ⩾ 1. Clearly P( /0) = 0 and, by Theorem 2.11, it remains to check that P is countably additive on A . Let\n(Dn)n⩾1 be a sequence of sets in A with Dn ↓ /0. By Lemma 2.4, it suffices to show that limn→∞ P(Dn) = 0.\n\nEach Dn is a finite union of measurable rectangles An,k × Bn,k, 1 ⩽ k ⩽ mn. If An,i ∩ An, j ̸= /0, we may replace\nthese two rectangles by three other rectangles with disjoint first sets, so that with no loss of generality we assume\nAn· are mutually disjoint. For ω1 ∈ Ω1, let Dn(ω1) = {ω2 ∈ Ω2 : (ω1, ω2) ∈ Dn} so that Dn(ω1) = Bn,k if ω1 ∈\nAn,k, for some (and hence only one) 1 ⩽ k ⩽ mn and Dn(ω2) = /0 otherwise. In particular, Dn(ω1) ∈ F2 (this also\nfollows more generally, see Exercise 1.13). Properties of (Dn)n⩾1 imply that Dn(ω1) ↓ /0 for all ω1 ∈ Ω1. Since\nP2 is a probability measure, it follows that if we define a sequence of functions on Ω1 by Xn(ω1) = P2(Dn(ω1)),\nn ⩾ 1, then Xn ↓ 0 pointwise on Ω1. Note also that Xn is a simple function, constant on any of the sets An,k, and\nzero otherwise. In particular, for ε > 0,\n\nn ((ε, ∞)) = {ω1 : Xn(ω1) > ε} = (cid:91)\nX −1\n\nAn,i,\n\nk∈In\n\nfor some subset In ⊆ {1, . . . , mn}. Again, by properties of (Dn)n⩾1, we have X −1\nP1-probability of these sets decreases to zero. This yields\n\nn ((ε, ∞)) ↓ /0 and hence the\n\nP(Dn) =\n\nmn\n∑\nk=1\n\nP1(An,k)P2(Bn,k) ⩽ P1(Xn > ε)P2(Ω2) + εP1(Ω1),\n\nwhere we kept Pi(Ωi) = 1 terms to make it clear how the inequalities were obtained. Taking limit as n → ∞,\ngives limn→∞ P(Dn) ⩽ ε for any ε > 0 and hence limn→∞ P(Dn) = 0 as required.\n\nRemark. Clearly, we could take any finite measures and not only probability measures in the statement of\nthe theorem. Further, through the usual arguments of restricting to subsets, the result also extends to σ -finite\nmeasures.\n\nPage 29\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nRemark. Note that the marginals, in the sense of Example 2.21, of the product measures P are given by Pi and\nthat P is uniquely specified by its marginals via (11). This is a special property of the product measure and is\nnot true for a general measure µ on the product space, as discussed in Examples 2.21 and 2.22.\n\nDeep Dive",
    "Theorem 2.24 extends to countable products and (11) then reads\n\n(cid:32)\n\n(cid:33)\n\nP\n\nE1 × . . . × EN × ∏\nn>N\n\nΩn\n\n= P1(E1) · . . . · PN(EN), ∀N ⩾ 1 and Ei ∈ Fi, 1 ⩽ i ⩽ N.\n\n(12)\n\nRecall Example 1.8 and its notation. We can then assert that there exists P on F which is the product measure\n2 = Pk({T }). We use this opportunity also to give a concrete construction of\nP = ⊗k⩾1Pk, where Pk({H}) = 1\na non-measurable set to show F ⊊ P(Ω). The construction is analogous to the construction of the Vitali set.\nWe define a relation ∼ on Ω by x ∼ y if and only if x and y differ in finitely many flips, i.e. |{k : xk ̸= yk}| < ∞.\nIt is direct to verify ∼ is reflexive, symmetric, and transitive. Assuming the axiom of choice (AC), we are\nable to find a set A ⊂ Ω such that A contains exactly one element from each equivalence class. We prove A\nis not measurable by contradiction. Let P∗ be the outer measure associated to P. As P∗ = P on F , we see\nthat sets in F are P∗-measurable. Note also that if for x1:n = (x1, . . . , xn) ∈ ∏n\nk=1 Ωk, we write the cylinder set\n[x1:n] as\n\n[x1:n] = {ω ∈ Ω : ωk = xk\n\nfor\n\n1 ⩽ k ⩽ n}\n\nthen P([x1:n]) = P∗([x1:n]) = 2−n for all such cylinder sets [x1:n]. By definition, P∗ is invariant under any finite\nflips. Denote the collection of finite flips (including the identity) by T , and {τ(A) : τ ∈ T } gives a countable\npartition of Ω. If we suppose A is P∗-measurable, then τ(A) is P∗-measurable and, in particular,\n\n1 = P∗(Ω) = ∑\n\nτ∈T\n\nP∗(τ(A)).\n\nThis leads to a contradiction since T is countably infinite and P∗(A) = P∗(τ(A)) for any τ ∈ T .\n\nThe construction of non-measurable set is closely related to set theory. In the above example and the Vitali\nset, we both use the axiom of choice (AC). It has been shown that under some weaker version of AC, we still\ncan construct non-measurable set, for example, under Zermelo–Fraenkel set theory (ZF) + Hahn-Banach\ntheorem. On the other hand, assuming ZF only is not enough to show the existence of non-measurable set.\n\nPage 30\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n3\n\nIndependence\n\nThere are two notions which really set probability apart and alive: independence and conditional expectation.\nBoth relate to (degrees of) co-dependence and ways to measure it. We saw a baby example of conditional\nexpectation, namely P(A|σ (B))(·), in §2.2 above. To develop it properly, we will need the theory of integration\nwhich is still ahead of us. However, we already have all the tools to talk about independence.\n\n3.1 Definitions and characterisations\n\nIndependence, or dependence, is all about information. A given piece of information is relevant if it potentially\nchanges the way we see things. If we do not care about it, then we would say this information is independent\nof what we have in mind. As σ -algebras describe the information content for us, the notion of independence is\nbest phrased in terms of them.",
    "Definition 3.1. Let (Ω, F , P) be a probability space and (Gi)i⩽n a finite collection of σ -algebras, Gi ⊆ F for\ni ⩽ n. We say that the σ -algebras (Gi)i⩽n are independent if and only if\n\nP(A1 ∩ . . . ∩ An) = P(A1) · . . . · P(An),\n\nfor any Ai ∈ Gi, i ⩽ n.\n\n(13)\n\nFor an arbitrary collection (Gi)i∈I of sub-σ -algebras of F , we say that these σ -algebras are independent if any\nfinite sub-collection of them is. Note that in (13) we could have Ai = Ω for some indices i and, in particular, a\nsub-collection of independent σ -algebras are also independent. Equally clearly, if (Gi)i∈I are independent and\nHi ⊆ Gi, i ∈ I, are further sub-σ -algebras, then (Hi)i∈I are also independent.",
    "Example 3.2. The trivial σ -algebra {Ω, /0} is independent of any other σ -algebra. Its information content is\nnull. More generally, observe that G is independent of itself if and only if P(A) ∈ {0, 1} for all A ∈ G .\n\nExercise 3.3. Let (Gn)n⩾1 be a sequence of independent σ -algebras. Use continuity of measure from above to\nshow that for any An ∈ Gn, n ⩾ 1,\n\n(cid:33)\n\n(cid:32)\n\nP\n\n(cid:92)\n\nAn\n\nn⩾1\n\nP(An).\n\n= ∏\nn⩾1",
    "Lemma 3.4. Let (Ω, F , P) be a probability space and A1, . . . , An some events in F . Then, their generated\nσ -algebras are independent if and only if\n\n(cid:33)\n\n(cid:32)\n\nP\n\n(cid:92)\n\nAi\n\ni∈J\n\nP(Ai),\n\n= ∏\ni∈J\n\nfor any J ⊆ {1, . . . , n}.\n\nProof. The results follows from Theorem 3.5 below since Ai = {Ai} is a π-system. But it can also be shown by\nhand, which we do for n = 2. One direction is obvious. For the other recall that σ (A) = {Ω, /0, A, Ac} and note\nthat if P(A ∩ B) = P(A)P(B) then\n\nP(A ∩ Bc) = P(A) − P(A ∩ B) = P(A)(1 − P(B)) = P(A)P(Bc)\n\nand the result follows by symmetry.\n\nThe above simple result also follows from the following much more general one: one does not need to verify\n\n(13) for all sets in the σ -algebras but it is enough to verify it for sets in generating π-systems.\n\nPage 31\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales",
    "Theorem 3.5. Let (Ω, F , P) be a probability space, (Gi)i∈I an arbitrary collection of σ -algebras, each gener-\nated by a π-system Ai ⊆ F , i.e., Gi = σ (Ai), i ∈ I. Then (Gi)i∈I are independent if and only if\n\n(cid:33)\n\n(cid:32)\n\nP\n\n(cid:92)\n\nAi\n\ni∈J\n\n= ∏\ni∈J\n\nP(Ai)\n\nfor any Ai ∈ Ai, i ∈ J, for any finite subset J ⊆ I.\n\n(14)\n\nProof. If (Gi)i∈I are independent then, by definition, (14) holds. The reverse implication is a simple application\nof Lemma 1.12 but we give the details nevertheless. Fix a finite subset J ⊂ I and number its elements J =\n{i1, . . . , in}. Let M1 be the set of A ∈ F for which\n\nP(A ∩ A2 ∩ . . . ∩ An) = P(A) · P(A2) · . . . · P(An)\n\nfor any Al ∈ Ail , l = 2, . . . , n.\n\nBy assumption, Ai1 ⊆ M1 and also Ω ∈ M1 by the assumption applied to J1 = J \\ {i1}. For A ⊆ B both in M1,\nwe have\n\nP((B \\ A) ∩ A2 ∩ . . . ∩ An) = P(B ∩ A2 ∩ . . . ∩ An) − P(A ∩ A2 ∩ . . . ∩ An)\n\n= (P(B) − P(A))P(A2) . . . P(An) = P(B \\ A)P(A2) . . . P(An)\n\nso that B \\ A ∈ M1. Finally, for an increasing sequence Bk ∈ M1, Bk ↑ B, continuity from below of P, see",
    "Proposition 2.3, implies that B ∈ M1. We conclude that M1 is a λ -system and hence, by the π-λ systems\nLemma (Lemma 1.12), Gi1 = σ (Ai1) ⊆ M1. We then proceed by induction. We let Mk be the A ∈ F for which\n\nP(A1 ∩ . . . Ak−1 ∩ A ∩ Ak+1 . . . ∩ An) = P(A1) · . . . · P(Ak−1) · P(A) · P(Ak+1) · . . . · P(An),\n\nfor any Al ∈ Gil , 1 ⩽ l < k and Al ∈ Ail , k < l ⩽ n. Then, by induction step, Aik ⊆ Mk and, as above, π-λ\nsystems lemma gives Gik ⊆ Mk.\n\nAn immediate corollary of the above is that if we have many independent channels of information, then\n\nmerging disjoint sub-groups of them, still gives us independent channels of information.",
    "Corollary 3.6. Let (Ω, F , P) be a probability space and (Gi)i∈I a collection of independent σ -algebras. Suppose\nthat I j ⊆ I, j ∈ J are all pairwise disjoint. Then (σ (Gi : i ∈ I j) : j ∈ J) are independent σ -algebras.\n\nProof. Let H j = σ (Gi : i ∈ I j) and\n\nA j =\n\n(cid:40)\n\n(cid:92)\n\ni∈K\n\nAi : Ai ∈ Gi, i ∈ K, for some K a finite subset of I j\n\n(cid:41)\n\nbe the collection of finite intersection of sets from Gi, i ∈ I j. Note that A j is a π-system and σ (A j) = H j.\nNote also that a finite subset of I j is, in particular, a finite subset of I and hence, by the assumed independence,\nprobability of a set in A j factorises as in (13). Now let L be a finite subset of J and consider sets Bl ∈ Al, l ∈ L.\nEach of these sets is itself an intersection of sets, i.e., Bl = (cid:84)\ni ∈ Gi.\nAs all Kl, l ∈ L, are disjoint, we obtain\n\ni, where Kl is a finite subset of Il and Al\n\ni∈Kl Al\n\n(cid:33)\n\n(cid:32)\n\nP\n\n(cid:92)\n\nBl\n\n= P\n\n\n\n\n\n(cid:92)\n\nAl\ni\n\nl∈L\n\nl∈L,i∈Kl\n\n\n = ∏\n\nl∈L,i∈Kl\n\nP(Al\n\ni) = ∏\nl∈L\n\n∏\ni∈Kl\n\nP(Al\n\ni) = ∏\nl∈L\n\nP\n\n(cid:32)\n\n(cid:33)\n\n(cid:92)\n\nAl\ni\n\ni∈Kl\n\nP (Bl) ,\n\n= ∏\nl∈L\n\nwhere we used independence of Gi, i ∈ I and (13) for the second equality, and we used independence of Gi, i ∈ Il\nseparately for each l ∈ L to obtain the fourth equality. The claim now follows by Theorem 3.5.\n\nPage 32\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales",
    "Definition 3.7. Let (Ω, F , P) be a probability space and (Xi)i∈I a family of random variables with values in some\nmeasurable spaces (Ei, Ei)i∈I. We say that these random variables are independent if their generated σ -algebras\n(σ (Xi))i∈I are.\n\nIt follows by the definition that (Xi)i∈I are independent if and only if for any finite subset J ⊆ I\n\nP(Xi ∈ Ai for all i ∈ J) = ∏\n\ni∈J\n\nP(Xi ∈ Ai),\n\nfor any Ai ∈ Ei, i ∈ J.\n\nThis can be further rephrased using the nomenclature of product measures.",
    "Theorem 3.8. Let (Ω, F , P) be a probability space and (Xi)i⩽n a finite family of random variables with values\nin some measurable spaces (Ei, Ei)i⩽n. These random variables are independent in and only if their joint dis-\ntribution µ(X1,...,Xn) on the product space (∏i⩽n Ei, ×i⩽nEi) is the product measure of the marginal distributions\nµXi.\n\nThe above statement extends to an arbitrary family of random variables as independence is defined by con-\nsidering finite subsets of variables. Note that this theorem generalises the results you learned in Prelims and\nPart A for discrete/continuous random variables – two continuous random variables X and Y are independent if\nand only if their joint density function can be written as the product of the density function of X and the density\nfunction of Y . The existence of product spaces in Theorem 2.24 tells us that, given Borel probability measures\nµ1, µ2, . . . , µn on R, there is a probability space on which there are independent random variables X1, X2, . . . , Xn\nwith µXi = µi. In particular, the notion of independence is non-vacuous.\n\nChecking independence of random variables from Definition 3.7 or Theorem 3.8 might be difficult. However,\n\nwhen combined with Theorem 3.5, it becomes more manageable! We have the following immediate corollary.",
    "Corollary 3.9. A sequence (Xn)n⩾1 of real-valued random variables on (Ω, F , P) is independent iff for all n ⩾ 1\nand all x1, . . . xn ∈ R (or R),\n\nP(X1 ⩽ x1, . . . , Xn ⩽ xn) = P(X1 ⩽ x1) . . . P(Xn ⩽ xn).",
    "Example 3.10. Recall our coin tossing representation in Example 1.22, namely on ([0, 1], B([0, 1])) we let\nXn(ω) = 1⌊2nω⌋ is even, n ⩾ 1, where 0 is even. We can now check that (Xn)n⩾1 are independent (exercise!). This\nshows that we built a good model, as different coin tosses ought to be independent, and also that the notion of\nindependence is interesting (and non-vacuous as already observed).\n\nAs independence is about information, the following Proposition is obvious from Definition 3.7 and since if\n\nY = f (X) then σ (Y ) ⊆ σ (X).",
    "Proposition 3.11. Let (Ω, F , P) be a probability space and (Xi)i∈I a family of independent random variables\nwith values in some measurable spaces (Ei, Ei)i∈I and fi : Ei → R be measurable, i ∈ I. Then (Yi := fi(Xi))i∈I\nare independent random variables.\n\nDeep Dive\n\nAs note before, Theorem 2.24 extends to countable products and (11) then changes to (12). This is important\nas it offers a canonical way to build a sequence of independent random variables with given distributions.\nIndeed, consider (Ωi, Fi, Pi) = ([0, 1], B([0, 1]), Leb). On the product space define Xi(ω) = ωi, where Ω ∋\nω = (ωi)i⩾1. Then (Xi)i⩾1 is a sequence of independent identically distributed random variables on the\nproduct probability space, each Xi is uniform on [0, 1]. Given any sequence (µi)i⩾1 of probability measures\non R we let (Fi)i⩾1 be their respective distribution functions and, as in Example 2.20, we set Yi = F −1\n(Xi).\n\ni\n\nPage 33\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nThen each Yi ∼ µi and, by Proposition 3.11, all (Yi)i⩾1 are independent.\n\n3.2 Kolmogorov’s 0-1 Law\n\nWe have now the tools to present a beautiful classical result in probability theory concerning ‘tail events’ asso-\nciated to sequences of independent random variables.",
    "Definition 3.12 (Tail σ -algebra). For a sequence of random variables (Xn)n⩾1 define\n\nand\n\nTn = σ (Xn+1, Xn+2 . . .)\n\nT =\n\n∞\n(cid:92)\n\nn=1\n\nTn.\n\nThen T is called the tail σ -algebra of the sequence (Xn)n⩾1.\nExercise 3.13. Check that T is a σ -algebra.\n\nRoughly speaking, any event A such that (a) whether A holds is determined by the sequence (Xn) but (b)\nchanging finitely many of these values does not affect whether A holds is in the tail σ -algebra. These conditions\nmay sound impossible at first, but in fact many events involving limits have these properties. For example, it is\neasy to check that A = {(Xn) converges} is a tail event: just check that A ∈ Tn for each n.",
    "Theorem 3.14 (Kolmogorov’s 0-1 Law). Let (Xn)n⩾1 be a sequence of independent random variables. Then the\ntail σ -algebra T of (Xn)n⩾1 contains only events of probability 0 or 1. Moreover, any T -measurable random\nvariable is almost surely constant.\nProof. Fix n ⩾ 1 and let Fn = σ (X1, . . . , Xn). Note that Fn is generated by the π-system of events\n\nA = (cid:8){X1 ⩽ x1, . . . , Xn ⩽ xn} : x1, . . . , xn ∈ R(cid:9)\n\nand Tn is generated by the π-system of events\n\nB = (cid:8){Xn+1 ⩽ xn+1, . . . , Xn+k ⩽ xn+k} : k ⩾ 1, xn+1, . . . , xn+k ∈ R(cid:9) .\n\nFor any A ∈ A , B ∈ B, by the independence of the random variables (Xn), we have\n\nP(A ∩ B) = P(A)P(B)\nand so by Theorem 3.5 the σ -algebras σ (A ) = Fn and σ (B) = Tn are also independent. Note also that this\nstatement follows directly from Corollary 3.6. Since T ⊆ Tn we conclude that Fn and T are also independent.\nFn is a\nn⩾1\nπ-system (although not in general a σ -algebra) generating the σ -algebra F∞ = σ ((Xn)n⩾1). So applying Theo-\nrem 3.5 again we see that F∞ and T are independent. But T ⊆ F∞ so that if A ∈ T\n\nThe above was true for all n ⩾ 1 and hence (cid:83)\n\nFn and T are also independent. Now (cid:83)\n\nn⩾1\n\nP(A) = P(A ∩ A) = P(A)2\n\nand so P(A) = 0 or P(A) = 1.\n\nNow suppose that Y is any (real-valued) T -measurable random variable. Then its distribution function\nFY (y) = P(Y ⩽ y) is increasing, right continuous and takes only values in {0, 1} since {Y ⩽ y} ∈ T . So P(Y =\nc) = 1 where c = inf{y : FY (y) = 1}. This extends easily to the extended-real-valued case.",
    "Example 3.15. Let (Xn)n⩾1 be a sequence of independent, identically distributed (i.i.d.) random variables and let\nSn = ∑n\nk=1 Xk. Consider U = lim supn→∞ Sn/n and L = lim infn→∞ Sn/n. Then U and L are tail random variables\nand so almost surely constant. We’ll prove later in the course that, L = U is the expectation of X1, a result known\nas the Strong Law of Large Numbers.\n\nPage 34\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n3.3 The Borel–Cantelli Lemmas\n\nWe turn now to second fundamental set of results which assert that certain events have probability one or zero.\nWe work on a fixed probability space (Ω, F , P).",
    "Definition 3.16. Let (An)n⩾1 be a sequence of sets from F . We define\n\nlim sup\nn→∞\n\nAn =\n\n∞\n(cid:92)\n\n(cid:91)\n\nn=1\n\nm⩾n\n\nAm\n\n= {ω ∈ Ω : ω ∈ Am for infinitely many m}\n= {An occurs infinitely often}\n= {An i.o.}\n\nand\n\nlim inf\nn→∞\n\nAn =\n\n∞\n(cid:91)\n\n(cid:92)\n\nn=1\n\nm⩾n\n\nAm\n\n= {ω ∈ Ω : ∃m0(ω) such that ω ∈ Am for all m ⩾ m0(ω)}\n= {An eventually}\n= {Ac\n\nn infinitely often}c.",
    "Lemma 3.17.\n\n1lim supn→∞ An = lim sup\nn→∞\n\n1An,\n\n1lim infn→∞ An = lim inf\nn→∞\n\n1An.\n\nProof. Note that 1(cid:83)\n\nn An = supn 1An and 1(cid:84)\n\nn An = infn 1An, and apply these twice.",
    "Lemma 3.18 (Fatou and Reverse Fatou for sets). Let (An)n⩾1 be a sequence of sets from F . Then\n\nP(lim inf\nn→∞\n\nAn) ⩽ lim inf\nn→∞\n\nP(An) and P(lim sup\nn→∞\n\nAn) ⩾ lim sup\nn→∞\n\nP(An).\n\nProof. Using continuity of P from above and below, see Proposition 2.3, we have\n\nP(An eventually) = lim\nn→∞\n\nP\n\n(cid:32)\n\n(cid:33)\n\n(cid:92)\n\nAm\n\nm⩾n\n\n⩽ lim\nn→∞\n\ninf\nm⩾n\n\nP(Am) = lim inf\nn→∞\n\nP(An)\n\nand hence (taking complements)\n\nP(An i.o.) ⩾ lim sup\nn→∞\n\nP(An).\n\nIn fact we can say more about the probabilities of these events.",
    "Lemma 3.19 (The First Borel–Cantelli Lemma, BC1). If ∑∞\n\nn=1\n\nP(An) < ∞ then P(An i.o.) = 0.\n\nRemark. Notice that we are making no assumptions about independence here. This is a very powerful result\nwhich we will use time and again.\n\nPage 35\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nProof. Let Gn = (cid:83)\n\nm⩾n Am. Then\n\nP(Gn) ⩽\n\n∞\n∑\nm=n\n\nP(Am)\n\nand Gn ↓ G = lim supn→∞ An, so by Proposition 2.3, P(Gn) ↓ P(G).\n\nSince ∑∞\n\nn=1\n\nP(An) < ∞, we have that\n\nand so\n\nas required.\n\n∞\n∑\nm=n\n\nP(Am) → 0\n\nas n → ∞,\n\nP\n\n(cid:18)\n\n(cid:19)\n\nlim sup\nn→∞\n\nAn\n\n= lim\nn→∞\n\nP(Gn) = 0\n\nA partial converse to BC1 is provided by the second Borel–Cantelli Lemma, but note that we must now\n\nassume that the events are independent.",
    "Lemma 3.20 (The Second Borel–Cantelli Lemma, BC2). Let (An) be a sequence of independent events. If\n∑∞\n\nP(An) = ∞ then P(An i.o.) = 1.\n\nn=1\n\nProof. Set am = P(Am) and note that 1 − a ⩽ e−a. We consider the complementary event {Ac\n\nn eventually}.\n\n(cid:34)\n\nP\n\n(cid:92)\n\nm⩾n\n\n(cid:35)\n\nAc\nm\n\n= ∏\nm⩾n\n\n(1 − am)\n\n(by independence, recall Exercise 3.3)\n\n(cid:18)\n\n⩽ exp\n\n− ∑\nm⩾n\n\n(cid:19)\n\nam\n\n= 0.\n\nHence\n\nand\n\nP (Ac\n\nn eventually) = P\n\n(cid:32)\n\n(cid:91)\n\n(cid:92)\n\nn⩾1\n\nm⩾n\n\n(cid:33)\n\nAc\nm\n\nP\n\n= lim\nn→∞\n\n(cid:33)\n\nAc\nm\n\n= 0,\n\n(cid:32)\n\n(cid:92)\n\nm⩾n\n\nP(An i.o.) = 1 − P(Ac\n\nn eventually) = 1.\n\nExercise 3.21. A monkey is provided with a typewriter. At each time step it has probability 1/26 of typing any\nof the 26 letters independently of other times. What is the probability that it will type ABRACADABRA at least\nonce? infinitely often?\nSolution. We can consider the events\n\nAk = {ABRACADABRA is typed between times 11k + 1 and 11(k + 1)}\n\nfor each k. The events are independent and P[Ak] = (1/26)11 > 0. So ∑∞\nprobability 1, Ak happens infinitely often.\n\nk=1\n\nP[Ak] = ∞. Thus BC2 says that with\n\nLater in the course, with the help of a suitable martingale, we’ll be able to work out how long we must wait,\n\non average, before we see patterns appearing in the outcomes of a series of independent experiments.\n\nWe’ll see many applications of BC1 and BC2 in what follows. Before developing more machinery, here is\n\none more.\n\nPage 36\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nExercise 3.22. Let (Xn)n⩾1 be independent exponentially distributed random variables with parameter 1 and let\nMn = max{X1, . . . , Xn}. Then\n\n(cid:18)\n\nP\n\nlim\nn→∞\n\nMn\nlog n\n\n(cid:19)\n\n= 1\n\n= 1.\n\nSolution. First recall that if X is an exponential random variable with parameter 1 then\n\nP(X ⩽ x) =\n\n(cid:26)\n\n0\n1 − e−x\n\nx < 0,\nx ⩾ 0.\n\nFix 0 < ε < 1. Then\n\nP(Mn ⩽ (1 − ε) log n) = P\n\n(cid:32) n\n(cid:92)\n\n{Xi ⩽ (1 − ε) log n}\n\n(cid:33)\n\ni=1\n\nP (Xi ⩽ (1 − ε) log n)\n\n(independence)\n\nn\n∏\ni=1\n(cid:18)\n\n=\n\n=\n\n1 −\n\n(cid:19)n\n\n1\nn1−ε\n\n⩽ exp(−nε ).\n\nThus\n\nand so by BC1\n\n∞\n∑\nn=1\n\nP(Mn ⩽ (1 − ε) log n) < ∞\n\nP(Mn ⩽ (1 − ε) log n i.o.) = 0.\n\nSince ε was arbitrary, taking a suitable countable union gives\n\nP\n\n(cid:18)\n\nlim inf\nn→∞\n\nMn\nlog n\n\n(cid:19)\n\n< 1\n\n= 0.\n\nThe reverse bound is similar: use BC1 to show that\n\nP (Mn ⩾ (1 + ε) log n i.o.) = P (Xn ⩾ (1 + ε) log n i.o.) = 0.\n\nAt first sight, it might look as though BC1 and BC2 are not very powerful - they tell us when certain events\nhave probability zero or one. But for many applications, in particular when the events are independent, many\ninteresting events can only have probability zero or one, because they are tail events.\n\nPage 37\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n4\n\nIntegration\n\nIn Part A Integration, you saw a theory of integration based on Lebesgue measure. It is natural to ask whether\nwe can develop an analogous theory for other measures. The answer is ‘yes’, and in fact almost all the work was\ndone in Part A; the proofs used there carry over to any measure. It is left as a (useful) exercise to check that.\nHere we just state the key definitions and results.\n\n4.1 Definition and first properties\n\nLet (Ω, F , µ) be a measure space. Given a measurable function f : Ω → R, we want to define, where possible,\nthe integral of f with respect to µ. There are many variants of the notation, such as:\n\n(cid:90)\n\nf dµ =\n\n(cid:90)\n\nΩ\n\nf dµ = µ( f ) =\n\n(cid:90)\n\nω∈Ω\n\nf (ω)dµ(ω) =\n\n(cid:90)\n\nf (ω)µ(dω)\n\nand so on. The dummy variable (here ω) is sometimes needed when, for example, we have a function f (ω, x)\nof two variables, and with x fixed are integrating the function f (·, x) given by ω (cid:55)→ f (ω, x).",
    "Definition 4.1. If f is a non-negative simple function with canonical form (6), then we define the integral of f\nwith respect to µ as\n\n(cid:90)\n\nf dµ =\n\nakµ(Ek).\n\nn\n∑\nk=1\n\nThis formula then also applies (exercise) whenever f is as in (6), even if this is not the canonical form, as\n\nlong as we avoid ∞ − ∞ (for example by taking ak ⩾ 0).",
    "Definition 4.2. For a non-negative measurable function f on (Ω, F , µ) we define the integral\n\n(cid:90)\n\nf dµ = sup\n\n(cid:26)(cid:90)\n\ngdµ : g simple, 0 ⩽ g ⩽ f\n\n(cid:27)\n\n.\n\nNote that the supremum may be equal to +∞. Recall from Lemma 1.26 that measurability of f is equivalent\nwith f being an increasing limit of simple function. The above definition and this notion of integral can not\nbe extended to non-measurable functions in any meaningful way. Indeed, we know well by now that we can\nnot measure - that is integrate the indicator function - some non-measurable sets! We recall also that one can\nuse a canonical construction to approximate f , see the proof of Lemma 1.26, and the above supremum may be\nreplaced with a limit along such an approximating sequence of simple functions – this is easy to check directly\n(exercise!) but it will also follow from the more general Theorem 4.6.\n\nRecall that in Riemann integration we needed to approximate the integral from above and from below. This\nwas necessary not only to define the integral but foremost to define the class of Riemann integrable functions,\ni.e., the ones where the lower and upper approximations coincide. There was no other stand alone way to define\nIn contrast, our new way of integrating works for all measurable non-negative functions and we\nthis class.\nsimply define the integral as the limit of its lower approximations. Most importantly, we can integrate against\narbitrary measures over a measurable space. Riemann integration relied on partitioning the state space, and hence\nworked on R. Our integration instead, borrowing from Lebesgue’s construction, through simple functions, in\neffect relies on partitioning the target space, so works for real-valued functions but which can be defined on an\narbitrary measure space.\n\nOne obvious consequence of the above definition is worth pointing out: if 0 ⩽ f ⩽ g are two measurable\nfunctions then (cid:82) f dµ ⩽ (cid:82) gdµ. This is a monotonicity property, also referred to as the comparison test or\ncomparison principle. Another obvious property is that if µ({ f = +∞}) > 0 then (cid:82) f dµ = +∞.\n\nPage 38\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales",
    "Definition 4.3. We say that a function f on (Ω, F , µ) is integrable, and write f ∈ L 1(Ω, F , µ), if f is mea-\nsurable and (cid:82) | f |dµ < ∞. If f is integrable, its integral is defined to be\n\n(cid:90)\n\nf dµ =\n\n(cid:90)\n\n(cid:90)\n\nf + dµ −\n\nf − dµ,\n\nwhere f + = max( f , 0) and f − = max(− f , 0) are the positive and negative parts of f .\n\nA very important point is that if f is measurable, then (cid:82) f dµ is defined either if f is non-negative (when\n∞ is a possible value) or if f is integrable. Clearly, by comparison, if f is measurable and | f | ⩽ g for some\ng ∈ L 1(Ω, F , µ) then f ∈ L 1(Ω, F , µ). Note that f = f + − f − and | f | = f + + f − so that another important\nconsequence of the above definition is the familiar inequality:\n\n(cid:12)\n(cid:90)\n(cid:12)\n(cid:12)\n(cid:12)\n\nf dµ\n\n(cid:90)\n\n⩽\n\n(cid:12)\n(cid:12)\n(cid:12)\n(cid:12)\n\n| f |dµ.\n\n(15)\n\nWe have defined integrals only over the whole space. This is all we need – if f is a measurable function on\n(Ω, F , µ) and A ∈ F then we define\n\n(cid:90)\n\n(cid:90)\n\nf dµ =\n\nf 1A dµ,\n\nA\ni.e., we integrate (over the whole space) the function that agrees with f on A and is 0 outside A.",
    "Example 4.4. If µ is the Lebesgue measure on (R, B(R)), then we have just redefined the Lebesgue integral as\nin Part A.",
    "Example 4.5. Suppose that µ is a discrete measure with mass pi at point xi ∈ R, for a (finite or countably\ninfinite) sequence x1, x2, . . .. Then you can check that\n\n(cid:90)\n\nf dµ = ∑\ni\n\nf (xi)pi,\n\nwhenever f ⩾ 0 (where +∞ is allowed as the answer) or the sum converges absolutely. This example is very\ndifferent in nature to the Lebesgue integral above – here integrals are just sums. It is rather pleasing to see that\nthe toolbox we developed covers both cases with a unified language.\n\nOur construction of the integral followed the steps seen in Part A Integration course. Importantly for us, our\n\ngeneralised integral still has all the good properties.",
    "Theorem 4.6 (Monotone Convergence Theorem (MCT)). Let ( fn) be a sequence of non-negative measurable\nfunctions on (Ω, F , µ). Then\n\n(cid:90)\n\n(cid:90)\n\nfn ↑ f =⇒\n\nfn dµ ↑\n\nf dµ.\n\nNote that we are not excluding (cid:82) f dµ = ∞ here. Also, it is easy to see that it is enough to suppose that fn ↑ f\nµ-almost everywhere. An equivalent formulation of the Monotone Convergence Theorem (MCT) considers\npartial sums: if ( fn) is a sequence of non-negative measurable functions, then\n\n(cid:90) ∞\n∑\nn=1\n\nfn dµ =\n\n(cid:90)\n\n∞\n∑\nn=1\n\nfn dµ.\n\nProof. Note that the MCT for fn = 1An is simply the continuity of µ from below, Proposition 2.3 (iv). The\ngeneral case is deduced from this, see Part A Integration.\n\nPage 39\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nThe MCT is a key result from which the rest of the integration theory essentially follows using the ‘bare\nhands method’ outlined in the comments following Lemma 1.26: start by considering indicator functions f = 1E,\nthen simple functions f , then non-negative measurable f via Lemma 1.26 and the MCT, and finally general\nmeasurable f via f = f + − f −. For this reason, MCT is stated here and not in the subsequent section, even if it\nwould also fit there by the virtue of its name.\n\nExercise 4.7. As a simple warmup exercise, show that if f and g are measurable functions on (Ω, F , µ) that are\neither both non-negative or both integrable, and c ∈ R, then\n\n(cid:90)\n\n( f + g)dµ =\n\n(cid:90)\n\n(cid:90)\n\nf dµ +\n\ng dµ,\n\n(cid:90)\n\nc f dµ = c\n\n(cid:90)\n\nf dµ.\n\nExercise 4.8. Use MCT to prove Lemma 3.19.\n\nP(Ak). Since Nn ↑ N = N∞, by MCT, we have (cid:82) N dP = ∑k⩾1\n\nk=1 1Ak , the (random) number of events Ak that hold for k ⩽ n. Then (cid:82) Nn dP =\nP[Ak] < ∞. But (cid:82) N dP < ∞ implies P(N =\n\nSolution. Consider Nn := ∑n\n∑n\n∞) = 0, as required.\n\nk=1\n\n4.2 Radon-Nikodym Theorem\n\nThe just defined integral offers a canonical way to construct new measures on a given measure space. This was\nfirst presented below Theorem 2.16 but can now be made rigorous.\n\nSuppose that (Ω, F , µ) is a measure space and f a positive integrable function. Then\n\nF ∋ A −→ ν(A) :=\n\n(cid:90)\n\nf dµ =\n\n(cid:90)\n\nA\n\nf (ω)1A(ω)µ(dω)\n\n(16)\n\ndefines a measure. This is easy to verify for a simple function f and follows in general by the MCT (exercise).\nNote that by definition if A is µ-null then it is also ν-null. We recall the terminology and notation of Definition\n2.7 and write ν ≪ µ.\n\nA particularly important special case is when (cid:82) f dµ = 1 so that ν is a probability measure. This is well\nknown to you under the heading of continuous random variables for Prelims or Part A probability. Take\n(Ω, F , µ) = (R, B(R), Leb) and let F(x) = (cid:82) x\n−∞ f (y)dy. Then ν((−∞, x]) = F(x) so that, by Theorem 2.10,\nν = µF is the Lebesgue-Stieltjes measure associated to F by Theorem 2.16. The function F(x) is the distribu-\ntion function corresponding to the probability measure ν.\n\nThe following fundamental result tells us that the above construction describes all measures ν absolutely\ncontinuous w.r.t. µ, ν ≪ µ. We state it for probability measures. An extension to finite measures is immediate\nand extension to σ -finite measures follows via the usual steps.",
    "Theorem 4.9 (Radon-Nikodym Theorem). Let µ, ν be two probability measures on a measurable space (Ω, F ).\nThen ν ≪ µ if and only if there exists a non-negative random variable f such that\n\nν(A) =\n\n(cid:90)\n\nA\n\nf dµ, A ∈ F .\n\nThe function f is often denoted dν\nFurther, ν ∼ µ if and only if f > 0 µ-a.s. (and then also ν-a.s.) in which case dµ\n\ndµ and is called the Radon-Nikodym derivative of ν w.r.t. µ.\n\ndν = 1\nf .\n\nExercise 4.10. Recall discrete measure theory on a countable Ω as presented in Example 2.9. Prove Theorem\n4.9 in this setting.\n\nPage 40\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nDeep Dive\n\nThe general proof of the Radon-Nikodym theorem is no joking matter. We will prove this result but only\nmuch later in the course once we have established a good understanding of martingale convergence. The\nRadon-Nikodym Theorem is often used to show existence of the conditional expectation so that the whole\nenterprise may then appear circular. Here, we follow a different path and do not use Theorem 4.9 to establish\nthe existence of conditional expectations so there is no appearance of circularity. However, one could also\nabstain from showing existence of the conditional expectation. Instead, one could use its defining properties\nto define when a family of random variables is a martingale and carry out the whole enterprise this way.\nCulminate with proving Theorem 4.9 and go back to existence of the basic objects on their own. A motivated\nreader is invited to follow through the different logical pathwise to a complete theory.\n\n4.3 Convergence Theorems\n\nThe following theorems were proved in Part A for the Lebesgue integral. The proofs essentially rely on the\nMCT and carry over to the more general integral defined here. We start with the functional versions of Lemma\n3.18.",
    "Theorem 4.11 (Fatou’s Lemma). Let ( fn) be a sequence of non-negative measurable functions on (Ω, F , µ).\nThen\n\n(cid:90)\n\nlim inf\nn→∞\n\nfn dµ ⩽ lim inf\nn→∞\n\n(cid:90)\n\nfn dµ.\n\nProof. We write lim inf fn for lim infn→∞ fn. Recall that\n\nlim inf fn = lim\nk→∞\n\ngk,\n\ngk = inf\nn⩾k\n\nfn.\n\nIn particular, for n ⩾ k, fn ⩾ gk and hence also (cid:82) fn dµ ⩾ (cid:82) gk dµ. As this holds for all n ⩾ k, we have\n\n(cid:90)\n\ngk dµ ⩽ inf\nn⩾k\n\n(cid:90)\n\nfn dµ.\n\nSince gk ↑ lim inf fn, as k → ∞, we apply MCT to obtain the desired inequality:\n\n(cid:90)\n\nlim inf fn dµ = lim\nk→∞\n\n(cid:90)\n\ngk dµ ⩽ lim\nk→∞\n\ninf\nn⩾k\n\n(cid:90)\n\nfn dµ = lim inf\nn→∞\n\n(cid:90)\n\nfn dµ.",
    "Lemma 4.12 (Reverse Fatou’s Lemma). Let ( fn) be a sequence of non-negative measurable functions on\n(Ω, F , µ). Assume that there exists a function g ∈ L 1(Ω, F , µ) such that fn ⩽ g for all n. Then\n\nProof. Apply Fatou to hn = g − fn. (Note that (cid:82) gdµ < ∞ is needed.)\n\n(cid:90)\n\nlim sup\nn→∞\n\nfn dµ ⩾ lim sup\nn→∞\n\n(cid:90)\n\nfn dµ.\n\nThe above lemmas gave us inequalities between limits of integrals and the integral of the limit. In most\ncases however, we are interested in having an equality. This is the subject of the following results. They are all\nwell known and very useful. At the same time however, from a probabilistic point of view, they are not fully\nsatisfactory. We will develop in §5.4 below a finer tool to deal with the issue of convergence of integrals, namely\nthe notion of uniform integrability.\n\nWe recall that ( fn) converges pointwise to f if, for every x ∈ Ω, we have fn(x) → f (x) as n → ∞.\n\nPage 41\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales",
    "Theorem 4.13 (Dominated Convergence Theorem (DCT)). Let ( fn) be a sequence of measurable functions on\n(Ω, F , µ) with fn → f pointwise. Suppose that for some integrable function g, | fn| ⩽ g for all n. Then f is\nintegrable and\n\n(cid:90)\n\n(cid:90)\n\nfn dµ →\n\nf dµ as n → ∞.\n\nProof. Taking limits we have 0 ⩽ | f | ⩽ g so that f ∈ L 1(Ω, F , µ) by comparison. Using (15) and applying",
    "Lemma 4.12 to hn = | fn − f | ⩽ 2g, we obtain\n\n0 ⩽ lim sup\n\nn→∞\n\n(cid:12)\n(cid:90)\n(cid:12)\n(cid:12)\n(cid:12)\n\nfn dµ −\n\n(cid:90)\n\nf dµ\n\n(cid:12)\n(cid:12)\n(cid:12)\n(cid:12)\n\n(cid:90)\n\n⩽ lim sup\nn→∞\n\n| fn − f |dµ ⩽\n\n(cid:90)\n\nlim sup\nn→∞\n\n| fn − f |dµ =\n\n(cid:90)\n\n0dµ = 0.",
    "Lemma 4.14 (Scheff´e). Suppose that fn, f ∈ L 1(Ω, F , µ) converge pointwise, fn → f as n → ∞. Then\n\n(cid:90)\n\n| fn − f |dµ → 0 ⇐⇒\n\n(cid:90)\n\n| fn|dµ →\n\n(cid:90)\n\n| f |dµ.\n\nDeep Dive\n\nProof. The “=⇒” implication is trivial since −| fn − f | ⩽ | fn|−| f | ⩽ | fn − f | so we show the reverse. Suppose\nfirst that fn, f are positive and (cid:82) fn dµ → (cid:82) f dµ. Since ( fn − f )− ⩽ f , DCT gives (cid:82) ( fn − f )− dµ → 0. For\nthe positive part, we have\n\n(cid:90)\n\n( fn − f )+ dµ =\n\n(cid:90)\n\nfn⩾ f\n\n( fn − f )dµ =\n\n(cid:90)\n\nfn dµ −\n\n(cid:90)\n\n(cid:90)\n\nf dµ −\n\n( fn − f )dµ.\n\nfn< f\n\nThe first term converges to the second by assumption and the last one coverges to zero by the previous\nargument. Together, we obtain the desired convergence (cid:82) | fn − f |dµ → 0.\n\nIn the general case, we have (cid:82) f ± dµ ⩽ lim inf (cid:82) f ±\n\nn dµ by Fatou. By assumption,\n\n(cid:90)\n\n( f + + f −)dµ = lim\n\n(cid:90)\n\n( f +\n\nn + f −\n\nn )dµ\n\nso that necessarily the sequences f +\nso the proof above applies and we conclude using | fn − f | ⩽ | f +\n\nn → f − satisfy the assumption of the Lemma and are positive\nn − f −|.\n\nn → f + and f −\n\nn − f +| + | f −\n\n4.4 Expectation\n\nThe notion of image measure developed in §2.4 allows us to see the integral of a function against a measure on\none space simply as the integral against the image measure on the image space. We phrase this as a theorem\nsince it is a key result for a lot of computations one has to do.",
    "Theorem 4.15. Let (Ω, F , P) be a probability measure, X a random variable with values in a measurable space\n(E, E ) and g a real-valued random variable on (E, E ). Let Q = P ◦ X −1 be the image of P via X. Then g is\nQ-integrable if and only if g ◦ X is P-integrable and then\n\n(cid:90)\n\nE\n\ng(x)Q(dx) =\n\n(cid:90)\n\nΩ\n\ng(X(ω))P(dω).\n\n(17)\n\nPage 42\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nProof. (17) holds by definition for g = 1A an indicator of an event A ∈ E . By linearity it then holds for any\nsimple function g. For a measurable g ⩾ 0, let gn ↑ g be a sequence of simple functions increasing to g, say\ngn = ∑k⩽mn ak1Ak and note that\n\ngn(X(ω)) = ∑\nk⩽mn\n\nak1X(ω)∈Ak = ∑\nk⩽mn\n\nak1X −1(Ak)(ω)\n\nare simple functions on Ω, gn ◦ X ↑ g ◦ X. MCT then gives the required equality for g with one integral being\nfinite if and only if the other is. The general case follows with g = g+ − g− and in particular g is Q-integrable if\nand only if g ◦ X is P-integrable.\n\nIn the reminder of this section, X denotes a random variable defined on a probability space (Ω, F , P). We\n\noften refer to the integral on Ω with respect to P as the expectation.",
    "Definition 4.16 (Expectation). We say that X admits a first moment, if X is integrable, i.e., X ∈ L 1(Ω, F , P)\nor\n\nE[|X|] =\n\n|X(ω)|P(dω) < ∞.\n\n(cid:90)\n\nΩ\n\nThe expectation of a random variable X defined on a probability space (Ω, F , P) is\n\n(cid:90)\n\nE[X] =\n\nX dP =\n\n(cid:90)\n\nΩ\n\nX(ω)P(dω).\n\nNote that this is well defined and finite if E[|X|] < ∞ but otherwise may be either +∞ or undefined.\n\nRecall that µX = P ◦ X −1 denotes the distribution of X. A simple application of Theorem 4.15, with g(x) = x,\n\ngives\n\nE[X] =\n\n(cid:90)\n\nΩ\n\nX(ω)P(dω) =\n\n(cid:90)\n\nR\n\nxµX (dx).\n\nIn other words, the expectation of X is simply the barycentre of its distribution. As one expects from the\nbarycentre, it is the optimal prediction of X using a constant as the following makes precise.\n\nExercise 4.17. For X ∈ L 2(Ω, F , P) show that\n\nE[(X − c)2]\n\ninf\nc∈R\n\nis attained by c = E[X]. We say that E[X] is the best constant mean square approximation of X.\n\nClearly, E[X] is a property of the distribution of X in the sense that two random variables X,Y , possi-\nbly defined on different probability spaces, with X ∼ Y , have the same expectation. More generally, we have\nE[g(X)] = (cid:82) g(x)µX (dx) which is thus determined by µX alone, which in turn is determined by its values on a\nπ-system: µX ((−∞, x]) = µ(X ⩽ x), x ∈ R. Very often in applications we suppress the sample space Ω and work\ndirectly with µX .",
    "Definition 4.18 (Variance). Suppose X admits a second moment, i.e., E[X 2] < ∞. Then, the variance of X is\ngiven by\n\nVar(X) := E (cid:2)(X − E[X])2(cid:3) = E[X 2] − (E[X])2\nand is also called the the second centred moment. The square root of the variance, (cid:112)Var(X), is called the\nstandard deviation of X.\n\nPage 43\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nNote that if we put\n\nY =\n\nX − E[X]\n(cid:112)Var(X)\n\nthen Y is a random variable with E[Y ] = 0 and Var(Y ) = E[Y 2] = 1. We say that Y is the standardised version\nof X: its distribution is that of X but shifted and rescaled to have the first two moments equal to 0 and 1.",
    "Definition 4.19. The nth standardised moment of X, if well defined, is given by\n\nE[Y n] = E\n\n(cid:34)(cid:32)\n\nX − E[X]\n(cid:112)Var(X)\n\n(cid:33)n(cid:35)\n\n.\n\nThe third standardised moment is known as skewness of X and the fourth one as kurtosis.\n\nNote that all the moments defined above are, by Theorem 4.15, determined by the distribution of X.\n\n4.5\n\nIntegration on a product space\n\nRecall the definition of product space, Definition 1.7, and the construction of the product measure in Theorem\n2.24. The canonical example of a product measure is given by the Lebesgue measure on R2, or, more generally,\non Rd.\n\nOur integration theory was valid for any measure space (Ω, F , µ) on which µ is a countably additive mea-\nsure. But as we already know for R2, in order to calculate the integral of a function of two variables it is\nconvenient to be able to proceed in stages and calculate the repeated integral. So if f is integrable with respect\nto Lebesgue measure on R2 then we know that\n\nf (x, y)d(x, y) =\n\n(cid:90) (cid:18)(cid:90)\n\n(cid:19)\n\nf (x, y)dx\n\ndy =\n\n(cid:90) (cid:18)(cid:90)\n\n(cid:19)\n\nf (x, y)dy\n\ndx.\n\n(cid:90)\n\nR2\n\nWe now extend this to a general setting.\n\nWe fix two probability spaces (Ωi, Fi, Pi), i = 1, 2 and let (Ω, F , P) denote their product space, i.e., P =\nP1 ⊗ P2. Recall from Lemma 1.29 that for a measurable f , the mappings with one coordinate fixed are also\nmeasurable (w.r.t. to the appropriate σ -algebra).",
    "Theorem 4.20 (Fubini/Tonelli). Let (Ω, F , P) be the product of probability spaces (Ωi, Fi, Pi), i = 1, 2, and let\nf = f (x, y) be a bounded measurable function on (Ω, F ). The functions\n\n(cid:90)\n\nx (cid:55)→\n\nΩ2\n\nf (x, y)P2(dy), y (cid:55)→\n\n(cid:90)\n\nΩ1\n\nf (x, y)dP1(dx)\n\nare F1- and F2-measurable respectively.\n\nSuppose either (i) that f is P-integrable on Ω or (ii) that f ⩾ 0. Then\n\n(cid:90)\n\nΩ\n\nf dP =\n\n(cid:90)\n\n(cid:18)(cid:90)\n\nΩ2\n\nΩ1\n\n(cid:19)\n\nf (x, y)P1(dx)\n\nP2(dy) =\n\n(cid:90)\n\n(cid:18)(cid:90)\n\nΩ1\n\nΩ2\n\n(cid:19)\n\nf (x, y)P2(dy)\n\nP1(dx),\n\nwhere in case (ii) the common value may be ∞.\n\nRemark (Warning). Just as we saw for functions on R2 in Part A Integration, for f to be integrable we require\nthat (cid:82) | f |dP < ∞. If we drop the assumption that f must be integrable or non-negative, then it is not hard to cook\nup examples where both repeated integrals exist but their values are different.\n\nPage 44\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nDeep Dive\n\nYou may recall from Part A Integration that statements about measurability of some functions, e.g., x →\nf (x, y), were for a.e. x and not for all x as here. This is because in Part A Integration you worked on the\ncompleted σ -algebra of all Lebesgue measurable sets and here we do not complete the σ -algebra by adding\nthe null sets.\n\nProof. Both statements follow as immediate applications of the Monotone Class Theorem (Theorem 1.28) and\nwe only outline the proof. First we check that the class H of bounded functions which satisfy the statements\nsatisfies the assumptions in Theorem 1.28. Then we observe that f = 1A1×A2 ∈ H for all A1 ∈ F1, A2 ∈ F2.\nThe statements then hold for all F measurable bounded functions, including simple functions. The general case\nfollows via the MCT.\n\nRemark. Note that we used the fact that Pi are probability measures, or more generally finite measures, when\napplying the Monotone Class Theorem: we need the integrals of a constant to be bounded! The above arguments\ncan then be extended, in the usual way, to σ -finite measures. But Fubini’s theorem may fail for arbitrary\nmeasures!",
    "Example 4.21. Let us consider an important example. Let X be a positive random variable on a generic proba-\nbility space (Ω, F , P). We consider the product space ([0, ∞) × Ω, B([0, ∞)) × F , Leb ⊗ P). Consider the area\nunder the graph of ω → X(ω), namely\n\nA := {(x, ω) : 0 ⩽ x ⩽ X(ω)};\n\nf = 1A.\n\nThe partial integrals are given by\n\n(cid:90)\n\nΩ\n\nf (x, ω)P(dω) = P(X ⩾ x)\n\nand\n\n(cid:90)\n\n[0,∞)\n\nf (x, ω)dx = X(ω),\n\nwhere dx denotes Leb(dx) in the usual fashion. Fubini gives us\n\n(P × Leb)(A) =\n\n(cid:90)\n\n[0,∞)\n\nP(X ⩾ x)dx = E[X].\n\n(18)\n\nRemark. Building on the above example, consider the cornerstone results for functions, e.g., MCT, Fatou’s\nLemma, and see that they simply correspond to the analogues for sets applied to ’areas under graph’.\n\nHere is a simple corollary of Fubini’s theorem which rephrases independence of random variables using expec-\ntations.",
    "Corollary 4.22. Let X,Y be random variables on some probability space (Ω, F , P). Then X and Y are inde-\npendent if and only if for any positive measurable functions f , g\n\nE[ f (X)g(Y )] = E[ f (X)]E[g(Y )].\n\nProof. For the “if” direction, take f = 1(−∞,r], g = 1(−∞,s], r, s ∈ R, and use Corollary 3.9. For the “only if”\ndirection, by Theorem 3.8, the joint distribution of (X,Y ) is the product measure, µ(X,Y ) = µX ⊗ µY . The result\nthen follows from Fubini’s theorem since, by Theorem 4.15, E[ f (X)g(Y )] = (cid:82)\n\nR2 f (x)g(y)µ(X,Y )(d(x, y)).\n\nIt is perhaps worth pausing and recalling that you saw the above in Prelims Probability for discrete random\n\nvariables. It is pleasing to see how much more elegant our language and proofs have become since!\n\nPage 45\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nDeep Dive\n\nThe statement and applications of Fubini’s theorem above pertained only to product measures on Ω. This\nis perhaps natural in analysis but much less in probability theory where we often consider measures on the\nproduct space which are not product measures, i.e., joint distribution of couples of random variables which\nare not independent. It is thus interesting to extend to this context.\n\nNaturally, there are many other measures on Ω. Let us elaborate on other ways to construct such measures\nand how to integrate against them. We keep the setup akin to Example 4.21 but it is clear things could be\nwritten for any product of any two probability spaces.",
    "Definition 4.23. A probability kernel on the product space (R × Ω, B(R) × F ) is a family of probability\nmeasures (Px)x∈R on F such that R ∋ x → Px(A) is measurable for any A ∈ F .\n\nIn words, a probability kernel is a measurable function in one argument and a probability measure in the\nother. A very special case is given by Px = P is independent of x. This is the case when constructing product\nmeasures.",
    "Theorem 4.24 (Generalised Fubini). Let (Px)x∈R be a probability kernel on (R × Ω, B(R) × F ) and let µ\nbe a probability measure on R. Then there exists a unique probability measure Q on B(R) × F such that\n\nQ(E × A) =\n\n(cid:90)\n\nE\n\nPx(A)µ(dx), E ∈ B(R), A ∈ F .\n\n(19)\n\nFor a positive mesurable function f on R × Ω, the function x → (cid:82)\n\nΩ f (x, ω)Px(dω) is measurable and\n\n(cid:90)\n\nR×Ω\n\nf dQ =\n\n(cid:90)\n\nR\n\nµ(dx)\n\n(cid:90)\n\nΩ\n\nf (x, ω)Px(dω).\n\nThe above equation remains true if f is assumed Q-integrable on R × Ω and then the function ω → f (x, ω)\nis Px-integrable µ-a.s.\n\nBy definition, the first marginal of Q is µ:\n\nQ(E × Ω) =\n\n(cid:90)\n\nE\n\nPx(Ω)µ(dx) =\n\n(cid:90)\n\nE\n\nµ(dx) = µ(E), E ∈ B(R).\n\nThe second marginal, which we call P, results from µ-weighting of the measures Px, more precisely\n\nP(A) := Q(R × A) =\n\n(cid:90)\n\nR\n\nPx(A)µ(dx), A ∈ F .\n\nAs we know, this marginal is simply the image law under the projection on the second coordinate. We thus\nhave the following corollary of Theorems 4.24 and 4.15.",
    "Corollary 4.25. In the setup of Theorem 4.24, let P be the marginal of Q on Ω and X be a positive variable\non (Ω, F ). Then x → (cid:82)\n\nΩ X(ω)Px(dω) is measurable and\n\n(cid:90)\n\nΩ\n\nX(ω)P(dω) =\n\n(cid:90)\n\nR\n\nµ(dx)\n\n(cid:90)\n\nΩ\n\nX(ω)Px(dω).\n\nPage 46\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nWe saw above a rich way to construct measures on the product space and how to integrate against them.\nIn fact, this construction is exhaustive: under mild assumptions on Ω any measure Q on the product space\nR × Ω can be disintegrated to be in the form (19). This naturally extends to general products Ω1 × Ω2, again\nunder some assumptions.\n\nPage 47\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n5 Complements and further results on integration\n\nWe stick to the setting of a probability space. All of what follows, with some care given to renormalisation, ex-\ntends to finite measures. Most results extend to σ -finite measures. Some arguments extend to arbitrary measures.\nAn interested and motivated reader can explore such extensions.\n\nThroughout this section we work on a fixed probability space (Ω, F , P). We often drop it from the\n\nconventional notation, e.g., the space L p(Ω, F , P) is simply denoted L p.\n\n5.1 Modes of convergence\n\nWe discuss now the different ways in which a sequence of random variables can converge. Note that this topic\nwas covered in some detail already in Part A Probability course. The motivating setting to keep in mind is that\nof Example 3.15. Suppose the Xn there have mean zero and variance one and recall that Sn = ∑n\nk=1 Xk. It is easy\nto show that P(|Sn/n| > ε) → 0, a result known as the Weak Law of Large Numbers, see Corollary 5.9. But\nthis does not tell us much at the behaviour of Sn(ω) for a given ω ∈ Ω. For this, we need a stronger result:\nP(Sn/n → 0) = 1, a result known as the Strong Law of Large Numbers (SLLN) and much more difficult to\nprove, see Theorem 9.3. Once we know this, it is natural to ask how fast is this convergence? This is answered\nby the Central Limit Theorem (CLT), which asserts that\n\nP\n\n(cid:20) Sn√\nn\n\n(cid:21)\n\n⩽ a\n\nn→∞−→\n\n(cid:90) a\n\n−∞\n\n1\n√\n2π\n\n(cid:18)\n\nexp\n\n−\n\n(cid:19)\n\nx2\n2\n\ndx\n\n(20)\n\nand is the cornerstone results in Statistics. This asserts convergence of Sn/\nn but of markedly different type (or\n’mode’) to the convergence of Sn/n. However, there are also different ways to assess the speed of convergence.\nLetting\n\n(cid:26)\n\nB =\n\nlim sup\nn→∞\n\n√\n\nSn\n2n log log n\n\n(cid:27)\n\n= 1\n\n,\n\n(21)\n\n√\n\nby Kolmogorov’s 0/1-law we have P[B] = 0 or P[B] = 1. In fact P[B] = 1. This is called the law of the iterated\nlogarithm (LIL). Here, the mode of convergence is the same as in the SLLN and the latter is implied by the\nLIL. Under the slightly stronger assumption that ∃α > 0 such that E[|Xn|2+α ] < ∞, Varadhan proves LIL by a\n(delicate) application of Borel–Cantelli, see Chapter 9.4.\n\nWe now give definitions of the various modes of convergence relevant to us in this course.",
    "Definition 5.1. Let p ⩾ 0. The space of all random variables X such that E[|X|p] < ∞ is denoted L p.\nIn\nparticular, L 0 is the space of all random variables. We also denote L ∞ the set of all random variables that are\nbounded.",
    "Definition 5.2 (Modes of convergence). Let X1, X2, . . . and X be random variables. We say that Xn converges to\nX\n\n• almost surely (written Xn\n\na.s.→ X or Xn → X a.s.) if\n\nP[Xn → X] = P\n\n(cid:104)(cid:8)ω : lim\n\nn→∞\n\nXn(ω) = X(ω)(cid:9)(cid:105)\n\n= 1.\n\n• in probability (written Xn\n\nP\n→ X) if, for every ε > 0,\n\nlim\nn→∞\n\nP(|Xn − X| > ε) = lim\nn→∞\n\nP(cid:2)(cid:8)ω : |Xn(ω) − X(ω)| > ε(cid:9)(cid:3) = 0.\n\n• in L p (or in Lp, or in pth moment), written Xn\n\nLp\n→ X, if all X, Xn ∈ L p, n ⩾ 1 and limn→∞ E[|Xn − X|p] = 0.\n\nPage 48\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n• weakly in L 1 (or in the σ (L1, L∞) topology) if Xn, X ∈ L 1, n ⩾ 1 and\n\nE[XnY ] = E[XY ], ∀ bounded r.v. Y.\n\nlim\nn→∞\n\n• in distribution (or weakly) (written Xn\n\nd→ X or Xn ⇒ X) if limn→∞ FXn(x) = FX (x) for every x ∈ R at which\n\nFX is continuous and where FY denotes the distribution function of Y .\n\nThese notions of convergence are all different. In particular, the last notion, that of convergence in distri-\nbution, is very different to the others: it only depends on the particular sequence of random variables through\ntheir distributions. In particular, it makes sense even if all Xn are defined on different probability spaces, unlike\nall the other notions. The notion of weak convergence in L 1 will not be used for now. We will come back to\nit when we discuss uniform integrability in §5.4. All the other modes of convergence were already discussed\nin Part A Probability. The notions of convergence almost surely and convergence in L1 were discussed, for\nLebesgue measure, rather than for arbitrary probability measures as here, also in Part A Integration. Here, we\nwill complement these previous studies and build a more comprehensive picture of the relations between the\nvarious modes of convergence. The results covered in the rest of this chapter are summarised in Figure 5.1.\n\n+ convergence of\npth moments\n(Lemma 4.14)\n\nin Lp\n\np > r > 0\n\nin Lr\n\n+ UI & p = 1\n(Thm. 5.24)\n\nalmost surely\n\nin probability\n\nin distribution\n\nalong a subsequence\n\nif the limit is a constant\n\nFigure 2: Relations between the different modes of convergence.",
    "Example 5.3 (Convergence a.s. does not imply convergence in L1). On the probability space Ω = [0, 1] with the\nBorel σ -algebra and Lebesgue measure, consider the sequence of functions fn given by\n\nfn(x) =\n\n(cid:26) n(1 − nx) 0 ⩽ x ⩽ 1/n,\n\n0\n\notherwise.\n\nPage 49\n\nf10nn1/n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nThen fn → 0 almost everywhere on [0, 1] but fn ̸→ 0 in L1. Thinking of each fn as a random variable, we have\nfn → 0 almost surely but fn ̸→ 0 in L1.",
    "Example 5.4 (Convergence in probability does not imply a.s. convergence). To understand what’s going on\nin (21) and (20), let’s stick with [0, 1] with the Borel sets and Lebesgue measure as our probability space. We\ndefine (Xn)n⩾1 as follows:\n\nfor each n there is a unique pair of integers (m, k) such that n = 2m + k and 0 ⩽ k < 2m. We set\n\nPictorially we have a ‘moving blip’ which travels repeatedly across [0, 1] getting narrower at each pass.\n\nXn(ω) = 1[k/2m,(k+1)/2m)(ω).\n\nFor fixed ω ∈ (0, 1), Xn(ω) = 1 i.o., so Xn ̸→ 0 a.s., but\n\nP[Xn ̸= 0] =\n\n1\n2m → 0\n\nas n → ∞,\n\nso Xn\n\nP\n→ 0. (Also, E[|Xn − 0|] = 1/2m → 0, so Xn\n\nL1\n→ 0).) On the other hand, if we look at the (X2n)n⩾1, we have\n\nand we see that X2n\n\na.s.→ 0.\n\nIt turns out that this is a general phenomenon.",
    "Theorem 5.5 (Convergence in Probability and a.s. Convergence). Let X1, X2, . . . and X be random variables.\n\n(i) If Xn\n\n(ii) If Xn\n\nP\n→ X.\n\na.s.→ X then Xn\nP\n→ X, then there exists a subsequence (Xnk )k⩾1 such that Xnk\n\na.s.→ X as k → ∞.\n\nProof. For ε > 0 and n ∈ N let\n\nAn,ε = {|Xn − X| > ε}.\n\nPage 50\n\nn=5n=2n=3n=4n=16n=2n=4n=8\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n(i) Suppose Xn\n\na.s.→ X. Then for any ε > 0 we have P[An,ε i.o.] = 0. By Lemma 3.18 (Fatou’s Lemma for\n\nsets), we have\n\n0 = P[An,ε i.o.] = P[lim sup\nn→∞\n\nAn,ε ] ⩾ lim sup\nn→∞\n\nP[An,ε ]\n\nand in particular P[An,ε ] → 0, so Xn\n\nP\n→ X.\n\n(ii) This is the more interesting direction. Suppose that Xn\n\nP\n→ X. Then for each k ⩾ 1 we have P[An,1/k] → 0,\n\nso there is some nk such that P[Ank,1/k] < 1/k2 and nk > nk−1 for k ⩾ 2. Setting Bk = Ank,1/k, we have\n\n∞\n∑\nk=1\n\nP[Bk] ⩽\n\n∞\n∑\nk=1\n\nk−2 < ∞.\n\nHence, by BC1, P[Bk i.o.] = 0. But if only finitely many Bk hold, then certainly Xnk → X, so Xnk\n\na.s.→ X.\n\nThe First Borel–Cantelli Lemma provides a very powerful tool for proving almost sure convergence of a\nsequence of random variables. Its successful application often rests on being able to find good bounds on the\nrandom variables Xn.\n\nL1\n→ X then, since −|Xn − X| ⩽ Xn − X ⩽ |Xn − X| and −|Xn − X| ⩽ |Xn| − |X| ⩽ |Xn − X|,\nRemark. Note that if Xn\nwe have both E[Xn] → E[X] and E[|Xn|] → E[|X|]. Naturally, these convergences alone do not imply convergence\nof Xn to X in L1, but the latter does if Xn → X a.s., recall Lemma 4.14 for more details.\n\n5.2 Some useful inequalities\n\nWe turn now to some inequalities which, in particular, often prove useful in the context discussed above. The\nfirst is trivial, but has many applications.",
    "Lemma 5.6 (Markov’s inequality). Let (Ω, F , P) be a probability space and X a non-negative random variable.\nThen, for each λ > 0\n\nP[X ⩾ λ ] ⩽ 1\nλ\n\nE[X].\n\nProof. Let λ > 0. Then, for each ω ∈ Ω we have X(ω) ⩾ λ 1{X⩾λ }(ω). Hence,\n\nE[X] ⩾ E[λ 1{X⩾λ }] = λ P[X ⩾ λ ].",
    "Corollary 5.7 (General Chebyshev’s Inequality). Let X be a random variable taking values in a (measurable)\nset A ⊆ R, and let φ : A → [0, ∞] be an increasing, measurable function. Then for any λ ∈ A with φ (λ ) < ∞ we\nhave\n\nP[X ⩾ λ ] ⩽\n\nE[φ (X)]\nφ (λ )\n\n.\n\nProof. We have\n\nby Markov’s inequality.\n\nP[X ⩾ λ ] ⩽ P[φ (X) ⩾ φ (λ )]\n\n⩽\n\n1\nφ (λ )\n\nE[φ (X)],\n\nPage 51\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nThe most familiar special case is given by taking φ (x) = x2 on [0, ∞) and applying the result to Y = |X −\n\nE[X]|, giving\n\nfor t > 0.\n\nP(cid:2)|X − E[X]| ⩾ t(cid:3) ⩽\n\nE[(X − E[X])2]\nt2\n\n=\n\nVar[X]\nt2",
    "Corollary 5.7 is also often applied with φ (x) = eθ x, θ ⩾ 0, to obtain\n\nP[X ⩾ λ ] ⩽ e−θ λ E[eθ X ].\n\nThe next step is often to optimize over θ .",
    "Corollary 5.8. For p > 0, convergence in Lp implies convergence in probability.\n\nProof. Recall that Xn → X in Lp if E[|Xn − X|p] → 0 as n → ∞. Now\n\nP[|Xn − X| > ε] = P[|Xn − X|p > ε p] ⩽ 1\nε p\n\nE[|Xn − X|p] → 0.\n\nThe next corollary is a reminder of a result you have seen in Prelims. It is called the ‘weak law’ because the\n\nnotion of convergence is a weak one.",
    "Corollary 5.9 (Weak law of large numbers). Let (Xn)n⩾1 be i.i.d. random variables with mean m and variance\nσ 2 < ∞. Set\n\nX(n) =\n\n1\nn\n\nn\n∑\ni=1\n\nXi.\n\nThen X(n) → m in probability as n → ∞.\n\nProof. We have E[X(n)] = n−1 ∑n\n\ni=1\n\nE[Xi] = m and, since the Xn are independent,\n\nVar[X(n)] = n−2Var\n\n(cid:35)\n\nXi\n\n= n−2\n\n(cid:34) n\n∑\ni=1\n\nn\n∑\ni=1\n\nVar[Xi] = σ 2/n.\n\nHence, by Chebyshev’s inequality,\n\nP[|X(n) − m| > ε] ⩽ Var[X(n)]\n\nε 2\n\n=\n\nσ 2\nε 2n\n\n→ 0.",
    "Definition 5.10 (Convex function). Let I ⊆ R be a (bounded or unbouded) interval. A function f : I → R is\nconvex if for all x, y ∈ I and t ∈ [0, 1],\n\nf (tx + (1 − t)y) ⩽ t f (x) + (1 − t) f (y).\n\nImportant examples of convex functions include x2, ex, e−x and |x| on R, and 1/x on (0, ∞). Note that a\n\ntwice differentiable function f is convex if and only if f ′′(x) ⩾ 0 for all x.",
    "Theorem 5.11 (Jensen’s inequality). Let f : I → R be a convex function on an interval I ⊆ R.\nintegrable random variable taking values in I then\n\nIf X is an\n\nE[ f (X)] ⩾ f (E[X]).\n\nPage 52\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nPerhaps the nicest proof of Theorem 5.11 rests on the following geometric lemma.",
    "Lemma 5.12. Suppose that f : I → R is convex and let m be an interior point of I. Then there exists a ∈ R such\nthat f (x) ⩾ f (m) + a(x − m) for all x ∈ I.\n\nProof. Let m be an interior point of I. For any x < m and y > m with x, y ∈ I, by convexity we have\n\nRearranging (or, better, drawing a picture), this is equivalent to\n\nf (m) ⩽ y − m\ny − x\n\nf (x) +\n\nm − x\ny − x\n\nf (y).\n\nIt follows that\n\nso choosing a so that\n\nf (m) − f (x)\nm − x\n\n⩽ f (y) − f (m)\ny − m\n\n.\n\nf (m) − f (x)\nm − x\n\nsup\nx<m\n\n⩽ inf\ny>m\n\nf (y) − f (m)\ny − m\n\n,\n\nf (m) − f (x)\nm − x\n\nsup\nx<m\n\n⩽ a ⩽ inf\ny>m\n\nf (y) − f (m)\ny − m\n\n(if f is differentiable at m we can choose a = f ′(m)) we have that f (x) ⩾ f (m) + a(x − m) for all x ∈ I.\n\nProof of Theorem 5.11. If E[X] is not an interior point of I then it is an endpoint, and X must be almost surely\nconstant, so the inequality is trivial. Otherwise, setting m = E[X] in the previous lemma we have\n\nNow take expectations to recover\n\nas required.\n\nf (X) ⩾ f (E[X]) + a(X − E[X]).\n\nE[ f (X)] ⩾ f (E[X])\n\nAs a byproduct of the proof, since a convex function is bounded from below by an affine function, E[ f (X)]\n\nis well defined, possibly infinite.\n\nRemark. Jensen’s inequality only works for probability measures, but often one can exploit it to prove results\nfor finite measures by first normalizing. For example, suppose that µ is a finite measure on (Ω, F ), and define\nν by ν(A) = µ(A)/µ(Ω). Then\n\n(cid:90)\n\n| f |3 dµ = µ(Ω)\n\n(cid:90)\n\n| f |3 dν ⩾ µ(Ω)\n\n(cid:12)\n(cid:90)\n(cid:12)\n(cid:12)\n(cid:12)\n\nf dν\n\n(cid:12)\n3\n(cid:12)\n(cid:12)\n(cid:12)\n\n= µ(Ω)−2\n\n(cid:12)\n(cid:90)\n(cid:12)\n(cid:12)\n(cid:12)\n\nf dµ\n\n(cid:12)\n3\n(cid:12)\n(cid:12)\n(cid:12)\n\n.\n\n5.3 L p spaces\n\nWe comment a bit more on the structure and properties of L p spaces. Those of you who take the Banach spaces\ncourse will see this done in a more systematic and general way. We will encounter Banach spaces, in particular\nHilbert spaces, time and again in probability. Those who continue to study martingales in continuous time will\nuse the Riesz representation theorem of elements in the dual space of a given Hilbert space.\n\nFor p > 0 the function x → xp is increasing on R+ so\n\n(x + y)p ⩽ (2 · x ∨ y)p ⩽ 2p(xp + yp), ∀x, y ∈ R+.\nIt follows that X,Y ∈ L p implies (X + Y ) ∈ L p. Obviously also αX ∈ L p for any α ∈ R so L p is a vector\nspace. For X ∈ L p let us put\n\n∥X∥p := (E[|X|p])\n\n1\np .\n\nPage 53\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales",
    "Lemma 5.13. Let 0 ⩽ r ⩽ p. Suppose X ∈ L p. Then X ∈ L r and\n\nIn particular, convergence in Lp implies convergence in Lr.\n\n∥X∥r ⩽ ∥X∥p.\n\nProof. Let Xk = |X| ∧ k which is positive and bounded (and in particular integrable). Applying Jensen’s inequal-\nity with the convex function f (x) = xp/r on [0, ∞) we get\n\n∥Xk∥p\n\nr = (E[|Xk|r])p/r ⩽ E[|Xk|p] ⩽ E[|X|p] = ∥X∥p\np.\n\nTaking limits and invoking the MCT gives the desired inequality. The implications for convergence in L p and\nL r is immediate.\n\nWe now derive two crucial inequalities. The H¨older inequality is used in many proofs and Minkowski’s\n\ninequality shows that ∥ · ∥p satisfies the triangular inequality.",
    "Theorem 5.14. Let p, q > 1 be such that 1\n\np + 1\n\nq = 1. Suppose X,Y ∈ L p and Z ∈ L q. Then\n\n(H¨older’s inequality)\n\n(Minkowski’s inequality)\n\nE[|XZ|] ⩽ ∥X∥p∥Z∥q,\n∥X +Y ∥p ⩽ ∥X∥p + ∥Y ∥p.\n\nProof. Proofs of these inequalities on (R, B(R), Leb) were given in Part A Integration. Here we follow Williams\nand derive these from Jensen’s inequality.\n\nIf X = 0 a.s. then there is nothing to show. Otherwise, define a new probability measure on (Ω, F ) by\np, as we did in §4.2, and a random variable Z := |Y |/|X|p−11|X|>0. Applying Jensen’s\n\nQ(A) = E[|X|p1A]/∥X∥p\ninequality with f (x) = xq, we have\n\n(E[|XY |])q = (E [Z|X|p])q =\n\n(cid:18)(cid:90)\n\nZ dQ · ∥X∥p\np\n\n(cid:19)q\n\n(cid:90)\n\n⩽\n\nZq dQ · ∥X∥pq\n\np = E[|Y |q]∥X∥q\np,\n\nwhere we used p + q = pq. H¨older’s inequality follows raising the sides to 1/q.\n\nFor Minkowski’s inequality note that X + Y ∈ L p since it is a vector space and let c = E[|X + Y |p]1/q =\n∥|X + Y |p−1∥q. Using first the triangular inequality on R, |x + y| ⩽ |x| + |y| and then H¨older’s inequality we\nobtain\n\nE[|X +Y |p] ⩽ E[|X| · |X +Y |p−1] + E[|Y | · |X +Y |p−1] ⩽ ∥X∥p · c + ∥Y ∥p · c.\n\nDividing by c gives the desired result since 1 − 1/q = 1/p.\n\nHere is a useful application of H¨older’s inequality.",
    "Lemma 5.15. Let X,Y be two positive random variables such that\n\nxP(X ⩾ x) ⩽ E[Y 1{X⩾x}], ∀x > 0.\n\nThen for p > 1 and q = p/(p − 1), we have\n\n∥X∥p ⩽ q∥Y ∥p.\n\nProof. This is only non-trivial if Y ∈ L p so we suppose E[Y p] < ∞. First use Fubini, in analogy to Example\n4.21, and the assumption, to show E[X p] ⩽ qE[X p−1Y ]. Then use H¨older’s inequality assuming X ∈ L p. In\ngeneral, use for Xn = X ∧ n and invoke MCT. The details are left as an exercise.\n\nPage 54\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nThe following result is of fundamental importance in functional analysis. We will exploit it for p = 2.",
    "Theorem 5.16. Let p ⩾ 1. The vector space L p is complete, i.e., for any sequence (Xn)n⩾1 ⊆ L p such that\n\nthere exists X ∈ L p such that Xn → X in L p.\n\n∥Xs − Xr∥p\n\nn→∞−→ 0\n\nsup\nr,s⩾n\n\nProof. We proceed in analogy to the proof of (ii) in Theorem 5.5 above. Pick kn such that\n\n∥Xs − Xr∥p ⩽ 2−n,\n\nand in particular E[|Xkn − Xkn+1|] ⩽ ∥Xkn − Xkn+1∥p ⩽ 2−n.\n\nsup\nr,s⩾kn\n\nPut Y = ∑n⩾1 |Xkn − Xkn+1|. By MCT we have E[Y ] < ∞ and in particular Y < ∞ a.s. The series being absolutely\nconvergent implies that limn→∞ Xkn exists a.s. We define\n\nso that X is a random variable and Xkn → X a.s. For n ⩾ 1 and r > kn\n\nX(ω) := lim sup\n\nn→∞\n\nXkn(ω), ω ∈ Ω\n\nE[|Xr − Xkm|p] = ∥Xr − Xkm∥p\np\n\n⩽ 2−np, m ⩾ n.\n\nTaking m ↑ ∞ and using Fatou’s lemma gives\n\nIt follows that X ∈ L p and also Xr → X in L p, as required.\n\nE[|Xr − X|p] ⩽ 2−np.\n\nDeep Dive\n\nA Banach space is a normed vector space which is complete. The above shows that L p is almost a Banach\nspace, the only nuisance is that ∥X∥p = 0 implies X = 0 a.s. To get rid of this problem, we quotient by\nthe equivalence relation of a.s. equality. This gives us the space Lp – its elements are not random variables\nanymore but rather equivalence classes relative to a.s. equality. From the function analytic point of view it is\na Banach space and a nicer object than L p. From the probabilistic point of view, we like to work with actual\nfunctions. This is, in particular, since when we have a large family (Xt)t⩾0 of functions, changing each of\nthem on a null set may actually do a lot of harm!\n\n5.4 Uniform integrability\n\nWe come back now to the issue of passing from convergence of random variables to convergence of integrals.\nSpecifically, we are interested in passing from convergence in probability to convergence in L 1 (this will then\nin particular also deal with a.s. convergence in one go). The right notion which provides an equivalence between\nthe two is given by:",
    "Definition 5.17 (Uniform Integrability). A collection C of random variables is called uniformly integrable (UI)\nif\n\nlim\nK→∞\n\nsup\nX∈C\n\nE[|X|1{|X|>K}] = 0.\n\nPage 55\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nTo put the above into words: for any ε > 0 there is a K large enough so that E[|X|1{|X|>K}] < ε for all X ∈ C .\nRemark. Note that UI property of C is not affected if we modify its elements on null sets. Consequently,\nit makes sense to talk about UI of a family of random variables which are only defined a.s. We will use this\nimplicitly in Theorem 6.11 below.",
    "Example 5.18. For X ∈ L 1 the decreasing function E[|X|1{|X|>K}] tends to 0 as K → ∞. Indeed, setting fn =\n|X|1{|X|>n}, the functions fn converge to 0 a.s., and are dominated by the integrable function |X|. So by the DCT,\nE[ fn] → 0. It follows that the singleton family {X} is uniformly integrable if and only if X is integrable.",
    "Example 5.19. If C is a family of random variables with |X| ⩽ Y for all X ∈ C and Y ∈ L 1 then C is uniformly\nintegrable (this is clear by the previous example). In particular, if we are in the setting of the DCT then UI holds.\nFrom the definition, clearly if C contains a non-integrable random variable then C is not UI. But UI of C is\nstrictly more than just all X ∈ C being integrable: we require the convergence E[|X|1{|X|>K}] → 0, K → ∞, to\nhold uniformly across X ∈ C . As easy but very important example is provided by a sequence converging in L 1.\nExercise 5.20. Suppose X, X1, X2, . . . ∈ L 1 and E[|Xn − X|] → 0 as n → ∞. Show that {Xn : n ⩾ 1} is uniformly\nintegrable.\n\nRemark 5.21. Note that in the definition of UI we can replace |X|1{|X|>K} by a ‘comparable’ expression such\nas (|X| − K)+. Their equivalence for the definition follows since",
    "Proposition 5.22. Let C be a family of random variables. Then C is UI if and only if\n\n0 ⩽ (|X| − 2K)+ ⩽ |X|1{|X|>2K} ⩽ 2(|X| − K)+.\n\nand\n\nE[|X|] < ∞\n\nsup\nX∈C\n\nsup\nA∈F :P(A)⩽δ\n\nsup\nX∈C\n\nE[|X|1A] δ →0−→ 0.\n\n(i)\n\n(ii)\n\nProof. Suppose C is UI. By definition, there exists K such that E[|X|1{|X|>K}] ⩽ 1, for all X ∈ C . Thus (i)\nholds:\n\nE[|X|] = E (cid:2)|X|1{|X|⩽K} + |X|1{|X|>K}\n\n(cid:3) ⩽ K + E (cid:2)|X|1{|X|>K}\n\n(cid:3) ⩽ K + 1, ∀X ∈ C .\n\nFix ε > 0 and choose K such that\n\nSet δ = ε/(2K) and suppose that P(A) < δ . Then for any X ∈ C ,\n\nE[|X|1{|X|>K}] < 1\n\n2ε, ∀X ∈ C .\n\nE[|X|1A] = E[|X|1A1{|X|>K}] + E[|X|1A1{|X|⩽K}]\n⩽ E[|X|1{|X|>K}] + E[K1A]\n2ε + KP(A) < ε,\n⩽ 1\n\nso that (ii) holds.\n\nFor the converse, suppose (i) and (ii) hold. Let ε > 0 be given. By (ii) there exists δ > 0 such that P(A) < δ\nimplies E[|X|1A] < ε for all X ∈ C . Let M denote the value of the finite supremum in (i). For K large enough,\nnamely for K > M/δ , by Markov’s inequality we have\nE[|X|]\nK\n\n< δ , ∀X ∈ C .\n\nP(|X| > K) ⩽\n\n⩽ M\nK\n\nPutting the two together we get the desired result:\nE (cid:2)|X|1{|X|>K}\n\n(cid:3) < ε\n\nfor all X ∈ C .\n\nPage 56\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nRemark. If we impose a minor technical condition on our probability space, namely that it is atomless, P({ω}) =\n0 for all ω ∈ Ω, then (ii) on its own implies uniform integrability. So ‘morally’ (ii) is really equivalent to uniform\nintegrability, and is often the best way of thinking about it.\n\nWe start with a variant of the Bounded Convergence Theorem, which is a warm up to the main result.",
    "Lemma 5.23. Let (Xn) be a sequence of random variables with Xn → X in probability, and suppose that |X| and\nall |Xn| are bounded by the same real number K. Then Xn → X in L1.\n\nProof. We use an idea which recurs again and again in this context: split by whether the relevant quantity is\n‘small’ or ‘large’. Specifically, fix ε > 0. Let An be the event {|Xn − X| > ε}. Then\n\nE[|Xn − X|] = E(cid:2)|Xn − X|1An + |Xn − X|1Ac\n\nn\n\n(cid:3)\n\n⩽ E[|Xn|1An] + E[|X|1An] + ε\n⩽ 2E[K1An] + ε = 2KP[An] + ε.\n\n(22)\n\nSince Xn converges to X in probability, P[An] → 0, so the bound above is at most 2ε if n is large enough, and\nE[|Xn − X|] → 0 as required.\n\nNaturally if Xn → X a.s. then the above is a simple corollary to the DCT. Note however that in Example 5.4\nwe saw a sequence of (Xn)n⩾1 which was uniformly bounded and converged in probability and in L1 but not\nalmost surely.\n\nThe next result extends the previous easy result to the situation when the (Xn)n⩾1 are uniformly integrable.\nIn this sense, it provides the converse to Exercise 5.20. It follows that UI is the right condition: Xn → X in L1 if\nand only if Xn → X in probability and {Xn : n ⩾ 1} is uniformly integrable.",
    "Theorem 5.24 (Vitali’s Convergence Theorem). Let (Xn) be a sequence of integrable random variables which\nconverges in probability to a random variable X. TFAE (The Following Are Equivalent):\n\n(i) the family {Xn : n ⩾ 1} is uniformly integrable,\n\n(ii) X ∈ L 1 and E[|Xn − X|] → 0 as n → ∞,\n\n(iii) X ∈ L 1 and E[|Xn|] → E[|X|] < ∞ as n → ∞.\n\nProof. Suppose C = {Xn : n ⩾ 1} is UI. We try to repeat the proof of Lemma 5.23, using the bound (22). Since\n|Xn| → |X| in probability, by Theorem 5.5 there exists a subsequence (Xnk )k⩾1 that converges to X a.s. Fatou’s\nLemma gives\n\nE[|X|] ⩽ lim inf\nk→∞\n\nE[|Xnk |] ⩽ sup\nn\n\nE[|Xn|],\n\nwhich is finite by Proposition 5.22, i.e., X is integrable. Now fix ε > 0, and let An = {|Xn − X| > ε}. As before,\n\nE[|Xn − X|] = E(cid:2)|Xn − X|1An\n\n(cid:3) + E(cid:2)|Xn − X|1Ac\n\n(cid:3)\n\nn\n\n⩽ E(cid:2)|Xn|1An\n\n(cid:3) + E(cid:2)|X|1An\n\n(cid:3) + ε.\n\nSince Xn → X in probability we have P[An] → 0 as n → ∞, so by Proposition 5.22 (ii)\n\nE[|Xn|1An] → 0\n\nas n → ∞.\n\nSimilarly, since {X} is uniformly integrable,\n\nE[|X|1An] → 0\n\nas n → ∞.\n\nPage 57\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nHence E[|Xn − X|] ⩽ 2ε for n large enough. Since ε > 0 was arbitrary this proves (ii).\n\n(ii) ⇒ (iii) follows by −|Xn − X| ⩽ |X| − |Xn| ⩽ |X − Xn| as in the proof of Lemma 4.14.\nIt remains to show (iii) ⇒ (i). Note that we can not repeat the arguments in the proof of Lemma 4.14 which\nrelied on a.s. convergence to use the DCT. Instead, we use the bounded convergence result Lemma 5.23. To\nP\n→ Y . We use Remark 5.21 to establish UI of C .\navoid clutter, let Yn = |Xn| and Y = |X|. Note that Yn,Y ⩾ 0, Yn\nP\n→ Y ∧ K and, by Lemma 5.23, E[Yn ∧ K] → E[Y ∧ K].\nSince |(Yn ∧ K) − (Y ∧ K)| ⩽ |Yn −Y |, we have Yn ∧ K\n\nRecalling that, by assumption, E[Yn] → E[Y ] this gives\n\nE[(Yn − K)+] = E[Yn] − E[Yn ∧ K] n→∞−→ E[Y ] − E[Y ∧ K] = E[(Y − K)+] < ε,\n\nwhere the last inequality holds for all K large enough since Y ∈ L 1. Hence there is an n0 such that for n ⩾ n0,\n\nThere are only finitely many n < n0, so there exists K′ ⩾ K such that such that\n\nE[(|Xn| − K)+] = E[(Yn − K)+] < 2ε.\n\nE[(|Xn| − K′)+] < 2ε\n\nfor all n, as required.\n\n5.5 Further results on UI (Deep Dive)\n\nDeep Dive\n\nThe following is very helpful in thinking about UI. While Proposition 5.22 makes it clear that just uniform\nbound on the first moments is not enough for UI, in fact anything more than that already is.",
    "Theorem 5.25 (La Vall´ee Poussin). Let C ⊆ L 1. Then C is UI if and only if there exists a positive increasing\nand convex g : R+ → R such that\n\nand\n\nlim\nx→∞\n\ng(x)\nx\n\n= ∞\n\nE[g(|X|)] < ∞.\n\nsup\nX∈C\n\nOne example of g which we shall meet later on is given by g(x) = x log x.\n\nProof. TBC\n\nLet us look again at the Definition of UI. It says that for any ε > 0, we can write each X ∈ C as X =\nX1{|X|⩽K} + X1{|X|>K}, where the first variable is obviously bounded and the second one is small in L 1. To\nrephrase, C is UI if and only if, for any ε > 0, there exists K such that C is contained in the Minkowski sum\n\nC ⊂ B∞\n\nK + B1\n\nε := {Y + Z : Y ∈ B∞\n\nK, Z ∈ B1\n\nε },\n\nε is a ball in L 1, B1\n\nε = {Z ∈ L 1 : E[|Z|] ⩽ ε} and B∞\n\nK is a ball in L ∞ seen as a subset in L 1,\nwhere B1\nK = {Y ∈ L 1 : |Y (ω)| ⩽ K ∀ω ∈ Ω}. Note that the Minkowski sum is a convex set so if it contains C it\nB∞\nalso contains its convex hull. It follows that if C is UI then so is its convex hull. Similarly, if a sequence in C\nconverges in L 1 to some X then we can also add X to C without affecting UI. Note also that a union of two\nUI families C , D is still UI and hence so is C + D (since 1\n2(C + D) is a subset of the convex hull of C ∪ D).\nAll of these properties become natural in light of the following result.\n\nPage 58\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales",
    "Theorem 5.26 (Dunford–Pettis). Let C ⊆ L1. TFAE\n\n(i) C is UI\n\n(ii) C is relatively weakly compact (i.e., in the σ (L1, L∞) topology the closure is compact)\n\n(iii) every sequence of elements in C contains a subsequence converging in σ (L1, L∞).\n\nSketchy sketch of (i) ⇒ (ii). From (i) to (ii): consider Q(A) := limU E[X1A], where U is an ultrafilter on\nC and A ∈ F . Part (i) in Proposition 5.22 shows the limit is well defined, while part (ii), together with",
    "Lemma 2.4, shows it is a measure. Using Theorem 4.9 we get ξ = dQ\ndP , in particular ξ ∈ L 1, and show\nthat limU E[XY ] = E[ξY ] for any Y ∈ L ∞. This is easy for a simple Y and then follows with a universal\napproximation argument in Lemma 1.26.\n\nThe reverse, from (ii) to (i), is more difficult. Equivalence between (ii) and (iii) follows from Eberlein–\nSmulian theorem, a difficult result which asserts that different types of compactness are equivalent for the\nweak topology on a Banach space.\n\nPage 59\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n6 Conditional Expectation\n\nFrom now on, we work on a fixed probability space (Ω, F , P). All the random variables are assumed to\nbe defined on (Ω, F ).\n\nAs already stated, independence and conditional expectation are the two key notions which set probability\n\nalive. We saw the former in §3 and are now about the develop the latter.\n\n6.1 Intuition\n\nOur objective is to capture in a mathematically rigorous way, the intuition that our assessment of probabilities,\nand hence of behaviour of random variables, should change as a function of our information. In Prelims we did\nthis through the notion of conditional probability. Suppose we consider an event A. Then, in absence of any\ninformation, we assess its likelihood as P(A). However, if someone tells us that an even B actually happens,\nthen we re-assess the chances of A as P(A|B) = P(A ∩ B)/P(B). Except that this is a post-factum assessment,\nonce we know that B has happened. A more forward thinking approach would be say: suppose you had the\ninformation about B, i.e., you shall know if it happens or not, then how would you assess chances of A? We\nalready answered this in §2.2 and the answer was given in (9):\n\nE [1A | σ (B)] (ω) = P(A | σ (B))(ω) =\n\nP(A ∩ B)\nP(B)\n\n1B(ω) +\n\nP(A ∩ Bc)\nP(Bc)\n\n1Bc(ω).\n\nAs expected the answer takes one value if B happens and another if Bc does. Note that we used expectations\nnotation above, harmless here since E[1A] = P(A), but more suitable to moving from indicators to more general\nrandom variables. For an integrable random variable X we already know from Exercise 4.17 that E[X] is the\nsingle best approximation, in the quadratic sense, to X using a constant. But if we are allowed to use instead a\nrandom variable taking two values, one if B happens and another if Bc does, then we would conjecture\n\nE[X | σ (B)](ω) =\n\nE [X1B]\nP(B)\n\n1B(ω) +\n\nE [X1Bc]\nP(Bc)\n\n1Bc(ω).\n\nIt turns out this answer is correct as the optimality property, known as the mean square approximation, is pre-\nserved.\n\nExercise 6.1. Let X be an integrable random variable and B ∈ F with P(B) > 0. For α, β ∈ R let Yα,β :=\nα1B + β 1Bc. Show that\n\nis attained by Yα,β = E[X | σ (B)] above.\n\ninf\nα,β ∈R\n\nE[(X −Yα,β )2]\n\nIt is also easy to see how the above could generalise to a more detailed information: suppose (Bn)n⩾1 is a\n\npartition of Ω, i.e., the sequence is pairwise disjoint and (cid:83)\n\nn⩾1 Bn = Ω, and that P(Bn) > 0 for all n ⩾ 1. Then\n\nE [1A | σ (Bn : n ⩾ 1)] (ω) = P(A | σ (Bn : n ⩾ 1))(ω) = ∑\nn⩾1\n\nP(A ∩ Bn)\nP(Bn)\n\n1Bn(ω)(ω)\n\nor, more generally, for an integrable random variable X,\n\nE [X | σ (Bn : n ⩾ 1)] (ω) = ∑\nn⩾1\n\nE [X1Bn]\nP(Bn)\n\n1Bn(ω)\n\n(23)\n\nis undoubtedly the right object. Our information is on the levels of Bn’s – we are able to tell them apart and\nhence can reason on each of these instead of the whole of Ω. On each Bn, we just use the old good conditional\n\nPage 60\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nprobability or averaging of X. The outcome is a random variable, taking possibly countably many different\nvalues, which tells us how we shall be evaluating the chances of A happening, or approximating X, depending\non our information about Bn’s. However, it is not clear how to proceed further as this is where the intuition stops\nreally! If we had an uncountable family, each Bi with P(Bi) = 0, i ∈ I, then we have no apparent way of making\nsense of the above.\n\n6.2 Definition, existence and uniqueness\n\nIf we consider more general types of information, i.e., if we want to condition on a σ -algebra G ⊂ F , we can\nnot hope to reason set-by-set or ω-by-ω. Instead we can appeal to the optimal prediction property. Above, one\ncan show that E[X | σ (Bn : n ⩾ 1)] minimises the prediction error E[(X −Y )2] among all Y = ∑n⩾1 αn1Bn. But\nthis gets a bit tedious if we do it by hand. And it essentially just follows from the fact that on the smallest\nlevel of granularity allowed, i.e., on the sets Bn, we use the best constant to approximate X: its expectation\non that set. Thus, by definition, we have that the average of E[X | σ (Bn : n ⩾ 1)] over any set we ‘know’ or\ncan distinguish, i.e., any Bn, is the same as average of X. This and the fact that E[X | σ (Bn : n ⩾ 1)] has to be\nσ (Bn : n ⩾ 1)-measurable leads to the following definition:",
    "Definition 6.2 (Conditional Expectation). Let (Ω, F , P) be a probability space and X an integrable random\nvariable. Let G ⊆ F be a σ -algebra. We say that a random variable Y is (a version of) the conditional expectation\nof X given G if Y is integrable, G -measurable and\n\nE[Y 1G] = E[X1G]\n\nfor all G ∈ G .\n\nThe integrals of X and Y over sets G ∈ G are the same – this is our averaging property – but Y is also\nG measurable whereas X is F -measurable. The conditional probability is defined simply as the conditional\nexpectation of an indicator\n\nP(A | G ) := E[1A | G ]\nfor A ∈ F . It is easy to see that when G = σ (B), for an event B ∈ F , the natural object proposed in (9) satisfies",
    "Definition 6.2. More generally, the following result takes care of the first two questions you may want to ask.",
    "Theorem 6.3 (Existence and uniqueness of conditional expectation). Let X be an integrable random variable\non a probability space (Ω, F , P) and G ⊆ F a σ -algebra. The conditional expectation of X given G exists and\nis denoted E[X | G ]. It is a.s. unique in the sense that if Z is also the conditional expectation of X given G then\nZ = E[X | G ] a.s.\n\nProof of uniqueness. Let Y, Z be two conditional expectations of X given G . Let G := {Y > Z} and note that\nG ∈ G as Y, Z are G -measurable. By definition, E[Y 1G] = E[X1G] = E[Z1G] so that E[(Y − Z)1G] = 0. But\n(Y − Z)1G ⩾ 0 a.s. and hence (Y − Z)1G = 0 a.s., i.e., P(G) = 0 since Y − Z > 0 on G. Swapping Y and Z, we\nalso have P(Z > Y ) = 0 and hence Y = Z a.s.\n\nWe will come back to the proof of existence later. Let us reiterate that the conditional expectation satisfies\n\n(cid:90)\n\nG\n\nE[X | G ]dP =\n\n(cid:90)\n\nG\n\nX dP\n\nfor all G ∈ G ,\n\n(24)\n\ni.e., using the expectation notation, E[E[X | G ]1G] = E[X1G], and we shall call (24) the defining relation.\n\nRemark 6.4. If E[X] = E[Y ] then the DCT shows that the family of sets G for which (24) is true forms a λ -\nsystem. A direct application of π-λ systems lemma thus shows that it is enough to verify (24) for G ∈ A ∪ {Ω}\nfor a π-system A generating G . While simple, this remark is very useful.\n\nPage 61\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nOur first task is to verify that (23) was a correct guess. And, with the above remark, it is enough to check\nthat (24) is satisfied for G = Bn. This is trivial, since if Y denotes the random variable on the right hand side of\n(23) then\n\nE[Y 1Bn] =\n\nE[1Bn] = E[X1Bn].\n\nE[X1Bn]\nP(Bn)\n\nSince the definition of the conditional expectation is so important, let us explain it once again, considering the\ncase G = σ (ξ ) for some random variable ξ . In this case, we often simple write E[X | ξ ] instead of E[X | σ (ξ )].\nSo, Y = E[X | ξ ] is supposed to be a random variable which depends only on the value of ξ , in the sense that\n\n“Y (ω) = E[X | ξ = z] = E[X1{ξ =z}]/P[ξ = z]′′\n\nwhen ξ (ω) = z. To avoid getting into trouble dividing by zero, we can integrate over {ξ = z} to express this as\n\nE[Y 1{ξ =z}] = E[X1{ξ =z}].\n\nStill, if P[ξ = z] = 0 for every z (as will often be the case), this condition simply says 0 = 0. So, just as we did\nwhen we failed to express the basic axioms for probability in terms of the probabilities of individual values, we\npass to sets of values, and in particular Borel sets. So instead we insist that Y is a function of ξ and\n\nE[Y 1{ξ ∈A}] = E[X1{ξ ∈A}]\n\nfor each A ∈ B(R). This is exactly what Definition 6.2 says in the case G = σ (ξ ). Note that thanks to Theorem\n1.27, we can say that E[X|ξ ] = f (ξ ) for some measurable function ξ . Thus, intuitively, we have ’ f (z) =\nE[X|ξ = z]‘ except the concept of the conditional expectation actually makes sense of this even if P(ξ = z) = 0\nfor all z ∈ R.\n\nIn general, it is not the values of ξ that matter, but the ‘information’ in ξ , coded by the σ -algebra ξ generates,\nso we define conditional expectation with respect to an arbitrary σ -algebra G . This then covers cases such as\nconditioning on two random variables at once and much more.\n\nRemark. So far, we defined conditional expectations only when X is integrable. Just as with ordinary expec-\ntation, the definitions work without problems if X ⩾ 0, allowing +∞ as a possible value. This is (an option)\nexercise for you to check.\n\n6.3\n\nImportant properties\n\nWe now turn to basic properties of the conditional expectation. Most of the following are obvious. Always\nremember that whereas expectation is a number, conditional expectation is a function on Ω and, since conditional\nexpectation is only defined up to equivalence (i.e., up to equality almost surely) we have to qualify many of our\nstatements with the caveat ‘a.s.’.",
    "Proposition 6.5. Let (Ω, F , P) be a probability space, X and Y integrable random variables, G ⊆ F a σ -\nalgebra and a, b, c real numbers. Then\n\n(i) E[E[X | G ]] = E[X].\n\n(ii) E[aX + bY + c | G ] a.s.= aE[X | G ] + bE[Y | G ] + c.\n\n(iii) If X is G -measurable, then E[X | G ] a.s.= X.\n\n(iv) E[c | G ] a.s.= c.\n\n(v) E[X | { /0, Ω}] = E[X].\n\nPage 62\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n(vi) If σ (X) and G are independent then E[X | G ] = E[X] a.s.\n\n(vii) If X ⩽ Y a.s. then E[X | G ] ⩽ E[Y | G ] a.s. In particular, if X ⩾ 0 a.s. then E[X | G ] ⩾ 0 a.s.\n(viii) (cid:12)\n\n(cid:12) ⩽ E[|X| | G ] a.s.\n\n(cid:12)E[X | G ](cid:12)\n\nProof. The proofs all follow from the requirement that E[X | G ] be G -measurable and the defining relation (24).\nWe just do some examples.\n\n(i) Set G = Ω in the defining relation.\n(ii) Clearly Z = aE[X | G ] + bE[Y | G ] is G -measurable, so we just have to check the defining relation. But\n\nfor G ∈ G ,\n\n(cid:90)\n\nG\n\nZ dP =\n\n(cid:90)\n\nG\n\n(cid:0)aE[X | G ] + bE[Y | G ](cid:1)dP = a\n\n= a\n\n(cid:90)\n\nG\n\n(cid:90)\n\nE[X | G ]dP + b\n\n(cid:90)\n\nX dP + b\n\nY dP\n\n(cid:90)\n\nG\n\nE[Y | G ]dP\n\nG\nG\n(aX + bY )dP.\n\n=\n\n(cid:90)\n\nG\n\nSo Z is a version of E[aX + bY | G ], and equality a.s. follows from uniqueness.\n\n(v) The sub σ -algebra is just { /0, Ω} and so E[X | { /0, Ω}] (in order to be measurable with respect to { /0, Ω})\n\nmust be constant. Now integrate over Ω to identify that constant.\n\n(vi) Note that E[X] is G -measurable and for G ∈ G\n\nE[E[X]1G] = E[X]P[G] = E[X]E[1G] = E[X1G],\n\nso the defining relation holds, where in the last equality we used independence and Proposition 3.11.\n\n(vii) By linearity it is enough to show the ‘in particular’ part. Suppose X ⩾ 0. If P(E[X | G ] < 0) > 0 then\n\nP(A) > 0, where A = {E[X | G ] ⩽ −1/n} for some n > 0. Since A ∈ G , by (24), we have\n\n0 ⩽ E[X1A] = E[E[X|G ]1A] ⩽ −\n\nP(A)\nn\n\n< 0\n\na contradiction.\n\nNotice that (vi) is intuitively clear. If X is independent of G , then telling me about events in G tells me\nnothing about X and so my assessment of its expectation does not change. On the other hand, for (iii), if X is\nG -measurable, then telling me about events in G actually tells me the value of X.\n\nThe conditional counterparts of our convergence theorems of integration also hold good.",
    "Proposition 6.6 (Conditional Convergence Theorems). Let X1, X2, . . . and X be integrable random variables on\na probability space (Ω, F , P), and let G ⊆ F be a σ -algebra.\n\n1. cMCT: If Xn ⩾ 0 for all n and Xn ↑ X as n → ∞, then E[Xn | G ] ↑ E[X | G ] a.s. as n → ∞.\n\n2. cFatou: If Xn ⩾ 0 for all n then\n\nE[lim inf\nn→∞\n\nXn | G ] ⩽ lim inf\nn→∞\n\nE[Xn | G ]\n\na.s.\n\n3. cDCT: If Y is an integrable random variable, |Xn| ⩽ Y for all n and Xn\n\na.s.→ X, then\n\nE[Xn | G ] a.s.→ E[X | G ]\n\nas n → ∞.\n\nPage 63\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nProof. The proofs all use the defining relation (24) to transfer statements about convergence of the conditional\nprobabilities to our usual convergence theorems. We give details for cMCT and leave the rest as an exercise.\n\nLet Yn = E[Xn | G ]. By Proposition 6.5 (vii) we know that Yn ⩾ 0 a.s. and An = {Yn < Yn−1} ∈ G and is null,\nn⩾2 An. Then A ∈ G is a null set, P(A) = 0, Y is G -measurable and\n\nP(An) = 0. Let Y := lim supn→∞ Yn and A = (cid:83)\noutside of A it is an increasing limit of Yn’s. For any G ∈ G we have\n\nE[Y 1G] = E[Y 1G∩Ac] MCT= lim\nn→∞\n\nE[Yn1G∩Ac]\n\n(24)\n= lim\nn→∞\n\nE[Xn1G∩Ac] MCT= E[X1G∩Ac] = E[X1G].\n\nTaking G = Ω, E[Y ] = E[X] < ∞ and it follows that Y is a version of E[X | G ], as required.\n\nThe following two results are incredibly useful in manipulating conditional expectations. The first is some-\n\ntimes referred to as ‘taking out what is known’.",
    "Lemma 6.7. Let X and Y be random variables on (Ω, F , P) with X, Y and XY integrable. Let G ⊆ F be a\nσ -algebra and suppose that Y is G -measurable. Then\n\nE[XY | G ] a.s.= Y E[X | G ].\n\nProof. The function Y E[X | G ] is clearly G -measurable, so we must check that it satisfies the defining relation\nfor E[XY | G ]. We do this by a standard sequence of steps.\n\nFirst suppose that X and Y are non-negative.\n\nG ∩ A ∈ G and so by the defining relation (24) for E[X | G ]\n\nIf Y = 1A for some A ∈ G , then for any G ∈ G we have\n\n(cid:90)\n\nG\n\nY E[X | G ]dP =\n\n(cid:90)\n\nG∩A\n\nE[X | G ]dP =\n\n(cid:90)\n\nG∩A\n\nX dP =\n\n(cid:90)\n\nG\n\nY X dP.\n\nNow extend by linearity to simple positive Y s. Now suppose that Y ⩾ 0 is G -measurable. Then there is a\nsequence (Yn)n⩾1 of simple G -measurable random variables with Yn ↑ Y as n → ∞, it follows that YnX ↑ Y X\nand we conclude by cMCT and a.s. uniqueness of the conditional expectation. Finally, for X, Y not necessarily\nnon-negative, write XY = (X + − X −)(Y + −Y −) and use linearity of the integral.",
    "Proposition 6.8 (Tower property of conditional expectations). Let (Ω, F , P) be a probability space, X an inte-\ngrable random variable and F1, F2 σ -algebras with F1 ⊆ F2 ⊆ F . Then\n(cid:104)\nE[X | F2] (cid:12)\nE\n\n= E[X | F1] a.s.\n\n(cid:12) F1\n\n(cid:105)\n\nIn other words, writing Xi = E[X | Fi],\n\nE[X2 | F1] = X1\n\na.s.\n\nProof. The left-hand side is certainly F1-measurable, so we need to check the defining relation for E[X | F1].\nLet G ∈ F1, noting that G ∈ F2. Applying the defining relation twice\n\n(cid:104)\nE[X | F2] (cid:12)\nE\n\n(cid:12) F1\n\n(cid:105)\n\ndP =\n\n(cid:90)\n\nG\n\n(cid:90)\n\nG\n\nE[X | F2]dP =\n\n(cid:90)\n\nG\n\nX dP.\n\nThis extends (i) of Proposition 6.5 which (in the light of (v)) is just the case F1 = { /0, Ω}.\nJensen’s inequality, Theorem 5.11, also extends to the conditional setting.",
    "Proposition 6.9 (Conditional Jensen’s Inequality). Suppose that (Ω, F , P) is a probability space and that X is\nan integrable random variable taking values in an open interval I ⊆ R. Let f : I → R be convex and let G be a\nsub σ -algebra of F . If E[| f (X)|] < ∞ then\n\nE[ f (X) | G ] ⩾ f (E[X | G ])\n\na.s.\n\nPage 64\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nProof. A convex function f on I is continuous and can be represented as the supremum over a countable family\nof affine functions {ln : n ⩾ 1} on I. Indeed, we may simply take ln to be supporting tangents from Lemma 5.12\nover a dense sets of mn in I. We have\n\nln (E[X | G ]) = E[ln(X) | G ] ⩽ E[ f (X)|G ]\n\na.s.\n\nand since a countable union of null sets is null, we may assume that the above holds a.s. for all n ⩾ 1 simultane-\nously. The result follows by taking the supremum in n.\n\nAn important special case is f (x) = xp for p > 1. In particular, for p = 2\n\nE[X 2 | G ] ⩾ E[X | G ]2\n\na.s.\n\nA very simple special case of this is the following.",
    "Example 6.10. Suppose that X is a non-trivial non-negative random variable: X ⩾ 0 and P(X > 0) > 0. Then\n\nP[X > 0] ⩾\n\nE[X]2\nE[X 2]\n\n.\n\nProof. Let A = {X > 0} and note that E[X1Ac] = 0 and E[X] = E[X1A]. In particular\n\nE[X | σ (A)] =\n\nE[X]\nP(A)\n\n1A.\n\nUsing Proposition 6.5 (i) and Proposition 6.9,\n\nE[X 2] = E(cid:2)E[X 2 | σ (A)](cid:3) ⩾ E(cid:2)E[X | σ (A)]2(cid:3) =\n\nE[X]2\nP(A)\n\n.\n\nRearranging gives the result.\n\nDeep Dive\n\nTaking expectations in the conditional Jensen for f (x) = |x|p, p ⩾ 1, tells us that for X ∈ L p,\n\n∥E[X|G ]∥p ⩽ ∥X∥p,\n\nor in functional analytic terms, X → E[X|G ] is a linear operator on Lp with norm ⩽ 1. It follows that it is also\ncontinuous in the weak topology, i.e., when Lp is endowed with the σ (Lp, Lq) topology.\n\nThe following provides a very important example of families of uniformly integrable random variables.\nIndeed, such families will play a key role in the remainder of this course. In the important special case when\n(Fn) is a filtration, (Xn) is a martingale, see Example 8.7.",
    "Theorem 6.11. Let X be an integrable random variable on (Ω, F , P) and {Fα : α ∈ I} a family of σ -algebras\nwith each Fα ⊆ F . Then the family {Xα : α ∈ I} with\n\nis uniformly integrable.\n\nXα = E[X | Fα ] a.s.\n\nPage 65\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nProof. Since f (x) = |x| is convex, by the conditional form of Jensen’s inequality (Proposition 6.9),\n\n|Xα | = |E[X | Fα ]| ⩽ E(cid:2)|X| | Fα\n\n(cid:3) a.s.\n\n(25)\n\nand in particular E[|Xα |] ⩽ E[|X|]. Using (25) and monotonicity of the conditional expectation (property (vii) in",
    "Proposition 6.5), we have\n\nE[|Xα |1{|Xα |>K}] ⩽ E (cid:2)E[|X| | Fα ]1{|Xα |>K}\n\n(cid:3) = E[|X|1{|Xα |>K}],\n\n(26)\n\nwhere for the equality we moved the indicator function inside the conditional expectation by Lemma 6.7 and\nthen used property (i) in Proposition 6.5. Since {X} is UI, applying Proposition 5.22, for a given ε > 0 we can\nfind δ > 0 such that P(A) < δ implies E[|X|1A] < ε. Since\n\nP[|Xα | ⩾ K] ⩽\n\nE[|Xα |]\nK\n\n⩽\n\nE[|X|]\nK\n\n,\n\nsetting K = 2E[|X|]/δ < ∞, it follows that E[|Xα |1{|Xα |>K}] < ε for every α.\n\nFinally, we come back to the optimality property discussed in Exercises 4.17 and 6.1. This was our motivat-\n\ning property and it is reassuring to see it holds throughout!\n\nRemark (Conditional Expectation via Mean Square Approximation). Let (Ω, F , P) be a probability space and\nX, Y square integrable random variables. Let G be a sub σ -algebra of F and suppose that Y is G -measurable.\nThen\n\nE[(Y − X)2] = E\n\n(cid:104)(cid:0)Y − E[X | G ] + E[X | G ] − X(cid:1)2(cid:105)\n\n= E(cid:2)(Y − E[X | G ])2(cid:3) + E(cid:2)(E[X | G ] − X)2(cid:3) + 2E[W Z]\n\nwhere W = Y − E[X | G ] and Z = E[X | G ] − X. Now Y and E[X | G ] are G -measurable, so W is G measurable,\nand using Proposition 6.5 (i) and Lemma 6.7 we have\n\nE[W Z] = E(cid:2)E[W Z | G ](cid:3) = E(cid:2)W E[Z | G ](cid:3).\nBut E(cid:2)E[X | G ] | G (cid:3) = E[X | G ], so E[Z | G ] = 0. Hence E[W Z] = 0, i.e., the cross-term vanishes. The second\nterm only depends on X and the first one is minimised by taking Y = E[X | G ]. Thus E[(X − Y )2] is min-\nimised taking Y = E[X | G ] or, in other words, E[X | G ] is the best mean-square approximation of X among\nall G -measurable random variables. We shall now use this property as our starting point to show existence of\nconditional expectations!\n\n6.4 Orthogonal projection in L 2\n\nWe need to develop an abstract equivalent of the well known projection in Rd. We work in L 2. It is (nearly) a\nHilbert space and has a natural geometry. From a probabilistic point of view we centre random variables around\ntheir mean and consider variance and covariance.\n\nExercise 6.12. For X,Y ∈ L 2 let\n\nCov(X,Y ) = E[(X − E[X])]E[(Y − E[Y ])] = E[XY ] − E[X]E[Y ].\n\nShow that Cov(·, ·) is bilinear on L 2 and that\n\nVar(X +Y ) = Var(X) + Var(Y ),\n\nif Cov(X,Y ) = 0.\n\nWhen Cov(X,Y ) = 0 we say that X and Y are uncorrelated. Clearly if X and Y are independent then they are\nalso uncorrelated. Show that the reverse does not need to hold (by means of a counterexample).\n\nPage 66\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nFrom a geometric point of view there is no need to centre things around their mean. We introduce a scalar\n\nproduct\n\n⟨X,Y ⟩ := E[XY ], X,Y ∈ L 2.\n\nNote that this is well defined since by H¨older’s inequality, Theorem 5.14, XY ∈ L 1. We say that X and Y are\northogonal if ⟨X,Y ⟩ = 0.",
    "Lemma 6.13 (Pythagoras’ theorem). If X,Y ∈ L 2 are orthogonal then\n\nExercise 6.14. Show that ⟨·, ·⟩ is bilinear on L 2 and use it to establish the parallelogram law\n\n∥X +Y ∥2\n\n2 = ∥X∥2\n\n2 + ∥Y ∥2\n2.\n\n∥X∥2\n\n2 + ∥Y ∥2\n\n2 = 1\n2\n\n(cid:0)∥X +Y ∥2\n\n2 + ∥X −Y ∥2\n2\n\n(cid:1) .\n\n(27)\n\nRecall from above that completeness means that Cauchy sequences converge to elements in the space.",
    "Theorem 6.15. Let K be a complete vector subspace of L 2. For any X ∈ L 2 the infimum\n\ninf\nZ∈K\n\n∥X − Z∥2\n\nis attained by some Y ∈ K and (X −Y ) is orthogonal to Z for all Z ∈ K with ∥Z∥2 > 0.\n\nRemark. The above result can be rephrased by saying that any X ∈ L 2 can be written as X = Y + (X −Y ) with\nY ∈ K and (X −Y ) orthogonal to K . Clearly such a decomposition is a.s. unique: if we have two such Y1,Y2\nthen their difference would be both in K and orthogonal to K and hence E[(Y1 −Y2)2] = 0 so that Y1 = Y2 a.s.\nWe call Y the (orthogonal) projection of X on K .",
    "Example 6.16. Let K be the vector space of random variables which are a.s. constant. Exercise 4.17 shows\nthat the projection of X on K is given by E[X].\n\nProof of Theorem 6.15. Let (Yn)n⩾1 be a sequence which attains the desired infimum, ∥X −Yn∥2 → ∆. We argue\nthat the sequence is Cauchy. Using (27), we have\n\n∥X −Yr∥2\n\n2 + ∥X −Ys∥2\n\n2 = 2∥X − 1\n\n2(Yr +Ys)∥2\n\n2 + 2∥ 1\n\n2(Yr −Ys)∥2\n2.\n\nSince K is a vector space, 1\nreadily implies that\n\n2(Yr ± Ys) ∈ K and in particular ∥X − 1\n\n2(Yr + Ys)∥2\n2\n\n⩾ ∆2. Optimality of (Yn)n⩾1\n\n∥Yr −Ys∥2\n\nn→∞−→ 0,\n\nsup\nr,s⩾n\n\ni.e., (Yn)n⩾1 is Cauchy. Since K is complete, there exists Y ∈ K with ∥Yn −Y ∥2 → 0 as n → ∞. Minkowski’s\ninequality, see Theorem 5.14, then gives ∥X − Y ∥2 ⩽ ∥X − Yn∥2 + ∥Y − Yn∥2 and taking limits we see that\n∥X −Y ∥2 = ∆ as required.\nNow, let Z ∈ K with ∥Z∥2 > 0 and note that (Y + tZ) ∈ K for all t ∈ R. Using optimality of Y we have\n\n0 ⩽ ∥X − (Y + tZ)∥2\n\n2 − ∥X −Y ∥2\n\n2 = t2∥Z∥2\n\n2 − 2tE[Z(X −Y )].\n\nTaking t = E[Z(X −Y )]/∥Z∥2\n\n2, yields\n\n0 ⩽ −\n\nE[Z(X −Y )]2\n∥Z∥2\n2\n\nwhich implies that E[Z(X −Y )] = 0 as desired.\n\nPage 67\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nProof of existence in Theorem 6.3. Suppose first that X ∈ L 2(Ω, F , P) and let K = L 2(Ω, G , P). Clearly K\nis a vector subspace of L 2(Ω, F , P) and is complete by Theorem 5.16. Let Y be the orthogonal projection of X\non K from Theorem 6.15. We will now verify that Y is a version of the conditional expectation of X given G .\nFirst Y is G -measurable since Y ∈ K . Second, for G ∈ G note that 1G ∈ K and since (X −Y ) is orthogonal to\nK we have E[(X −Y )1G] = 0 which shows that (24) hold.\n\nFor X ∈ L 1, by linearity, it is enough to deal with X ± separately. Suppose thus that X ⩾ 0 and let Xn =\nX ∧ n which are bounded and in particular in L 2 so that Yn = E[Xn | G ] exists by the above. From the cMCT,",
    "Proposition 6.6, we know that Y := lim supn→∞ Yn is a version of E[X | G ].\n\n6.5 Conditional Independence (Deep Dive)\n\nDeep Dive\n\nThe notion of conditional independence appears very naturally when we discuss the Markov property. If you\nrecall from Part A Probability, a simply way of saying that (Xn)n⩾0 is a Markov chain was to say that the\nfuture distribution of the chain only depends on path so far through the present state, or, that future and past\nare conditionally independent given present.",
    "Definition 6.17. Let F1, F2, F3 be three sub-σ -algebras of F . We say that F1 and F3 are conditionally\nindependent given F2 if\n\nP(A1 ∩ A3 | F2) = P(A1 | F2)P(A3 | F2),\n\na.s.\n\nfor all A1 ∈ F1, A3 ∈ F3.\n\nIt is should be clear, by linearity of conditional expectation (see Proposition 6.5) and the conditional\n\nmonotone convergence theorem (see Proposition 6.6), that the above is equivalent to saying that\n\nE[X1X3 | F2] = E[X1 | F2]E[X3 | F2]\n\na.s.\n\nfor all non-negative random variables X1 and X3, respectively F1- and F3- measurable. We could also\nreplace non-negativity by integrability of X1X3, X1 and X3. It is also clear that independence can be recovered\nby taking the trivial F2 = { /0, Ω}.",
    "Theorem 6.18. Let F1, F2, F3 be three sub-σ -algebras of F , and set F12 = σ (F1, F2). Then F1 and F3\nare conditionally independent given F2 if and only if\n\nfor all F3-measurable integrable random variable X3.\n\nE[X3 | F12] = E[X3 | F2] a.s.\n\nProof. To make various equalities clearer, we will refer to different properties in Proposition 6.5 simply by\ntheir list numbers (i), (ii) etc. We will refer to the tower property of conditional expectation, Proposition 6.8,\nas (t) and to the property of “taking out what is known”, Lemma 6.7, as (k).\n(⇒) We suppose F1 and F3 are conditionally independent given F2. By definition, E[X3 | F2] is F2-\nmeasurable and hence also F12-measurable. To establish the desired equality, we thus need to verify that\n\nE[E[X3 | F2]1A] = E[X31A]\n\nfor all A ∈ F12. This holds for A = Ω by (i). It is then easy to see that the family of sets A for which the above\nholds is a λ -system and thus it is enough, by Lemma 1.12, to verify it for the π-system of sets A = A1 ∩ A2,\n\nPage 68\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nA1 ∈ F1, A1 ∈ F2. We have\n\nE[E[X3 | F2]1A11A2]\n\n(t)\n= E[E[E[X3 | F2]1A11A2 | F2]]\nE[X31A1 | F2]]\n= E[1A2\n\n(k)\nE[1A2 | F2]]\n= E[E[X3 | F2]1A2\n(i)\n= E[X31A11A2],\n\n(k)\n= E[E[1A2X31A1 | F2]]\n\n(28)\n\n(29)\n\nas required, and where the third equality followed by the assumed conditional independence.\n(⇐) Suppose now that\n\nE[X3 | F12] = E[X3 | F2]\n\na.s.\n\nfor all F3-measurable integrable random variable X3. Then\n\nE[X1X3 | F2]\n\n(t)\n= E[E[X1X3 | F12] | F2]\n\n(k)\n= E[X1E[X3 | F12] | F2] = E[X1E[X3 | F2] | F2]\n\n(k)\n= E[X1 | F2]E[X3 | F2],\n\nas required and where the third equality followed by assumption.\n\nPage 69\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n7 Filtrations and stopping times\n\nThe language and tools we have developed so far lend themselves beautifully to describing random phenomena\noccurring in time. These are known as stochastic processes and they offer a new level of fun! We will be able\nto capture their dynamics, their relation to us learning new information, their local properties as well as their\nlong-run behaviour and so much more!\n\nWe start with notions relating to information and its evolution. This is captured via σ -algebras and suitable\nclasses of random variables. We work on a fixed probability space (Ω, F , P). Note however, in analogy to §1,\nthe measure P does not play any role here, it’s all about sets, functions and their measurability. P will become\nimportant in the next step: when we consider the nature of the random evolution in §8.",
    "Definition 7.1 (Filtration). A filtration on the probability space (Ω, F , P) is a sequence (Fn)n⩾0 of σ -algebras\nFn ⊆ F such that for all n, Fn ⊆ Fn+1.\n\nWe then call (Ω, F , (Fn)n⩾0, P) a filtered probability space.\nUsually n is interpreted as time and Fn represents our knowledge accumulated by time n. Note in particular\n\nthat we never forget anything. We usually start at time 0 (the beginning), but not always. We let\n\nF∞ = σ\n\n(cid:32)\n\n(cid:33)\n\n(cid:91)\n\nFn\n\nn⩾0\n\n(30)\n\nbe the σ -algebra generated by the filtration. This captures all the information we may acquire but it may be\nsmaller than the abstract F on our space.",
    "Definition 7.2 (Adapted stochastic process). A stochastic process (Xn)n⩾0 is a sequence of random variables\ndefined on (Ω, F , P). The process is integrable if each Xn is integrable.\n\nWe say that (Xn)n⩾0 is adapted to the filtration (Fn)n⩾0 if, for each n, Xn is Fn-measurable.\nWe may write X for (Xn)n⩾0. If Fn represents our knowledge at time n, then X being adapted to (Fn)n⩾0\n\nsimply means that Xn is observable at time n. Here is an obvious example of such a filtration.",
    "Definition 7.3 (Natural filtration). The natural filtration (F X\non the probability space (Ω, F , P) is defined by\n\nn )n⩾0 associated with a stochastic process (Xn)n⩾0\n\nF X\n\nn = σ (X0, X1, . . . , Xn),\n\nn ⩾ 0.\n\nA stochastic process X is automatically adapted to the natural filtration it generates. It is also, by definition,\n\nthe smallest filtration to which X is adapted.\n\nWe talked above of the index n as the time. We can think of this as days, seconds or years. But it could\nalso be some other, non-uniform, clock ticking. Whatever the real world interpretation of this clock may be,\nwe shall refer to instances in this clock as deterministic times. It is maybe easiest to think of these as days and\nXn could be, e.g., the temperature recorded in Greenwich Observatory at noon on this day, or the Rolls-Royce\nHoldings plc closing price at London Stock Exchange. However, in reality we use many other, random, times:\nthe next time I meet you, the first time you see a yeti, the moment the stock price drops by more than 30%\nfrom its past maximum. It is clear these are well defined but not known a priori. They are not deterministic but\nrather of the type ‘I know you when I see you’. We shall turn these now into a mathematically precise notion of\nstopping times. Much of the power of martingale methods that we develop later comes from the fact that they\nwork equally well index by deterministic times as indexed by stopping times.",
    "Definition 7.4 (Stopping time). Let (Ω, F , P) be a probability space and (Fn)n⩾0 a filtration. A random variable\nτ taking values in N ∪ {∞} = {0, 1, 2, . . . , ∞} is called a stopping time with respect to (Fn)n⩾0 if {τ = n} ∈ Fn\nfor all n.\n\nPage 70\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nSo a random time τ is a stopping time if at any point in time n, I can use the current information Fn to\ndecide if I should stop {τ = n} or not. Because (Fn)n⩾0 is filtration, this is equivalent to {τ ⩽ n} ∈ Fn – I stop\nnow or have stopped already – or yet to {τ > n} ∈ Fn, I decide to continue. You can think of a stopping time as\na valid strategy for playing a game, investing or gambling. The strategy can rely on the information accrued so\nfar but can not ‘peak into the future’. All of the examples listed before the definition have this property.\n\nIf the choice of the filtration is unambiguous we shall simply say that τ is a stopping time. Stopping times\nare sometimes called optional times. Note that not all random times are stopping times. If n = 365 and τ is the\nwarmest day of the year, then I need F365 to decide when τ actually happens. Likewise, the day in November\n2024 on which Rolls Royce is most expensive is not known in advance or when it happens. You need to wait till\nthe end of November to know when it actually occurred. It is not a stopping time.\n\nWe now discuss some easy properties of stopping times and first examples. All of this captures the intuition,\ne.g., it is clear that if I have two valid strategies then I may decide to stop when the first one tells me to, or when\nboth tell me to, i.e., minimum and maximum of stopping times are also stopping times.",
    "Proposition 7.5. Let (Ω, F , (Fn)n⩾0, P) be a filtered probability space and τ, ρ stopping times. Then\n\n(i) A deterministic time t, t(ω) = n for all ω ∈ Ω is a stopping time;\n\n(ii) τ ∧ ρ and τ ∨ ρ are stopping times.\n\nProof. Exercise\n\nThe following proposition says that the first time an adapted process enters a region is a stopping time. It is\nalso called the first hitting time and provides a canonical example of a stopping time. Indeed, many times will\nbe of this type for some process X. We recall the usual convention that inf /0 = ∞.",
    "Proposition 7.6. Let X = (Xn)n⩾0 be an adapted process on (Ω, F , (Fn)n⩾0, P) and B ∈ B(R). Then\n\nthe first hitting time of B, is a stopping time.\n\nhB = inf{n ⩾ 0 : Xn ∈ B},\n\nProof.\n\n{hB ⩽ n} =\n\nn\n(cid:91)\n\nk=0\n\nX −1\nk (B) ∈ Fn.\n\nThe next thing we would like to understand is what information do we have at the moment τ? This is a\nrandom time, sometimes it may come early and sometimes very late. But intuitively, since we know it happens\nwhen it happens, we should be able to specify the information we have amassed by that time. This is now made\nprecise.",
    "Definition 7.7. Let τ be a stopping time on (Ω, F , (Fn)n⩾0, P). The σ -algebra of information at time τ is\ndefined as\n\nFτ = {A ∈ F∞ : A ∩ {τ = n} ∈ Fn ∀n ⩾ 0}.\n\n(31)\n\nSo an event A is known by time τ if its part learned if τ = n is normally learned by time n. Note that in the\ndefinition we could change {τ = n} to {τ ⩽ n}. The following shows that our new notion behaves as we would\nwant it to.",
    "Proposition 7.8. Let τ, ρ be stopping times on (Ω, F , (Fn)n⩾0, P). Then\n\nPage 71\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n(i) Fτ defined in (31) is a σ -algebra;\n\n(ii) if τ ⩽ ρ then Fτ ⊆ Fρ .\n\nProof. Exercise.\n\nIn particular, combining Propositions 7.5 and 7.8, we have that (Fτ∧n)n⩾0 is a filtration which is smaller\n\nthan the original one in the sense that Fτ∧n ⊆ Fn, n ⩾ 0.\n\nIf (Xn)n⩾0 represents our ongoing winning in a game and τ is our stopping strategy then the final win is Xτ .\n\nIf τ < ∞ then it is a well defined function\n\nand is F -measurable since\n\nΩ ∋ ω −→ Xτ (ω) := Xτ(ω)(ω)\n\nτ (B) = (cid:91)\nX −1\nn⩾0\n\nτ −1({n}) ∩ X −1\n\nn (B) ∈ F .\n\nIn fact, Xτ is Fτ -measurable. We rephrase this introducing the notion of a stopped process.",
    "Proposition 7.9 (Stopped process). Let X = (Xn)n⩾0 be an adapted process on (Ω, F , (Fn)n⩾0, P) and τ a\nstopping time. Then X τ = (Xτ∧n)n⩾0 is a stochastic process, called the stopped process. X τ is adapted to the\nfiltration (Fτ∧n)n⩾0 and hence also to the filtration (Fn)n⩾0.\n\nProof. It suffices to show that if ρ is a finite stopping time then Xρ is Fρ -measurable which follows from",
    "Corollary 1.19 and (31) since\n\n{Xρ ⩽ x} ∩ {ρ = n} = {Xn ⩽ x} ∩ {ρ = n} ∈ Fn,\n\nfor all n ⩾ 0.\n\nPage 72\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n8 Martingales in discrete time\n\nMuch of modern probability theory derived from two sources: the mathematics of measure and gambling. (The\nlatter perhaps explains why it took so long for probability theory to become a respectable part of mathematics.)\nAlthough the term ‘martingale’ has many meanings outside mathematics – it is the name given to a strap attached\nto a fencer’s ´ep´ee, it’s a strut under the bowsprit of a sailing ship and it is part of a horse’s harness that prevents\nthe horse from throwing its head back – its introduction to mathematics, by Ville in 1939, was inspired by the\ngambling strategy ‘the infallible martingale’. This is a strategy for making a sure profit on games such as roulette\nin which one makes a sequence of bets. The strategy is to stake £1 (on, say, black or red at roulette) and keep\ndoubling the stake until that number wins. When it does, all previous losses and more are recouped and you\nleave the table with a profit. It doesn’t matter how unfavourable the odds are, only that a winning play comes up\neventually. But the martingale is not infallible. Nailing down why in purely mathematical terms had to await the\ndevelopment of martingales in the mathematical sense by J.L. Doob in the 1940’s. Doob originally called them\n‘processes with property E’, but in his famous book on stochastic processes he reverted to the term ‘martingale’\nand he later attributed much of the success of martingale theory to the name.\n\n8.1 Definitions, examples and first properties\n\nThe mathematical term martingale doesn’t refer to the gambling strategy, but rather models the outcomes of a\nseries of fair games (although as we shall see this is only one application). Here is the key definition:",
    "Definition 8.1 (Martingale, submartingales, supermartingale). Let (Ω, F , (Fn)n⩾0, P) be a filtered probability\nspace. An integrable, Fn-adapted stochastic process (Xn)n⩾0 is called\n\n(i) a martingale if for every n ⩾ 0, E[Xn+1 | Fn] = Xn a.s.,\n\n(ii) a submartingale if for every n ⩾ 0, E[Xn+1 | Fn] ⩾ Xn a.s.,\n\n(iii) a supermartingale if for every n ⩾ 0, E[Xn+1 | Fn] ⩽ Xn a.s.\n\nIf we think of Xn as our accumulated fortune when we make a sequence of bets, then a martingale represents\na fair game in the sense that the conditional expectation of Xn+1 − Xn, given our knowledge at the time when we\nmake the (n + 1)st bet (that is Fn), is zero. A submartingale represents a favourable game and a supermartingale\nan unfavourable game. One could say that these terms are the wrong way round, i.e., they represent the point of\nview of ‘the other player’. However, they are very well established by now, so it’s too late to change them!\n\nHere are some elementary properties.",
    "Proposition 8.2. Let (Ω, F , P) be a probability space.\n\n(i) A stochastic process (Xn)n⩾0 on (Ω, F , P) is a submartingale w.r.t. the filtration (Fn)n⩾0 if and only\nIt is a martingale if and only if it is both a supermartingale and a\n\nif (−Xn)n⩾0 is a supermartingale.\nsubmartingale.\n\n(ii) If (Xn)n⩾0 is a submartingale w.r.t. some filtration (Fn)n⩾0 and is adapted to another smaller filtration\n(Gn)n⩾0, Gn ⊆ Fn, n ⩾ 0, then it is also a submartingale with respect to (Gn)n⩾0. In particular, X is a\nsubmartingale with respect to its natural filtration (F X\n\nn )n⩾0.\n\n(iii) If (Xn)n⩾0 is a submartingale and n ⩾ m then\n\nE[Xn | Fm] ⩾ Xm a.s.\n\nPage 73\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nProof. (i) is obvious.\n\nFor (ii) note that integrability is not affected by a change of filtration. Thus, by the tower property,\n\nE[Xn+1 | Gn] = E(cid:2)E[Xn+1 | Fn] | Gn\n\n(cid:3) ⩾ E[Xn | Gn] = Xn a.s.\n\nBy definition, X is adapted to its own natural filtration and it is the smallest such filtration so F X\nabove applies.\n\nn ⊆ Fn and the\n\n(iii). We fix m and prove the result by induction on n. The base case n = m is obvious. For n > m we have\n\nFm ⊆ Fn and using the submartingale property\n\nE[Xn+1 | Fm] = E(cid:2)E[Xn+1 | Fn] | Fm\n\n(cid:3) ⩾ E[Xn | Fm] a.s.,\n\nso E[Xn | Fm] ⩾ Xm a.s. follows by induction.\n\nOf course, part (iii) holds for a supermartingale with the inequalities reversed, and for a martingale with\n\nequality instead. Also, taking expectations in (iii), we see that for a submartingale X we have\n\nE[Xn] ⩾ E[Xm] ⩾ E[X0],\n\nn ⩾ m ⩾ 0,\n\nwith reversed inequalities for supermartingale and equalities for a martingale. Note however that the property\nE[Xn+1 | Fn] = Xn is much stronger than just E[Xn+1] = E[Xn]!\nRemark. The collection of all martingales on a fixed filtered probability space (Ω, F , (Fn)n⩾0, P) is a vector\nspace: if (Xn)n⩾0 and (Yn)n⩾0 are martingales then so is (aXn + bYn)n⩾0 for any a, b ∈ R.\n\nWarning. There is a reason why we usually have a filtration in mind. In contrast to the above remark, it is easy\n(exercise!) to find examples where (Xn) is a martingale with respect to its natural filtration, (Yn) is a martingale\nwith respect to its natural filtration, but (Xn +Yn) is not a martingale with respect to its natural filtration. So it’s\nnot just to be fussy that we specify a filtration (Fn).",
    "Example 8.3 (Sums of independent random variables). Suppose that Y1,Y2, . . . are independent integrable ran-\ndom variables on the probability space (Ω, F , P) and that E[Yn] = 0 for each n. Let X0 = 0 and\n\nXn =\n\nn\n∑\nk=1\n\nYk,\n\nn ⩾ 1.\n\nThen (Xn)n⩾0 is a martingale with respect to the natural filtration given by\n\nFn = σ (X0, X1, . . . , Xn) = σ (Y1, . . . ,Yn).\n\nIndeed, X is adapted and integrable and\n\nE[Xn+1 | Fn] = E[Xn +Yn+1 | Fn] = E[Xn | Fn] + E[Yn+1 | Fn] = Xn + E[Yn+1] = Xn, a.s.\n\nNote that we used basic properties of the conditional expectations, notably (iii) and (vi) in Proposition 6.5.\nThese are very useful when dealing with martingales!\n\nIn this sense martingales generalize the notion of sums of independent random variables with mean zero.\nThe independent random variables (Yi)i⩾1 of Example 8.3 can be replaced by martingale differences (which are\nnot necessarily independent).",
    "Definition 8.4 (Martingale differences). Let (Ω, F , P) be a probability space and (Fn)n⩾0 a filtration. A se-\nquence (Yn)n⩾1 of integrable random variables, adapted to the filtration (Fn)n⩾1, is called a martingale difference\nsequence w.r.t. (Fn) if\n\nE[Yn+1 | Fn] = 0\n\na.s.\n\nfor all n ⩾ 0.\n\nPage 74\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nIt is easy to check that (Xn)n⩾0 is a martingale w.r.t. (Fn)n⩾0 if and only if X0 is integrable and F0-\nmeasurable, and (Xn − Xn−1)n⩾1 is a martingale difference sequence w.r.t. (Fn). Here are two examples of\nmartingale which are not sums of independent random variables.",
    "Example 8.5. Let (Ω, F , P) be a probability space and let (Zn)n⩾1 be a sequence of independent integrable\nrandom variables with E[Zn] = 1 for all n. Define\n\nXn =\n\nn\n∏\ni=1\n\nZi\n\nfor n ⩾ 0,\n\nso X0 = 1. Then (Xn)n⩾0 is a martingale w.r.t. its natural filtration. (Exercise).",
    "Example 8.6. Suppose that Y1,Y2, . . . are i.i.d. random variables on (Ω, F , P) with E[exp(Y1)] = c < ∞. Then\n\nis a martingale with respect to the natural filtration (exercise!).\n\nXn = exp (Y1 + . . . +Yn) c−n",
    "Example 8.7. Let (Ω, F , (Fn)n⩾0, P) be a filtered probability space and X an integrable random variable. Then\n\nXn = E[X | Fn],\n\nn ⩾ 0,\n\nis an (Fn)n⩾0-martingale. Indeed, Xn is certainly Fn-measurable and integrable and, by the tower property of\nconditional expectation,\n\nE[Xn+1 | Fn] = E[E[X | Fn+1] | Fn] = E[X | Fn] = Xn\n\na.s.\n\nWe note also that X is automatically UI by Theorem 6.11 and if Xn → X in probability then it already converges\nin L 1 by Theorem 5.24. We shall later see that this is always the case and this convergence characterises such\nclosed martingales.",
    "Example 8.8. An integrable adapted process X which is increasing, Xn ⩾ Xn−1 a.s., n ⩾ 1, is a submartingale.\n\nThe above gave a trivial example of a submartingale. We now turn to more interesting examples and ways\nof obtaining (sub/super)martingales from other martingales. The first way is trivial: suppose that (Xn)n⩾0 is a\n(sub)martingale with respect to (Fn)n⩾0, and that Y is F0-measurable. Then (Xn −Y )n⩾0 is also a (sub)martingale\nw.r.t. (Fn). In particular, if X0 is F0-measurable, then (Xn)n⩾0 is a martingale if and only if (Xn − X0)n⩾0 is a\nmartingale. This is often useful, as in many contexts it allows us to assume without loss of generality that X0 = 0.",
    "Proposition 8.9. Let (Ω, F , P) be a probability space. Suppose that (Xn)n⩾0 is a martingale with respect to the\nfiltration (Fn)n⩾0. Let f be a convex function on R. If f (Xn) is an integrable random variable for each n ⩾ 0,\nthen ( f (Xn))n⩾0 is a submartingale w.r.t (Fn)n⩾0.\n\nProof. Since Xn is Fn-measurable, so is f (Xn). By Jensen’s inequality for conditional expectations and the\nmartingale property of (Xn),\n\nE[ f (Xn+1) | Fn] ⩾ f (cid:0)E[Xn+1 | Fn](cid:1) = f (Xn)\n\na.s.",
    "Corollary 8.10. If (Xn)n⩾0 is a martingale w.r.t. (Fn)n⩾0 and K ∈ R then (subject to integrability) (|Xn|)n⩾0,\n(X 2\n\nn )n⩾0, (eXn)n⩾0, (e−Xn)n⩾0, (max(Xn, K))n⩾0 are all submartingales w.r.t. (Fn)n⩾0.\n\nPage 75\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales",
    "Definition 8.11 (Predictable process). Let (Ω, F , P) be a probability space and (Fn)n⩾0 a filtration. A sequence\n(Vn)n⩾1 of random variables is predictable with respect to (Fn)n⩾0 if Vn is Fn−1-measurable for all n ⩾ 1.\n\nIn other words, the value of Vn is known ‘one step in advance.’",
    "Theorem 8.12 (Discrete stochastic integral or martingale transform). Let (Ω, F , (Fn)n⩾0, P) be a filtered prob-\nability space and (Yn)n⩾0 a martingale. Suppose that (Vn)n⩾1 is predictable w.r.t. (Fn), and let X0 = 0 and\n\nXn =\n\nn\n∑\nk=1\n\nVk(Yk −Yk−1),\n\nn ⩾ 1.\n\nIf each Xn is integrable then (Xn)n⩾0 is a martingale w.r.t. (Fn).\n\nAn important special case when all Xn are automatically integrable is when all Vn are bounded. The sequence\n\n(Xn)n⩾0 is called a martingale transform and is often denoted\n\n((V ◦Y )n)n⩾0.\n\nIt is a discrete version of the stochastic integral. Here we started with X0 = 0; as far as obtaining a martingale\nis concerned, it makes no difference if we add some F0-measurable integrable random variable Z to all Xn;\nsometimes we take Z = Y0, so Xn = Y0 + ∑n\n\nk=1 Vk(Yk −Yk−1).\n\nProof. For k ⩽ n, all Yk and Vk are Fn-measurable, so Xn is Fn-measurable. Also,\n\nE[Xn+1 − Xn | Fn]\n\na.s.= E[Vn+1(Yn+1 −Yn) | Fn]\na.s.= Vn+1E[Yn+1 −Yn | Fn]\n= 0 a.s.\n\n(taking out what is known)\n\nTypical examples of predictable sequences appear in gambling or finance contexts where they might con-\nstitute strategies for future action. The strategy is then based on the current state of affairs. If, for example,\n(k − 1) rounds of some gambling game have just been completed, then the strategy for the kth round is to bet Vk;\na quantity that can only depend on what is known by time k − 1. The change in fortune in the kth round is then\nVk(Yk −Yk−1). More broadly, we will use the above result to retain the martingale property under stopping. This\nwill be fundamental in what follows, see Theorem 8.16.",
    "Proposition 8.13. Let (Yn)n⩾0 be a supermartingale on a filtered probability space (Ω, F , (Fn)n⩾0, P), (Vn)n⩾1\na non-negative predictable process and let X0 = 0 and\n\nXn =\n\nn\n∑\nk=1\n\nVk(Yk −Yk−1),\n\nn ⩾ 1.\n\nIf Xn is integrable, n ⩾ 0, then X is a supermartingale.\n\nProof. Exercise: imitate the proof of Theorem 8.12.\n\nThere are more examples on the problem sheet. Here is a last one.\n\nPage 76\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nExercise 8.14. Let (Yi)i⩾1 be independent random variables such that E[Yi] = mi, Var(Yi) = σ 2\n\ni < ∞. Let\n\ns2\nn =\n\nn\n∑\ni=1\n\nσ 2\ni = Var\n\n(cid:33)\n\nYi\n\n.\n\n(cid:32) n\n∑\ni=1\n\nTake (Fn)n⩾0 to be the natural filtration generated by (Yn)n⩾1. By Example 8.3,\n\nXn =\n\nn\n∑\ni=1\n\n(Yi − mi)\n\nis a martingale and so by Proposition 8.9, since f (x) = x2 is a convex function, (X 2\nwe can recover a martingale from it by compensation. Show that\n\nn )n⩾0 is a submartingale. But\n\nMn =\n\nis a martingale with respect to (Fn)n⩾0.\n\n(cid:33)2\n\n(Yi − mi)\n\n− s2\nn,\n\nn ⩾ 0\n\n(cid:32) n\n∑\ni=1\n\nThis process of ‘compensation’, whereby we correct a process by something predictable (in this example it\n\nwas deterministic) in order to obtain a martingale reflects a general result due to Doob.",
    "Theorem 8.15 (Doob’s Decomposition Theorem). Let (Ω, F , (Fn)n⩾0, P) be a filtered probability space and\nX = (Xn)n⩾0 an integrable adapted process. Then\n\n(i) (Xn)n⩾0 has a Doob decomposition\n\nwhere (Mn)n⩾0 is a martingale w.r.t. (Fn)n⩾0, (An)n⩾1 is predictable w.r.t. (Fn), and M0 = 0 = A0.\n\nXn = X0 + Mn + An\n\n(32)\n\n(ii) Doob decompositions are essentially unique: if Xn = X0 + (cid:101)Mn + (cid:101)An is another Doob decomposition of\n\n(Xn)n⩾0 then\n\nP\n\n(cid:16)\nMn = (cid:101)Mn, An = (cid:101)An for all n ⩾ 0\n\n(cid:17)\n\n= 1.\n\n(iii) (Xn)n⩾0 is a submartingale if and only if (An)n⩾0 in (32) is an increasing process (i.e., An+1 ⩾ An a.s. for\n\nall n) and a supermartingale if and only if (An)n⩾0 is a decreasing process.\n\nProof. (i). Let\n\nand\n\nAn =\n\nn\n∑\nk=1\n\nE[Xk − Xk−1 | Fk−1] =\n\n(cid:0)E[Xk | Fk−1] − Xk−1\n\nn\n∑\nk=1\n\n(cid:1)\n\nMn =\n\n(cid:0)Xk − E[Xk | Fk−1](cid:1).\n\nn\n∑\nk=1\n\nk=1(Xk − Xk−1) = Xn − X0, so (32) holds. The kth summand in An is Fk−1-measurable, so An is\nThen Mn + An = ∑n\nFn−1-measurable, i.e., A is a predictable process. Also, as X is integrable so are (Mn)n⩾0 and (An)n⩾0. Finally,\nsince\n\nE[Mn+1 − Mn | Fn] = E(cid:2)Xn+1 − E[Xn+1 | Fn] (cid:12)\n\n(cid:12) Fn\n\n(cid:3) = 0,\n\nthe process (Mn)n⩾0 is a martingale.\n\na.s.\n\nPage 77\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n(ii) For uniqueness, note that in any Doob decomposition, by predictability we have\n\nAn+1 − An = E[An+1 − An | Fn]\n\n= E[(Xn+1 − Xn) − (Mn+1 − Mn) | Fn]\n= E[Xn+1 − Xn | Fn]\n\na.s.,\n\nwhich combined with A0 = 0 proves uniqueness of (An). Since Mn = Xn − X0 − An, uniqueness of (Mn) follows.\n\n(iii) Just note that\n\nas shown above.\n\nE[Xn+1 | Fn] − Xn = E[Xn+1 − Xn | Fn] = An+1 − An\n\na.s.\n\nRemark. The above proof follows a clear logic and is, all in all, a relatively straightforward exercise. In contrast,\nthe proof of the analogue result for martingales indexed with a continuous time parameter is a delicate affair!\n\nRemark (The angle bracket process ⟨M⟩). Let M be a martingale on (Ω, F , (Fn)n⩾0, P) with E[M2\neach n. We then say that M is an L2-martingale. Naturally, by Proposition 8.9, (M2\nby Theorem 8.15 it has a Doob decomposition (which is essentially unique),\n\nn ] < ∞ for\nn )n⩾0 is a submartingale. Thus\n\nM2\n\nn = M2\n\n0 + Nn + An\n\nwhere (Nn)n⩾0 is a martingale and (An)n⩾0 is an increasing predictable process. The process (An)n⩾0 is often\ndenoted by (⟨M⟩n)n⩾0.\nNote that E[M2\n\nn ] = E[M2\n\n0 ] + E[An] and (since E[Mn+1 | Fn] = Mn) that\nAn+1 − An = E[M2\n\nn+1 − M2\n\nn | Fn] = E[(Mn+1 − Mn)2 | Fn].\n\nThat is, the increments of An are the conditional variances of our martingale difference sequence. It turns out\nthat (⟨M⟩n)n⩾0 is an extremely powerful tool with which to study (Mn)n⩾0. It is beyond our scope here, but\nits continuous time equivalent, known as the quadratic variation process, will be used extensively in Part B\nContinuous Martingales and Stochastic Calculus course.\n\n8.2 Stopped martingales and Stopping Theorems\n\nMuch of the power of martingale methods, as we shall see, comes from the fact that (under suitable boundedness\nassumptions) the martingale property is preserved if we ‘stop’ the process at stopping times. In fact, the ‘natural’\ndeterministic times are something of a red herring. It is far better and more useful to think of martingales as\nliving on random time scales. Random, but ones which do not anticipate the future, so ones made up of stopping\ntimes.\n\nThe following is a simple corollary of Theorem 8.12. It is however so important that it is stated as a theorem!",
    "Theorem 8.16 (Stopped Martingale). Let X be a martingale on a filtered probability space (Ω, F , (Fn)n⩾0, P)\nand τ be a finite stopping time. Then Xτ = (Xτ∧n : n ⩾ 0) is a martingale with respect to (Fn)n⩾0 and with\nrespect to (Fτ∧n)n⩾0.\nProof. Note that {τ ⩾ k} = {τ > k − 1} ∈ Fk−1 so that Vk = 1k⩽τ , k ⩾ 1, is predictable. We have\n\nX0 +\n\nn\n∑\nk=1\n\nVk(Xk − Xk−1) = X0 +\n\nτ∧n\n∑\nk=1\n\n(Xk − Xk−1) = Xτ∧n\n\nand the result follows by Theorem 8.12 and Proposition 8.2.\n\nPage 78\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nMore generally, we have the following fundamental result.",
    "Theorem 8.17 (Doob’s Optional Sampling Theorem). Let X be a martingale on a filtered probability space\n(Ω, F , (Fn)n⩾0, P) and τ, ρ be two bounded stopping times, τ ⩽ ρ. Then\n\nE[Xρ | Fτ ] = Xτ a.s.\n\n(33)\n\nand in particular E[Xρ ] = E[Xτ ] = E[X0].\nSimilarly, if X is a sub- (resp. super-) martingale then E[Xρ | Fτ ] ⩾ Xτ (resp. E[Xρ | Fτ ] ⩽ Xτ ) a.s.\n\nProof. Consider first the case when ρ = n is a constant. Then (33) follows by simply checking the defining\nrelationship for the conditional expectation since for any A ∈ Fτ we have\n\nE[Xn1A] =\n\nn\n∑\nk=0\n\nE[Xn1A1τ=k] =\n\nn\n∑\nk=0\n\nE[Xk1A1τ=k] =\n\nn\n∑\nk=0\n\nE[Xτ 1A1τ=k] = E[Xτ 1A],\n\nwhere the first equality follows since τ ⩽ n and the second by definition of Fτ in (31) and since X is a martingale.\nConsider now the general case. The process Yn = Xρ∧n − Xτ∧n, n ⩾ 0, is a martingale as a difference of two\nmartingales, by Theorem 8.16. It follows that:\n\n0 = Yτ∧n = E[Yn | Fτ∧n] = E[Xρ∧n | Fτ∧n] − Xτ∧n\n\na.s.\n\nwhere the first equality is by definition, the second follows from the case of a deterministic ρ shown above and\nthe third since Xτ∧n is Fτ∧n-measurable by Proposition 7.9. It suffices to take n large enough so that n ⩾ ρ ⩾ τ.\nThe proof for sub-/super- martingales is the same but uses Proposition 8.13 instead of Theorem 8.12.\n\nWe note that the assumption that τ, ρ are bounded is important as the following simple example demon-\n\nstrates.",
    "Example 8.18. Let (Yk)k⩾1 be i.i.d. random variables with P(Yk = 1) = P(Yk = −1) = 1\nk=1 Yk.\nThus Mn is the position of a simple random walk started from the origin after n steps. In particular, (Mn)n⩾0 is a\nmartingale and E[Mn] = 0 for all n.\n\n2. Set Mn = ∑n\n\nNow let τ = h{1} = min{n : Mn = 1}, a stopping time by Proposition 7.6. It is easy to show, e.g., in analogy\n\nto Exercise 3.21, that τ < ∞ a.s. and hence Mτ = 1 a.s. But then E[Mτ ] = 1 ̸= 0 = E[M0].\n\nThe problem in the above example is is that τ is too large. It is finite a.s. but E[τ] = ∞. Doob’s stopping\ntheorem may be extended but requires some further assumptions. Here we give most often invoked extensions.",
    "Corollary 8.19 (Variants of Doob’s Optional Stopping Theorem). Let (Mn)n⩾0 be a martingale on a filtered\nprobability space (Ω, F , (Fn)n⩾0, P) and τ an a.s. finite stopping time. Then\n\nE[Mτ 1τ<∞] = E[M0]\n\nif either of the following two conditions holds:\n\n(i) {Mn : n ⩾ 0} is uniformly integrable;\n\n(ii) E[τ] < ∞ and there exists L ∈ R such that\n\nE(cid:2)|Mn+1 − Mn| (cid:12)\n\n(cid:12) Fn\n\n(cid:3) ⩽ L,\n\na.s. for all n.\n\nPage 79\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nProof. (i) Let K > 0. The process (|Mn| − K)+, n ⩾ 0 is a submartingale by Proposition 8.9 and hence, by",
    "Theorem 8.17, we have E[(|Mτ∧n| − K)+] ⩽ E[(|Mn| − K)+]. It follows, by Remark 5.21, that the family (Mτ∧n :\nn ⩾ 0) is Uniformly Integrable. We have Mτ∧n → Mτ 1τ<∞ a.s., since τ is a.s. finite, and hence also in L 1 by",
    "Theorem 5.24. In particular E[Mτ∧n] → E[Mτ 1τ<∞]. We conclude since, by Theorem 8.17, E[Mτ∧n] = E[M0].\n\n(ii) Replacing Mn by Mn − M0, we assume without loss of generality that M0 = 0. Then\n\n|Mn∧τ | = |Mn∧τ − M0∧τ | ⩽\n\nn\n∑\ni=1\n\n|Mi∧τ − M(i−1)∧τ | ⩽\n\n∞\n∑\ni=1\n\n|Mi∧τ − M(i−1)∧τ | =\n\n∞\n∑\ni=1\n\n1τ⩾i|Mi − Mi−1|.\n\n(34)\n\nNow\n\nE\n\n(cid:34) ∞\n∑\ni=1\n\n(cid:35)\n\n1τ⩾i|Mi − Mi−1|\n\n=\n\n=\n\n=\n\nE(cid:2)1τ⩾i|Mi − Mi−1|(cid:3)\n\n(by monotone convergence)\n\nE (cid:2) E(cid:2)1τ⩾i|Mi − Mi−1| (cid:12)\n\n(cid:12) Fi−1\n\nE (cid:2) 1τ⩾iE(cid:2)|Mi − Mi−1| (cid:12)\n\n(cid:12) Fi−1\n\n(cid:3) (cid:3)\n\n(cid:3) (cid:3)\n\n(tower property)\n\n(since {τ ⩾ i} ∈ Fi−1)\n\n⩽ L\n\nE[1τ⩾i] = L\n\n∞\n∑\ni=1\n\nP[τ ⩾ i] = LE[τ] < ∞.\n\n∞\n∑\ni=1\n∞\n∑\ni=1\n∞\n∑\ni=1\n∞\n∑\ni=1\n\nThe result now follows, as above, by DCT with the function on the right hand side of (34) as the dominating\nfunction.\n\nWe stated the Optional Stopping Theorem for martingales, but similar results are available for sub/super-\n\nmartingales – just replace the equality in (33) by the appropriate inequality.\n\nNote that if |Mi − Mi−1| ⩽ L always holds, and E[τ] < ∞, then the second case applies. This is an important\n\ncase of the Optional Stopping Theorem for applications. We give one such example.",
    "Example 8.20. Suppose that (Ω, F , P) is a probability space and (Xi)i⩾1 are i.i.d. random variables with P[Xi =\nj] = p j > 0 for each j = 0, 1, 2, . . .. What is the expected number of random variables that must be observed\nbefore the subsequence 0, 1, 2, 0, 1 occurs?\n\nSolution. Consider a casino offering fair bets, where the expected gain from each bet is zero. In particular, a\ngambler betting £a on the outcome of the next random variable being a j will lose with probability 1 − p j and\nwill win £a/p j with probability p j. (Her expected pay-out is 0(1 − p j) + p ja/p j = a, the same as the stake.)\n\nImagine a sequence of gamblers betting at the casino, each with an initial fortune of £1.\nGambler i bets £1 that Xi = 0; she is out if she loses and, if she wins, she bets her entire fortune of £1/p0 that\nXi+1 = 1; if she wins again she bets her fortune of £1/(p0 p1) that Xi+2 = 2; if she wins that bet, then she bets\n£1/(p0 p1 p2) that Xi+3 = 0; if she wins that bet then she bets her total fortune of £1/(p2\n0 p1 p2) that Xi+4 = 1; if\n0 p2\nshe wins she quits with a fortune of £1/(p2\n\n1 p2).\n\nLet Mn be the casino’s winnings after n games (so when Xn has just been revealed). Then (Mn)n⩾0 is a\nmean zero martingale w.r.t. the filtration (Fn)n⩾0 where Fn = σ (X1, . . . , Xn). Write τ for the number of random\n1 p2 and note that P(τ > 5) ⩽ (1 − ε) and\nvariables to be revealed before we see the required pattern. Let ε = p2\nP(τ ⩾ n) < ∞. Since at most 5 people bet at any one\nmore generally, P(τ > 5n) ⩽ (1 − ε)n so that E[τ] = ∑n⩾0\ntime, |Mn+1 − Mn| is bounded by a constant (say L = 5/(p2\n0 p2\n1 p2)), so condition (ii) of Theorem 8.19 is satisfied\n(with this L).\n\n0 p2\n\nWhen Xτ is revealed each of the gamblers 1, 2, . . . , τ have paid £1 to enter.\n\n• Gambler τ − 4 has won £1/(p2\n\n0 p2\n\n1 p2),\n\nPage 80\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n• Gamblers τ − 3 and τ − 2 have both lost and are out,\n\n• Gambler τ − 1 has won £1/(p0 p1),\n\n• Gambler τ has lost and is out.\n\nOf course, gamblers τ + 1, τ + 2, . . . have not bet at all yet and all gamblers prior to τ − 4 have lost and are out.\n\nBy Theorem 8.19 E[Mτ ] = 0, so taking expectations,\n\nMτ = τ −\n\n1\n0 p2\np2\n1 p2\n\n−\n\n1\np0 p1\n\n.\n\nE[τ] =\n\n1\np2\n0 p2\n1 p2\n\n+\n\n1\np0 p1\n\n.\n\nThe same trick can be used to calculate the expected time until any specified (finite) pattern occurs in i.i.d.\n\ndata.\n\n8.3 Maximal Inequalities\n\nMartingales have to evolve, locally, in a balanced way – in the sense that the conditional expectation of the\nincrement, at any point in time, is zero. This allows us to control the maximum of the process, along its\ntrajectory, using its final value.",
    "Theorem 8.21 (Doob’s maximal inequality). Let (Xn)n⩾0 be a submartingale on (Ω, F , (Fn)n⩾0, P). Then, for\nλ > 0,\n\nY λ\nn = (Xn − λ )1{maxk⩽n Xk⩾λ },\n\nn ⩾ 0,\n\nis a submartingale. In particular,\n\nλ P(cid:2)max\nk⩽n\n\nXk ⩾ λ (cid:3) ⩽ E[Xn1{maxk⩽n Xk⩾λ }] ⩽ E[|Xn|].\n\n(35)\n\nProof. Let τ = h[λ ,∞) = inf{n ⩾ 0 : Xn ⩾ λ } and set Vn = 1{τ⩽n−1}, n ⩾ 1. Let X n := maxk⩽n Xk and note that\nVn = 1{X n−1⩾λ }. Applying Proposition 8.13 to −X and V we deduce that (V ◦ X)0 = 0,\n\n(V ◦ X)n =\n\nn\n∑\nk=1\n\nVk(Xk − Xk−1) = Xn∨τ − Xτ = (Xn − Xτ )1{τ⩽n},\n\nn ⩾ 1,\n\nis a submartingale. Further, Xτ ⩾ λ by definition so that (Xτ − λ )1{τ⩽n}, n ⩾ 0, is an adapted integrable and\nnon-decreasing process and hence a submartingale. This shows that Y λ is a sum of two submartingales and\nhence also a submartingale. In particular\n\n0 ⩽ E[(X0 − λ )1{X0⩾λ }] = E[Y λ\n\n0 ] ⩽ E[Y λ\n\nn ] = E[(Xn − λ )1{τ⩽n}] = E[Xn1{X n⩾λ }] − λ P(X n ⩾ λ ).\n\nRearranging we obtain the first required inequality and the second one is trivial.",
    "Corollary 8.22. Let p ⩾ 1 and (Mn)n⩾0 be a martingale on a filtered probability space (Ω, F , (Fn)n⩾0, P) with\nMn ∈ L p for all n ⩾ 0. Then, for any n ⩾ 0 and λ > 0\n\nP\n\n(cid:20)\n\nmax\nn⩽N\n\n|Mn| ⩾ λ\n\n(cid:21)\n\n⩽\n\nE[|MN|p]\nλ p\n\n.\n\nPage 81\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nProof. This follows by applying Theorem 8.21 to (|Mn|p)n⩾0 which is a submartingale by Proposition 8.9.",
    "Theorem 8.23 (Doob’s Lp inequality). Let p > 1 and (Xn)n⩾0 be a non-negative submartingale on (Ω, F , (Fn)n⩾0, P)\nwith Xn ∈ L p for all n ⩾ 0. Then maxk⩽n Xk ∈ L p and\n\nE[X p\n\nn ] ⩽ E\n\n(cid:20)\n\nmax\nk⩽n\n\n(cid:21)\n\n⩽\n\nX p\nk\n\n(cid:18) p\n\n(cid:19)p\n\np − 1\n\nE[X p\n\nn ].\n\nProof. The result follows instantly from Theorem 8.21 and Lemma 5.15.\n\nRemark. Note that maxk⩽n X p\nk = (maxk⩽n Xk)p. The above is most often applied with Xn = |Mn| for a martingale\nM. Note that p/(p − 1) = q with 1/p + 1/q = 1. The above can be rephrased saying that the L p norm of the\nrunning maximum ∥ maxk⩽n Xk∥p is comparable with the L p norm of the terminal value ∥Xn∥p. The assumption\np > 1 is important. The result is no longer true for p = 1.\nNote that the stopped process X n is also a positive submartingale so the values of X after n are irrelevant, it is\nenough to have the submartingale defined for 1 ⩽ k ⩽ n.\n\nWe finish the section with a variant of the maximal inequality for supermartingales.",
    "Proposition 8.24. Let (Xn)n⩾0 be a supermartingale on a filtered probability space (Ω, F , (Fn)n⩾0, P). Then\n\nλ P(max\nk⩽n\n\n|Xk| ⩾ λ ) ⩽ E[X0] + 2E[X −\n\nn ], ∀λ , n ⩾ 0.\n\n(36)\n\nProof. Applying Doob’s optional sampling theorem to X and the stopping time τ = min{k : Xk ⩾ λ } ∧ n, we\nobtain\n\nE[X0] ⩾ E[Xτ ] ⩾ λ P(max\nk⩽n\n\nXk ⩾ λ ) + E[Xn1{maxk⩽n Xk<λ }].\n\nThis leads to\n\nλ P(max\nk⩽n\n\nXk ⩾ λ ) ⩽ E[X0] + E[X −\nn ].\n\nOn the other hand, the process (X −\nto it giving\n\nn )n⩾0 is a non-negative submartingale so we may apply Theorem 8.21 directly\n\nλ P(max\nk⩽n\n\nX −\nk\n\n⩾ λ ) ⩽ E[X −\nn ].\n\nCombining, we obtain the desired result.\n\n8.4 The Upcrossing Lemma and Martingale Convergence\n\nWe turn now to studying the limiting behaviour of sub-/super- martingales. We start by bounding the number of\ntimes these processes can cross an interval of values [a, b]. This will allow us to control their oscillations and, in\nconsequence, their limits.\n\nLet (Xn)n⩾0 be an integrable random process, for example modelling the value of an asset. Suppose that\n(Vn)n⩾1 is a predictable process representing an investment strategy based on that asset. The result of Theo-\nrem 8.13 tells us that if (Xn)n⩾0 is a supermartingale and our strategy (Vn)n⩾1 only allows us to hold non-negative\namounts of the asset, then our fortune is also a supermartingale. Consider the following strategy:\n\n1. You do not invest until the current value Xn goes below some level a (representing what you consider to\n\nbe a bottom price), in which case you buy a share.\n\n2. You keep your share until Xn gets above some level b (a value you consider to be overpriced) in which\n\ncase you sell your share and you return to the first step.\n\nPage 82\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nThree remarks:\n\n1. However clever this strategy may seem, if (Xn)n⩾0 is a supermartingale and you stop playing at some\nbounded stopping time, then in expectation your losses will at least equal your winnings. You can not\noutsmart the game.\n\n2. Your ‘winnings’, i.e., profit from shares actually sold, are at least (b − a) times the number of times the\n\nprocess went up from a to b. (They can be greater, since the price can ‘jump over’ a and b.)\n\n3. If you stop, owning a share, at a time n when the value is below the price at which you bought, then\n\n(selling out) you lose an amount which is at most (Xn − a)−: you bought at or below a.\n\nCombining these remarks, if (Xn)n⩾0 is a supermartingale we should be able to bound (from above) the expected\nnumber of times the stock price rises from a to b by E[(Xn − a)−]/(b − a). This is precisely what Doob’s\nupcrossing inequality will tell us. To make it precise, we need some notation.",
    "Definition 8.25 (Upcrossings). If x = (xn)n⩾0 is a sequence of real numbers and a < b are fixed, define two\ninteger-valued sequences (ρk)k⩾1 = (ρk([a, b], x))k⩾1 and (τk)k⩾0 = (τk([a, b], x))k⩾0 recursively as follows:\n\nLet τ0 = 0 and for k ⩾ 1 let\n\nρk = inf{n ⩾ τk−1 : xn ⩽ a},\nτk = inf{n ⩾ ρk : xn ⩾ b},\n\nwith the usual convention that inf /0 = ∞.\n\nLet\n\nbe the number of upcrossings of [a, b] by x by time n and let\n\nUn([a, b], x) = max{k ⩾ 0 : τk ⩽ n}\n\nU([a, b], x) = sup\n\nn\n\nUn([a, b], x) = sup{k ⩾ 0 : τk < ∞}\n\nbe the total number of upcrossings of [a, b] by x.",
    "Lemma 8.26 (Doob’s Upcrossing Lemma). Let X = (Xn)n⩾0 be a supermartingale on a filtered probability\nspace (Ω, F , (Fn)n⩾0, P) and a < b some fixed real numbers. Then, for every n ⩾ 0,\n\nE[Un([a, b], X)] ⩽\n\nE[(Xn − a)−]\nb − a\n\n.\n\nProof. ρk, τk are simply first hitting times after previous hitting times. It is an easy induction to check that for\nk ⩾ 1, the random variables ρk = ρk([a, b], X) and τk = τk([a, b], X) are stopping times. Now set\n\nVn = ∑\nk⩾1\n\n1{ρk<n⩽τk}.\n\nNotice that Vn only takes the values 0 and 1. It is 1 at time n if X is in the process of making an upcrossing from\na to b or if ρk < n and τk = ∞. It encodes our investment strategy above: we hold one unit of stock during an\nupcrossing or if τk is infinite for some k and n > ρk.\nNotice that\n\n{ρk < n ⩽ τk} = {ρk ⩽ n − 1} ∩ {τk ⩽ n − 1}c ∈ Fn−1.\n\nPage 83\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nb\n\na\n\nρ1\n\nV = 0\n\nV = 1\n\nτ1\n\nV = 0\n\nρ2\n\nV = 1\n\nτ2\n\nFigure 3: Illustration of the sequence of stopping times introduced in Definition 8.25.\n\nSo (Vn)n⩾1 is non-negative and predictable so, by Proposition 8.13, (V ◦ X)n, n ⩾ 0 is a supermartingale. We\nwrite Un = Un([a, b], X) and compute directly:\n\nVk(Xk − Xk−1)\n\n(V ◦ X)n =\n\n=\n\nn\n∑\nk=1\nUn\n∑\ni=1\n\n(Xτi − Xρi) + 1{ρUn+1<n}(Xn − XρUn+1)\n\n⩾ (b − a)Un − (Xn − a)−.\n\nFor the last step, note that if indicator function in (37) is non-zero, then ρUn+1 < ∞, so XρUn+1\nXn − XρUn+1\n\n⩾ Xn − a ⩾ −(Xn − a)−. Taking expectations in (38),\n\n0 = E[(V ◦ X)0] ⩾ E[(V ◦ X)n] ⩾ (b − a)E[Un] − E[(Xn − a)−]\n\nand rearranging gives the result.\n\n(37)\n\n(38)\n\n⩽ a. Hence\n\nOne way to show that a sequence of real numbers converges as n → ∞ is to show that it doesn’t oscillate too\n\nwildly; this can be expressed in terms of upcrossings as follows.",
    "Lemma 8.27. A real sequence x = (xn) converges to a limit in [−∞, ∞] if and only if U([a, b], x) < ∞ for all\na, b ∈ Q with a < b.\n\nProof. From the definitions/basic analysis, x converges if and only if lim inf xn = lim sup xn.\n\n(i) If U([a, b], x) = ∞, then\n\nand so x does not converge.\n\n(ii) If x does not converge, then we can choose rationals a and b with\n\nlim inf\nn→∞\n\nxn ⩽ a < b ⩽ lim sup\nn→∞\n\nxn\n\nand then U([a, b], x) = ∞.\n\nlim inf\nn→∞\n\nxn < a < b < lim sup\n\nn→∞\n\nxn,\n\nA supermartingale X is just a random sequence; by Doob’s Upcrossing Lemma we can bound the expected\nnumber of upcrossings of [a, b] that it makes for any a < b and so our hope is that we can combine this with",
    "Lemma 8.27 to show that the random sequence (Xn) converges. This is our next result.\n\nPage 84\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales",
    "Definition 8.28. Let (Xn) be a sequence of random variables on a probability space (Ω, F , P), and let p ⩾ 1.\nWe say that (Xn) is bounded in Lp if\n\nE[|Xn|p] < ∞.\n\nsup\nn\n\nNote that the condition says exactly that the set {Xn : n ⩾ 0} of random variables is a bounded subset of\n\nLp(Ω, F , P): there is some K such that ||Xn||p ⩽ K for all n.",
    "Theorem 8.29 (Doob’s Forward Convergence Theorem). Let X be a sub- or super- martingale on a filtered\nprobability space (Ω, F , (Fn)n⩾0, P). If X is bounded in L1 then (Xn)n⩾0 converges a.s to a limit X∞, and X∞ is\nintegrable.\n\nProof. Considering (−Xn) if necessary, we may suppose without loss of generality that X = (Xn) is a super-\nmartingale.\n\nFix rationals a < b. Then by Doob’s Upcrossing Lemma\n\nE[Un([a, b], X)] ⩽\n\nE[(Xn − a)−]\nb − a\n\n⩽\n\nE[|Xn|] + |a|\nb − a\n\n.\n\nSince Un(· · · ) ↑ U(· · · ) as n → ∞, by the Monotone Convergence Theorem\n\nE[U([a, b], X)] = lim\nn→∞\n\nE[Un([a, b], X)] ⩽ supn\n\nE[|Xn|] + |a|\nb − a\n\n< ∞.\n\nHence P[U([a, b], X) = ∞] = 0. Since Q is countable, it follows that\n\n(cid:105)\n(cid:104)\n∃ a, b ∈ Q, a < b, s.t. U([a, b], X) = ∞\n\nP\n\n= 0.\n\nSo by Lemma 8.27 (Xn)n⩾0 converges a.s. to some X∞. (Specifically, we may take X∞ = lim inf Xn, which is\nalways defined, and measurable.) It remains to check that X∞ is integrable. Since |Xn| → |X∞| a.s., Fatou’s\nLemma gives\n\nE[|X∞|] = E(cid:2)lim inf\n\nn→∞\n\n|Xn|(cid:3) ⩽ lim inf\nn→∞\n\nE[|Xn|] ⩽ sup\nn\n\nE[|Xn|],\n\nwhich is finite by assumption.\n\nRemark. Warning: the above does not say that Xn converge to X in L 1. In particular, it does not say that\nE[Xn] → E[X]. This, in general, is false, as Example 8.31 below demonstrates.",
    "Corollary 8.30. If (Xn)n⩾0 is a non-negative supermartingale, then X∞ = limn→∞ Xn exists a.s. and is integrable.\n\nProof. Since E[|Xn|] = E[Xn] ⩽ E[X0] we may apply Theorem 8.29.\n\nOf course, the result holds for any supermartingale bounded below by a constant, and for any submartingale\nbounded above by a constant. The classic example of a non-negative supermartingale is your bankroll if you\nbet in a (realistic) casino, where all bets are at unfavourable (or, unrealistically, neutral) odds, and you can’t bet\nmore than you have. Here is another example.",
    "Example 8.31 (Galton–Watson branching process). Recall Definition 0.1: let X be a non-negative integer valued\nrandom variable with 0 < m = E[X] < ∞. Let (Xn,r)n,r⩾1 be an array of i.i.d. random variables with the same\ndistribution as X. Set Z0 = 1 and\n\nZn+1 =\n\nZn\n∑\nr=1\n\nXn+1,r =\n\n∞\n∑\nr=1\n\nXn+1,r1{Zn⩾r}\n\nPage 85\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nso Zn+1 is the number of individuals in generation (n + 1) of our branching process. Finally, let Mn = Zn/mn,\nand let Fn = σ ({Xi,r : i ⩽ n, r ⩾ 1}). By cMCT (which applies since everything is non-negative)\n\nE[Zn+1 | Fn] =\n\n=\n\n=\n\n=\n\n∞\n∑\nr=1\n∞\n∑\nr=1\n∞\n∑\nr=1\n∞\n∑\nr=1\n\nE[1{Zn⩾r}Xn+1,r | Fn] a.s.\n\n1{Zn⩾r}E[Xn+1,r | Fn] a.s.\n\n(taking out what is known)\n\n1{Zn⩾r}E[Xn+1,r] a.s.\n\n(independence)\n\n1{Zn⩾r}m = Znm,\n\nand in particular Zn, Mn are both integrable. Clearly, both are Fn-measurable and E[Mn+1 | Fn] = Mn a.s. We\nconclude that (Mn)n⩾0 is a non-negative martingale and, by Corollary 8.30, it converges a.s. to a finite limit M∞.\nDoes it converge in any other sense?\n\nIf m < 1 then by the above (Zn)n⩾0 is a non-negative supermartingale and hence also converges a.s. to a finite\nlimit Z∞. But since Mn = Zn/mn converges, we necessarily have Z∞ = 0 a.s. Since Zn is integer valued it has to\nbe equal to 0 from some point onwards, i.e., Zn = 0 a.s., for n ⩾ τ, where τ = τ(ω) is the extinction time which\nwe conclude has to be finite a.s. Note that τ = inf{n : Zn = 0} is a stopping time.\n\nIt follows that M∞ = 0 a.s. as well since Mn = 0 for n ⩾ τ. In particular, Mn does not converge to M∞ in L 1\n\nby Lemma 4.14, and hence also not in any other L p for p > 1 by Lemma 5.13.\n\nWhat is happening for our subcritical branching process is that although for large n, Mn is very likely to be\nzero, if it is not zero then it is very big with sufficiently high probability that E[Mn] is constant and does not\nconverge to 0. This mirrors what we saw with sequences in Example 5.3. Finally note that, by Theorem 5.24,\nwe can also conclude that {Mn : n ⩾ 0} is not Uniformly Integrable.\n\n8.5 Uniformly integrable martingales\n\nWe have done most of the work in §5.4. It remains to use it in conjunction with what we already know about\nmartingales. We say that a martingale M = (Mn)n⩾0 is uniformly integrable to indicate that the family of random\nvariables {Mn : n ⩾ 0} is UI.",
    "Theorem 8.32. Let (Mn)n⩾0 be a martingale on a filtered probability space (Ω, F , (Fn)n⩾0, P). TFAE\n\n(i) M is uniformly integrable,\n\n(ii) there is some F∞-measurable random variable M∞ such that Mn → M∞ almost surely and in L 1,\n\n(iii) there is an integrable F∞-measurable random variable M∞ such that Mn = E[M∞ | Fn] a.s. for all n.\n\nFurther, under these conditions, if M∞ ∈ L p for p > 1 then the convergence Mn → M∞ also holds in L p.\n\nProof. (i) =⇒ (ii): M is UI so in particular, by Proposition 5.22, bounded in L 1 and hence, by Doob’s Forward\nConvergence Theorem (Theorem 8.29) it converges a.s. to some integrable M∞. Since a.s. convergence implies\nconvergence in probability, Mn → M∞ in L1 by Theorem 5.24. Each Mn is F∞-measurable and hence so is M∞\nby Proposition 1.24.\n\n(ii) =⇒ (iii): Since (Mn) is a martingale, for m ⩾ n, we have\n\nE[Mm | Fn] = Mn\n\na.s.,\n\nPage 86\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nso, by the defining relation (24) for the conditional expectation,\n\nE[Mm1A] = E[Mn1A],\n\nfor all A ∈ Fn.\n\nSince\n\nit follows that\n\n(cid:12)E[M∞1A] − E[Mm1A](cid:12)\n(cid:12)\n\n(cid:12) ⩽ E[|(M∞ − Mm)1A|] ⩽ E[|M∞ − Mm|] → 0,\n\nE[M∞1A] = E[Mn1A]\n\nfor all A ∈ Fn.\n\nSince Mn is Fn-measurable, this shows that Mn = E[M∞ | Fn] a.s.\n\n(iii) =⇒ (i) by Theorem 6.11.\nThe last assertion follows instantly from the Dominated Convergence Theorem and Theorem 8.33 below.\n\nWe now extend the optional sampling theorem as well as the maximal and Lp inequalities to the setting of\n\nUI martingales.",
    "Theorem 8.33. On a filtered probability space (Ω, F , (Fn)n⩾0, P), let M be a UI martingale so that Mn =\nE[M∞ | Fn] for some M∞ ∈ L 1(Ω, F∞, P). Then for any stopping times τ ⩽ ρ\n\nE[Mρ | Fτ ] = Mτ a.s.\n\n(39)\n\nand in particular E[Mτ ] = E[M0].\nFurther, Doob’s maximal and Lp inequalities extend to n = ∞. Specifically, with M∗\n\n∞ = maxn⩾0 |Mn| we have\n\n⩾ λ ] ⩽ E[|M∞|1{M∗\nFurther, if M∞ ∈ L p for some p > 1 then, with p−1 + q−1 = 1,\n\nλ P[M∗\n∞\n\n∞\n\n⩾λ }],\n\n∥M∞∥p ⩽ ∥M∗\n\n∞∥p ⩽ q∥M∞∥p\n\nand Mn → M∞ in L p.\n\nDeep Dive\n\nλ ⩾ 0.\n\n(40)\n\n(41)\n\nProof. First note that if τ is bounded, τ ⩽ n and ρ = ∞ then by Theorem 8.17\n\nMτ = E[Mn | Fτ ] = E[E[M∞ | Fn] | Fτ ] = E[M∞ | Fτ ].\n\nIt remains the establish the same for any stopping time τ and ρ = ∞ as the general case then follows by the\ntower property.\n\nLet A ∈ Fτ and note that A ∩ {τ ⩽ n} is in Fn, by definition of Fτ , but also in Fτ∧n as is easy to verify.\n\nThen\n\nE[M∞1A∩{τ<∞}] = lim\nn→∞\n\nE[M∞1A∩{τ⩽n}] = lim\nn→∞\n\nE[Mτ∧n1A∩{τ⩽n}] = E[Mτ 1A∩{τ<∞}],\n\nwhere the first equality follows by the MCT, the second follows since we already have the desired property for\nbounded stopping times and the last equality is a consequence of Theorem 5.24 thanks to uniform integrability\nof the family Mτ∧n = E[M∞ | Fτ∧n], n ⩾ 0, (by Theorem 6.11) and a.s. convergence Mτ∧n1A∩{τ⩽n} → Mτ 1A\n(and hence also in probability). Finally, the equality E[M∞1A∩{τ=∞}] = E[Mτ 1A∩{τ=∞}] is obvious. This\nestablishes (39).\n\nWe turn to the two remaining assertions. By conditional Jensen’s inequality (|Mn|)0⩽n⩽∞ is a submartin-\n\ngale. By Doob’s maximal inequality, Theorem 8.21, with M∗\n\nn = maxk⩽n |Mk|, we have\n\nλ P(cid:2)M∗\nn\n\n⩾ λ (cid:3) ⩽ E[|Mn|1{M∗\n\nn\n\n⩾λ }] ⩽ E[|M∞|1{M∗\n\nn\n\n⩾λ }]\n\nPage 87\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n⩾ λ } ∈ Fn and E[|M∞| | Fn] ⩾ |Mn|. Taking the limit in n → ∞, using MCT on the left and DCT\nsince {M∗\nn\non the right, we see that the maximal inequality (40) holds as required. Suppose now that M∞ ∈ L p for some\np > 1. Then Doob’s Lp inequality (41) follows by Lemma 5.15. It shows in particular that |Mn|p ⩽ (M∗\n∞)p ∈\nL 1 and hence Mn → M∞ in L p by the DCT.\n\nPage 88\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n9 Some applications of the martingale theory\n\n9.1 Backwards Martingales and the Strong Law of Large Numbers\n\nSo far our martingales were sequences (Mn) of random variables on (Ω, F , P) defined for all integers n ⩾ 0.\nBut in fact the definition makes just as good sense for any ‘interval’ I of integers. The conditions are that\nfor every t ∈ I we have a σ -algebra Ft ⊆ F (information known at time t) and an integrable, Ft-measurable\nrandom variable Mt, with E[Mt+1 | Ft] = Mt a.s. Note that we already implicitly considered the finite case\nI = {0, 1, 2, . . . , N}.\n\nBackwards martingales are martingales for which time is indexed by I = {t ∈ Z : t ⩽ 0}. The main difficulty\nis deciding whether to write (Mn)n⩽0 or (M−n)n⩾0. From now on we write the latter. Note that a backwards\nmartingale ends at time 0. This instantly reminds us of UI martingales in Theorem 8.32 and makes our life\neasier.",
    "Definition 9.1. Given σ -algebras (F−n)n⩾0 with F−n ⊆ F and\n\n· · · ⊆ F−(n+1) ⊆ F−n ⊆ · · · ⊆ F−2 ⊆ F−1 ⊆ F0,\n\na backwards martingale w.r.t. (F−n) is a sequence (M−n)n⩾0 of integrable random variables, each M−n is F−n-\nmeasurable and\n\nE[M−n+1 | F−n] = M−n\n\na.s.\n\nfor all n ⩾ 1.\n\nFor any backwards martingale, we have\n\nE[M0 | F−n] = M−n\n\na.s.\n\nSince M0 is integrable, it follows from Theorem 6.11 that (M−n)n⩾0 is automatically uniformly integrable.\n\nDoob’s Upcrossing Lemma (Lemma 8.26), dealt with martingales on a finite set of time points. We can\napply it to (M−m, M−m+1, . . . , M−1, M0), to see that if Um([a, b], M) is the number of upcrossings of [a, b] by the\nbackwards martingale between times −m and 0, then\n\nE[Um([a, b], M)] ⩽\n\nE[(M0 − a)−]\nb − a\n\n.\n\n(42)\n\nMimicking the proof of Doob’s Forward Convergence Theorem (Theorem 8.29), we let m → ∞ and use Mono-\ntone Convergence Theorem to conclude that U([a, b], M) = U∞([a, b], M) is integrable and hence finite a.s.",
    "Lemma 8.27 then shows that M−n converges a.s. to M−∞ := lim infn→∞ M−n. Recall that as n increases F−n\ndecrease, so that M−∞ is F−n-measurable for all n ⩾ 0 and hence also measurable with respect to\n\nF−∞ =\n\n∞\n(cid:92)\n\nk=0\n\nF−k.\n\nSince (M−n) is uniformly integrable, adapting the proof of Theorem 8.32 gives the following result.",
    "Theorem 9.2. Let (M−n)n⩾0 be a backwards martingale w.r.t. (F−n)n⩾0. Then M−n converges a.s. and in L1 as\nn → ∞ to the random variable M−∞ = E[M0 | F−∞].\n\nNote that we can replace M0 by any other fixed element of the sequence: M−∞ = E[M−k | F−∞] for all k ⩾ 0.\n\nWe now use this result to prove the celebrated Kolmogorov’s Strong Law.\n\nPage 89\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales",
    "Theorem 9.3 (Kolmogorov’s Strong Law of Large Numbers). Let (Xn)n⩾1 be a sequence of i.i.d. random vari-\nables each of which is integrable and has mean m, and set\n\nThen\n\nProof. For n ⩾ 1 set\n\nSn =\n\nn\n∑\nk=1\n\nXk.\n\nSn\nn\n\nn→∞−→ m a.s. and in L 1.\n\nF−n = σ (Sn, Sn+1, Sn+2, . . .) = σ (Sn, Xn+1, Xn+2, . . .),\nnoting that F−n−1 ⊆ F−n. Conditioning on F−n preserves the symmetry between X1, . . . , Xn, since none of\nSn, Sn+1, . . . is affected by permuting X1, . . . , Xn. Hence,\n\nE[X1 | F−n] = E[X2 | F−n] = · · · = E[Xn | F−n]\n\nand so they are all equal (a.s.) to their average:\n\n1\nn\nLet M−n = Sn/n. Then, for n ⩾ 2,\n\nE[Xi | F−n] =\n\nE[X1 + · · · + Xn | F−n] =\n\n1\nn\n\nE[Sn | F−n] =\n\n1\nn\n\nSn,\n\n1 ⩽ i ⩽ n.\n\nE[M−n+1 | F−n] =\n\n1\nn − 1\n\nE[Sn−1 | F−n] =\n\n1\nn − 1\n\nn−1\n∑\ni=1\n\nE[Xi | F−n] =\n\nSn\nn\n\n= M−n.\n\nIn other words, (M−n)n⩾1 is a backwards martingale w.r.t. (F−n)n⩾1. Thus, by Theorem 9.2, Sn/n converges\na.s. and in L1 to M−∞ = E[M−1 | F−∞], where F−∞ = (cid:84)\n\nk⩾1\nNow by L1 convergence, E[M−∞] = limn→∞ E[M−n] = E[M−1] = E[S1] = m. In terms of the random variables\nX1, X2, . . . , the limit M−∞ = lim inf Sn/n is a tail random variable, so by Kolmogorov’s 0-1 law (Theorem 3.14)\nit is a.s. constant, so M−∞ = m a.s.\n\nF−k.\n\nDeep Dive\n\n9.2 Exchangeability and the ballot theorem\n\nThe material in §9.2 is not part of the “examinable syllabus”. You won’t be asked to reproduce these results\ndirectly. However, just like many of the problem sheet questions, the methods help to develop your intuition\nfor the ideas of the course.\n\nIn our proof of the Strong Law of Large Numbers we used symmetry in a key way. There it followed\n\nfrom independence of our random variables, but in general a weaker condition suffices.",
    "Definition 9.4 (Exchangeability). The random variables X1, . . . , Xn are said to be exchangeable if the vector\n(Xi1, . . . , Xin) has the same probability distribution for every permutation i1, . . . , in of 1, . . . , n.",
    "Example 9.5. Let X1, . . . , Xn be the results of n successive samples without replacement from a pool of at\nleast n values (some of which may be the same). Then the random variables X1, . . . , Xn are exchangeable but\nnot independent.\n\nIt turns out that we can use the construction in the proof of the Strong Law of Large Numbers to manu-\nfacture a finite martingale from a finite collection of exchangeable random variables. Suppose that X1, . . . , Xn\n\nPage 90\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nare exchangeable and integrable, and set S j = ∑\n\nj\ni=1 Xi. Let\n\nZ j = E[X1 | σ (Sn+1− j, . . . , Sn−1, Sn)],\n\nj = 1, 2, . . . n.\n\nNote that Z j is defined by conditioning on the last j sums; since we condition on more as j increases, (Z j)n\nis certainly a martingale. Now\n\nj=1\n\nSn+1− j = E[Sn+1− j | σ (Sn+1− j, . . . , Sn)]\n\n=\n\nn+ j−1\n∑\ni=1\n\nE[Xi | σ (Sn+1− j, . . . , Sn)]\n\n= (n + 1 − j)E[X1 | σ (Sn+1− j, . . . , Sn)]\n= (n + 1 − j)Z j,\n\n(by exchangeability)\n\nso Z j = Sn+1− j/(n + 1 − j).",
    "Definition 9.6. The martingale\n\nZ j =\n\nSn+1− j\nn + 1 − j\n\n,\n\nj = 1, 2, . . . , n,\n\nis sometimes called Doob’s backward martingale.",
    "Example 9.7 (The ballot problem). In an election between candidates A and B, candidate A receives n votes\nand candidate B receives m votes, where n > m. Assuming that in the count of votes all orderings are equally\nlikely, what is the probability that A is always ahead of B during the count?\n\nSolution:\n\nLet Xi = 1 if the ith vote counted is for A and −1 if the ith vote counted is for B, and let Sk = ∑k\n\ni=1 Xi.\n\nBecause all orderings of the n + m votes are equally likely, X1, . . . , Xn+m are exchangeable, so\n\nZ j =\n\nSn+m+1− j\nn + m + 1 − j\n\n,\n\nj = 1, 2, . . . , n + m,\n\nis a Doob backward martingale.\n\nBecause\n\nZ1 =\n\nSn+m\nn + m\n\n=\n\nn − m\nn + m\n\n,\n\nthe mean of this martingale is (n − m)/(n + m).\n\nBecause n > m, either (i) A is always ahead in the count, or (ii) there is a tie at some point. Case (ii)\n\nhappens if and only if some S j = 0, i.e., if and only if some Z j = 0.\n\nDefine the bounded stopping time τ by\n\nτ = min{ j ⩾ 1 : Z j = 0 or j = n + m}.\n\nIn case (i), Zτ = Zn+m = X1 = 1. (If A is always ahead, he must receive the first vote.) Clearly, in case (ii),\nZτ = 0, so\n\n(cid:26) 1 if A is always ahead,\n\nZτ =\n\n0 otherwise.\n\nPage 91\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nBy Theorem 8.17, E[Zτ ] = (n − m)/(n + m) and so\n\nP[A is always ahead] =\n\nn − m\nn + m\n\n.\n\n(cid:50)\n\n9.3 Azuma-Hoeffding inequality and concentration of Lipschitz functions\n\nThe material in §9.3 is not part of the “examinable syllabus”. You won’t be asked to reproduce any of these\nresults directly. However, the methods involved are very good illustrations of ideas from earlier in the course:\nparticularly the Doob martingale ideas involved in Theorem 9.12 and its applications.\n\nBy applying Markov’s inequality to the moment generating function, we can get better bounds than we\n\nget from the mean and variance alone.",
    "Lemma 9.8.\n\n(i) Let Y be a random variable with mean 0, taking values in [−c, c]. Then\n\nE[eθY ] ⩽ exp\n\n(cid:19)\n\n.\n\nθ 2c2\n\n(cid:18) 1\n2\n\n(ii) Let G be a σ -algebra, and Y be a random variable with E[Y |G ] = 0 a.s. and Y ∈ [−c, c] a.s. Then\n\nE[eθY | G ] ⩽ exp\n\n(cid:19)\n\nθ 2c2\n\n(cid:18) 1\n2\n\na.s.\n\nProof. Let f (y) = eθ y. Since f is convex,\n\nfor all y ∈ [−c, c]. Then taking expectations,\n\nf (y) ⩽ c − y\n2c\n\nf (−c) +\n\nc + y\n2c\n\nf (c)\n\nE[ f (Y )] ⩽ E\n\n(cid:20) c −Y\n2c\n\nf (−c) +\n\n(cid:21)\n\nf (c)\n\nc +Y\n2c\n\nf (c)\n\n=\n\n=\n\nf (−c) +\n\n1\n2\ne−θ c + eθ c\n2\n\n1\n2\n\n.\n\nNow, comparing Taylor expansions term by term,\n\ne−θ c + eθ c\n2\n\n=\n\n∞\n∑\nn=0\n\n(θ c)2n\n(2n)!\n\n⩽\n\n∞\n∑\nn=0\n\n(θ c)2n\n2nn!\n\n= exp\n\n(cid:19)\n\n.\n\nθ 2c2\n\n(cid:18) 1\n2\n\ngiving part (i).\n\nFor the conditional version of the statement, consider any G ∈ G with P[G] > 0. Then E[Y 1G] = 0, so\n\nE[Y | G] = 0. Applying part (i) with probability measure P[. | G], we obtain E[eθY | G] ⩽ exp (cid:0) 1\n\nNow consider the G-measurable set G := {ω : E[eθY |G ](ω) > exp (cid:0) 1\nprobability, it contradicts the previous paragraph. So indeed E[eθY | G ] ⩽ exp (cid:0) 1\n\n2 θ 2c2(cid:1)}.\n\n2 θ 2c2(cid:1).\nIf this set has positive\n2 θ 2c2(cid:1) a.s. as required.\n\nPage 92\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales",
    "Lemma 9.9. Suppose M is a martingale with M0 = 0 and |Mn − Mn−1| ⩽ c a.s. for all n. Then\n\n(cid:104)\neθ Mn\n\n(cid:105)\n\nE\n\n⩽ exp\n\n(cid:19)\n\n.\n\nθ 2c2n\n\n(cid:18) 1\n2\n\nProof. Let Wn = eθ Mn, so that Wn is non-negative and Wn = Wn−1eθ (Mn−Mn−1).\nThen applying Lemma 9.8(ii) with Y = Mn − Mn−1 and G = Fn=1,\n\nE(Wn | Fn−1) = Wn−1E\n\n(cid:105)\n\n(cid:104)\neθ (Mn−Mn−1) | Fn−1\n(cid:18) 1\n(cid:19)\n2\n\nθ 2c2\n\na.s.\n\n⩽ Wn−1 exp\n\nTaking expectations we obtain E[Wn] ⩽ exp (cid:0) 1\n\n2 θ 2c2(cid:1) E[Wn−1] and the result follows by induction.",
    "Theorem 9.10 (Simple version of the Azuma-Hoeffding inequality). Suppose M is a martingale with M0 = 0\nand |Mn − Mn−1| ⩽ c a.s. for all n. Then\n\nP(Mn ⩾ a) ⩽ exp\n\n(cid:18)\n\n−\n\n(cid:19)\n\n,\n\n1\n2\n\na2\nc2n\n\nP(|Mn| ⩾ a) ⩽ 2 exp\n\n(cid:18)\n\n−\n\n(cid:19)\n\n.\n\n1\n2\n\na2\nc2n\n\nand\n\nProof.\n\nP(Mn ⩾ a) ⩽ P\n\n(cid:16)\neθ Mn ⩽ eθ a(cid:17)\n(cid:18) 1\n2\n\nθ 2c2\n\n⩽ e−θ a exp\n\n(cid:19)\n\nusing Markov’s inequality. Now we are free to optimise over θ . The RHS is minimised when θ = a/(c2n),\ngiving the required bound.\n\nThe same argument applies replacing M by the martingale −M. Summing the two bounds then gives the\n\nbound for |M|.\n\nWe now introduce the idea of discrete Lipschitz functions.",
    "Definition 9.11. Let h be a function of n variables. The function h is said to be c-Lipschitz, where c > 0, if\nchanging the value of any one coordinate causes the value of h to change by at most c. That is, whenever\nx = (x1, . . . , xn) and y = (y1, . . . , yn) differ in at most one coordinate, then |h(x) − h(y)| ⩽ c.",
    "Theorem 9.12 (Concentration of discrete Lipschitz functions). Suppose h is a c-Lipschitz function, and\nX1, . . . , Xn are independent random variables. Then\n\nP (|h(X1, . . . , Xn) − E[h(X1, . . . , Xn)]| ⩾ a) ⩽ 2 exp\n\n(cid:18)\n\n−\n\n(cid:19)\n\n.\n\n1\n2\n\na2\nc2n\n\nPage 93\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nProof. The proof is based on the idea of the Doob martingale. We reveal information about the underly-\ning random variables X1, . . . , Xn one step at a time, gradually acquiring a more precise idea of the value\nh(X1, . . . , Xn).\n\nFor 0 ⩽ k ⩽ n, let Fk = σ (X1, . . . , Xk), and let\n\nMk = E[h(X1, . . . , Xn) | Fk] − E[h(X1, . . . , Xn)].\n\nThen M0 = 0, and Mn = h(X1, . . . , Xn) − E[h(X1, . . . , Xn)].\n\nWe claim |Mk+1 − Mk| ⩽ c a.s. To show this, let (cid:98)Xk+1 be a random variable with the same distribution as\n\nXk+1, which is independent of X1, . . . , Xn.\n\nThen\n\nE[h(X1, . . . , Xk, Xk+1, . . . , Xn) | Fk]\n= E[h(X1, . . . , Xk, (cid:98)Xk+1, . . . , Xn) | Fk]\n= E[h(X1, . . . , Xk, (cid:98)Xk+1, . . . , Xn) | Fk+1].\n\nThis gives\n\nMk+1 − Mk = E[h(X1, . . . , Xk, (cid:98)Xk+1, . . . , Xn) − h(X1, . . . , Xk, Xk+1, . . . , Xn) | Fk+1].\n\nBut the difference between the two values of h inside the conditional expectation on the RHS is in [−c, c],\nso we obtain |Mk+1 − Mk| ⩽ c a.s. as required. Now the required estimate for Mn follows from the Azuma-\nHoeffding bound (Theorem 9.10).\n\nThe examples below of the application of Theorem 9.12 show that martingale methods can be applied to\n\nproblems far away from what one might think of as “stochastic process theory”.",
    "Example 9.13 (Longest common subsequence). Let X = (X1, X2, . . . , Xm) and Y = (Y1,Y2, . . . ,Ym) be two\nindependent sequences, each with independent entries.\n\nLet Lm be the length of the longest sequence which is a subsequence (not necessarily consecutive) of both\n\nsequences.\n\nFor example, if m = 12 and X =“CAGGGTAGTAAG” and Y =“CGTGTGAAAACT” then both X and\n\nY contain the substring “CGGTAAA”, and Lm = 7.\n\nChanging a single entry can’t change the length of the longest common subsequence by more than 1. We\n\ncan apply Theorem 9.12 with n = 2m and c = 1, to get\n\nP(|Lm − E[Lm]| ⩾ a) ⩽ 2 exp\n\n(cid:18)\n\n−\n\n(cid:19)\n\n.\n\na2\n4m\n\nWe obtain that for large m, “typical fluctuations” of Lm around its mean are on the scale at most\n\n√\n\nm.\n\nNote that we didn’t require the sequences X and Y to have the same distribution, or for the entries of each\n\nsequence to be identically distributed.\n\nAs suggested by the choice of strings above, longest common subsequence problems arise for example\nin computational biology, involving the comparison of DNA strings (which evolve via mutation, insertion or\ndeletion of individual nucleotides).",
    "Example 9.14 (Minimum-length matching). Suppose there are m red points in the box [0, 1]2 ⊂ R2, with\npositions R1, . . . , Rm, and m blue points with positions B1, . . . , Bm.\n\nPage 94\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nLet X be the length of the minimal-length matching, which joins pairs consisting of one blue and one red\n\npoint. That is,\n\nXm = min\n\nm\n∑\nk=1\n\n∥Rk − Bik ∥,\n\nwhere the minimum is taken over all permutations i1, i2, . . . , im of 1, 2, . . . , m, and ∥r − b∥ denotes Euclidean\ndistance between r and b.\n\nAlternatively let Y be the length of the minimal-length alternating tour, a path which visits all 2m points,\n\nalternating between red and blue, and returning to its starting point:\n\nYm = min\n\n(cid:40) m\n∑\nk=1\n\n∥Rik − B jk ∥ +\n\nm−1\n∑\nk=1\n\n∥B jk − Rik+1∥ + ∥B jm − Ri1∥\n\n,\n\n(cid:41)\n\nwhere now the minimum is over all pairs of permutations i1, i2, . . . , im and j1, j2, . . . , jm of 1, 2, . . . , m.\n\nMoving a single point cannot change Xm by more than\n\n2.\nIf the positions of the points are independent, then applying Theorem 9.12 with n = 2m and the appropriate\nvalue of c, we obtain\n\n2, and cannot change Ym by more than 2\n\n√\n\n√\n\nP(|Xm − E[Xm]| ⩾ a) ⩽ 2 exp\n\nP(|Ym − E[Ym]| ⩾ a) ⩽ 2 exp\n\n(cid:18)\n\n−\n\n(cid:18)\n\n−\n\n(cid:19)\n\na2\n8m\na2\n32m\n\n(cid:19)\n\n.\n\n√\n\nAgain this gives concentration of Xm and Ym around their means on the scale of\n\nm. This may be a poor\nbound; for example if all the points are i.i.d. uniform on the box [0, 1]2, then in fact the means themselves\nm as m → ∞. However, we didn’t assume identical distribution. For example we might have red\ngrow like\npoints uniform on the left half [0, 1/2] × [0, 1], and blue points uniform on the right half [1/2, 1] × [0, 1], in\n√\nwhich case the means grow linearly in m, and the O(\n\nm) fluctuation bound is more interesting.\n\n√",
    "Example 9.15 (Chromatic number of a random graph). The Erd¨os-R´enyi random graph model G(N, p) con-\nsists of a graph with N vertices, in which each edge (out of the (cid:0) N\n(cid:1) possible edges) appears independently\n2\nwith probability p. If p = 1/2, then the graph is uniformly distributed over all possible graphs with N vertices.\nThe chromatic number χ(G) of a graph G is the minimal number of colours needed to colour the vertices\n\nof G so that any two adjacent vertices have different colours.\n\nConsider applying Theorem 9.12 to the chromatic number χ(G) of a random graph G ∼ G(N, 1/2).\n(cid:1) independent Bernoulli random variables, each one encoding the\nWe could write χ(G) as a function of (cid:0) N\n2\npresence or absence of a given edge. Adding or removing a single edge cannot change the chromatic number\nby more than 1. This would give us a fluctuation bound on χ(G) on the order of N as N → ∞. However,\nfor large N this is an extremely poor, in fact trivial, result, since χ(G) itself is known to be on the order of\nN/ log(N).\n\nWe can do much better. For 2 ⩽ k ⩽ N, let Xk consist of a collection of k − 1 Bernoulli random vari-\nables, encoding the presence or absence of the k − 1 edges {1, k}, {2, k}, . . . , {k − 1, k}. It’s still the case that\nX2, . . . , XN are independent. All the information in Xk concerns edges that intersect the vertex k; changing the\nstatus of any subset of these edges can only change the chromatic number by at most 1 (consider recolouring\nvertex k as necessary). The Doob martingale from the proof of Theorem 9.12 involves revealing information\nabout the graph vertex by vertex, rather than edge by edge, and is called the vertex exposure martingale.\n\nPage 95\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nApplying the theorem with n = N − 1 and c = 1, we obtain\n\nP (|χ(G) − E[χ(G)]| ⩾ a) ⩽ 2 exp\n\n(cid:18)\n\n−\n\na2\n2(N − 1)\n\n(cid:19)\n\n,\n\ngiving a concentration bound on the scale of\n\n√\n\nN for large N.\n\n9.4 The Law of the Iterated Logarithm",
    "Theorem 9.16 (Khinchine/Kolmogorov). Let X1, X2, . . . be i.i.d. with mean 0 and variance 1. Let Sn = ∑n\nn ⩾ 1. Then, almost surely,\n\ni=1 Xi,\n\nlim sup\nn→∞\n\n√\n\nSn\n2n log log n\n\n= 1,\n\nlim inf\nn→∞\n\n√\n\nSn\n2n log log n\n\n= −1.\n\nThe above was shown in the 1920ties. It was subsequently extended to continuous time and Brownian\nmotion in 1940ties. Then Strassen, who was interested in invariance principles and embeddings, established\na beautiful extension of LIL in 1964. We follow Williams’ exposition. Let St be the linear interpolation of\n(Sn), i.e.,\n\nSt(ω) = (t − n)Sn+1(ω) + (n − t + 1)Sn(ω),\n\nt ∈ [n, n + 1),\n\nand consider a LIL rescaling shrunk to interval [0, 1]:\n\nZn(t, ω) :=\n\n√\n\nStn(ω)\n2n log log n\n\n,\n\nt ∈ [0, 1].\n\nLIL tells us that as for any sequence nk → ∞, the final value of the transformed path Znk (1, ω) will stay within\n[−1, 1] a.s., and for a.s. every ω, we can find a sequence nk(ω) which attains 1, and another one which hits −1.\nStrassen’s version tells something about the whole path of Z! Let K(ω) be the set of functions f : [0, 1] → R\nsuch that there exists a sequence nk(ω) with\n\nLet Γ be the set of functions f : [0, 1] → R which are of the form\n\nZn(t, ω) → f (t),\n\nuniformly in t ∈ [0, 1].\n\nf (t) =\n\n(cid:90) t\n\n0\n\nh(s)ds, where\n\n(cid:90) 1\n\n0\n\nh(s)2 ds ⩽ 1.\n\nA simple application of H¨older’s inequality gives\n\n| f (1)| ⩽\n\n(cid:115)\n\n(cid:90) 1\n\n0\n\nh(s)2 ds\n\n(cid:115)\n\n(cid:90) 1\n\n0\n\nds ⩽ 1,\n\nwith equality attained by the paths f (t) = t and f (t) = −t. Strassen discovered that a.s., each path can attain\nall functions in Γ when we consider all possible sequences!",
    "Theorem 9.17 (Strassen). We have\n\nP(K = Γ) = 1.\n\nPage 96\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nNote that our definition of K above as bit informal. It is a set-valued random variable but we did not make\nit clear where it was taking values and in what sense it was measurable. Strassen’s result is remarkable in\nmany ways. For starters, the fact that K is a.s. valued in paths which are absolutely continuous is not clear. In\nfact, if we consider\n\nBn(t, ω) :=\n\n,\n\nt ∈ [0, 1],\n\nStn√\nn\n\nthen Donsker’s theorem says that Bn converges in distribution, as a random variable taking values in continu-\nous paths on [0, 1], to a Brownian motion. This process, as you will learn in B8.2, has paths which are a.s. of\ninfinite variation and can not be represented as a Lebesgue integral. Naturally, the amazing part of Strassen’s\nresult is that each path, under rescaling, attains the same set of possible scaling limits a.s.\n\n9.5 Likelihood Ratio and Statistics\n\n9.6 Radon-Nikodym Theorem and changes of measure\n\nWe come back to the discussion of Radon-Nikodym Theorem, which was stated as Theorem 4.9. It is inti-\nmately linked to the topic of convergence of martingales which was explored in particular in Section 8.5.\n\nThroughout, when we need to stress the measure with respect to which the expectation is taken, we write\n\nEP. We start with a simple but slightly subtle observation.",
    "Lemma 9.18. Let (Ω, F , P) be a given probability space and G a sub-σ -algebra in F . Then ˜P = P|G , the\nmeasure P restricted to G , is a probability measure on G and\n\nfor any G -measurable random variable X.\n\nEP[X] = E ˜P[X],\n\nProof. This follows directly from Theorem 4.15, observing that P ◦ X −1 = ˜P ◦ X −1 since G -measurability of\nX precisely means that X −1(A) is in G , on which P and ˜P agree, for any Borel set A.\n\nTo start, we are going to admit Theorem 4.9 holds and show it allows us to deduce existence of conditional\n\nexpectation, Theorem 6.3.\n\nAlternative proof of Theorem 6.3. Note that we have already dealt with uniqueness from the definition of\nconditional expectation.\n\nLet ˜P = P|G denote the measure P restricted to the σ -algebra G . Recall that X is integrable. Suppose\nA X dP = EP[X1A] = E ˜P[X1A], where the last equality\nfirst that X is non-negative and for A ∈ G , let Q(A) = (cid:82)\nfollows by Lemma 9.18 above. This, as explained in the similar definition in (16), defines a finite measure Q\non (Ω, G ), with Q(Ω) = E[X] and Q ≪ ˜P. Radon-Nikodym Theorem (Thm. 4.9) then yields existence of a\nnon-negative G -measurable random variable Z such that for all A ∈ G ,\n\nQ(A) = E ˜P[Z1A] = EP[Z1A],\n\nwhere the last equality is by Lemma 9.18 above. In particular, E[Z] = Q(Ω) = E[X] < ∞. Combining this\nwith the definition of Q, we see that the defining relation (24) for the conditional expectation is satisfied and\nhence Z = E[X | G ] a.s.\n\nFor the general case, write X = X + − X − where X + and X − are the positive and negative parts of X. Then\n\nE[X + | G ] − E[X − | G ] is G -measurable and, by linearity of the integral, satisfies the defining relation.\n\nPage 97\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nLet us now consider a given filtered probability space (Ω, F , (Fn)n⩾0, P). We are interested in measures\non F∞ so subject to restricting P, we may simply assume F = F∞. Suppose Q ≪ P is a given probability\nmeasure on F . Theorem 4.9 gives us a non-negative density Z which is F -measurable and such that\n\nQ(A) = EP[Z1A], A ∈ F∞.\n\nClearly, we can also consider Q ≪ P as measures on Fn, for any n ⩾ 0, and Theorem 4.9 then gives us\nexistence of a non-negative Zn which is Fn measurable and such that\n\nQ(A) = EP[Zn1A], A ∈ Fn.\n\nIn addition, E[Zn] = Q(Ω) = 1 = E[Z]. Comparing the above displayed equations we conclude that the\ndefining relation (24) holds and Zn = E[Z | Fn] a.s. By Theorem 8.32 (Zn) is a UI martingale and Zn → Z a.s.\nand in L1.\n\nConversely, if we have a martingale (Zn) which is non-negative and E[Zn] = 1 then we can define a\n\nsequence of probability measures Qn on Fn, n ⩾ 0, which are consistent in that\n\nQn+1(A) = E[Zn+11A] = E[Zn1A] = Qn(A), A ∈ Fn,\n\nor in other words Qn = Qn+1|Fn. Note that, by Corollary 8.30, Zn → Z a.s., for some non-negative, integrable\nand F -measurable Z. In particular, we can define Q on F via Q(A) = E[Z1A]. However, to conclude that\nQ is a probability measure absolutely continuous to P and consistent with the sequence Qn in the sense that\nQn = Q|Fn is equivalent to saying that Zn = E[Z | Fn], which by Theorem 8.32, is equivalent to (Zn) being\nUI.\n\nAn important example where (Zn) is not UI is encountered in likelihood ratio test in statistics, which is\nconsidered in question 5 on problem sheet 4. Consider a biased coin which lands heads with probability p ∈\n{a, b} with 0 < a ̸= b < 1. Then for any finite number of coin tosses, the probability measures corresponding\nto the two values of p are equivalent to each other. Their R-N densities will form a martingale Zn. This\nmartingale will converge to Z∞ = 0 since in the limit, the set of full measure under one measure is a null set\nunder the other (and vice-versa: the measures are mutually singular).\n\nThe ideas above can be used to invert the relationship and to use martingale convergence to prove Theorem\n\n4.9. First, we detail a useful consequence of absolute continuity of measures.",
    "Lemma 9.19. Suppose Q ≪ P are two probability measures on F . Then\n\n∀ε > 0 ∃δ > 0 ∀A ∈ F , P(A) < δ ⇒ Q(A) < ε.\n\nProof. Suppose this is not the case. Then for some ε > 0, there exists a sequence of events (An) such that\n\nP(An) < 2−n\n\nbutQ(An) ⩾ ε,\n\nn ⩾ 1.\n\nLet B = lim sup Bn = {Bni.o.}. Then Lemma 3.19 (BC1) instantly gives P(B) = 0 but reverse Fatou for sets,",
    "Lemma 3.18, gives Q(B) ⩾ lim supn→∞\nMartingale proof of Theorem 4.9. We write ν = Q and µ = P and divide by the total mass of µ, so that P is\na probability measure.\nStep 1: separable σ -algebras.\nSuppose that F = σ (F1, F2, . . .) is generated by a countable sequence of sets. Note that we can replace F2 by\n\nQ(An) ⩾ ε which is a contradiction to Q ≪ P.\n\nPage 98\n\n\fJan Obł´oj\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\n1 , and F3 by F3 ∩ (F1 ∪ F2)c, etc., and that we can always add ((cid:83)\n\nF2 ∩ F c\ngenerality, we can assume that F = σ (A1, A2, . . .) for (An) a partition of Ω. Let Fn := σ (A1, . . . , An) and\n\nn Fn)c to the list, so that with no loss of\n\nZn =\n\nn\n∑\nk=1\n\nak1Ak , where ak =\n\nQ(Ak)\nP(Ak)\n\n1P(Ak)>0.\n\nThen, by definition, Zn is Fn-measurable and integrable since E[Zn] = Q(Ω). Further, by direct computation,\nE[Zn1A] = Q(A), for any A ∈ Fn, noting such A is in fact a finite union of atoms (Ak)k⩽n or their complements.\nWe conclude that E[Zn+11A] = E[Zn1A], A ∈ Fn and hence (Zn) is a martingale.\n\nNow, take ε > 0 and δ given via Lemma 9.19. Let K > Q(Ω)/δ . Markov’s inequality, Lemma 5.6, gives\n\nP(Zn > K) ⩽\n\nE[Zn]\nK\n\n=\n\nQ(Ω)\nK\n\n< δ , ∀n ⩾ 1.\n\nAnd hence, we obtain\n\nε > Q(Zn > K) = E[Zn1Zn>K], ∀n ⩾ 1.\nThis, be Definition 5.17, ensures UI of (Zn) and hence, by Theorem 8.32, there exists a non-negative integrable\nF -measurable Z such that Zn = E[Z | Fn]. This instantly gives us Q(A) = E[Zn1A] = E[Z1A] for A ∈ Fn and\nhence Q(A) = E[Z1A] for A ∈ (cid:83)\nFn, which is a π-system. It remains to invoke the π-λ systems lemma,",
    "Lemma 1.12, to conclude that\n\nn⩾1\n\nQ(A) = E[Z1A], A ∈ F ,\n\ni.e. Z =\n\ndQ\ndP .\n\nStep 2: please see Williams’ book.\n\nFinally, note that the results shown above allow us to make precise sense of the pathway suggested in\nthe Deep Dive at the end of Section 4.2. Specifically, in our definition on a martingale, Definition 8.1, we\ncould have said that (Xn)n⩾0 is a martingale if it is an adapted integrable process such that E[Xn+11A] =\nE[Xn1A] for all A ∈ Fn, and all n ⩾ 0. We could have thus ignored the issue of existence of a conditional\nexpectation and side-step it by imposing the defining relationships directly as part of the martingale property.\nIt is easy to verify this for simple martingales, say for the simple symmetric random walk, so the notion of a\nmartingale would be seen to be non-empty, and we could carry out and establish all of the results on martingale\nconvergence, including Theorem 8.32. This, in turn, allowed us to show Radon-Nikodym Theorem above,\nwhich in turn allowed us to derive an easy proof for existence of the conditional expectation. This provides\na nice probabilistic self-contained pathway which side-steps any discussion of L2 projections.\nIt is nice\nto observe this, but it is not necessarily advantageous from a pedagogical point of view – the intuition of\nconditional expectation as an L2-projection/approximation is a very useful one to have!\n\nPage 99\n\n\fIndex\n\nL1-bounded, 85\nL2-martingale, 78\nLp inequality, 82\nλ -system, 14\nπ-λ systems lemma, 15\nπ-system, 14\nσ -algebra, 12\nBorel, 13\ngenerated by a collection of sets, 13\ngenerated by a random variable, 16\ngenerated by a rv, 16\nindependent, 31\nproduct, 13, 16\ntail, 34\nσ -algebra at τ, 71\n\nabsolute continuity, 22\nadapted process, 70\nalgebra, 12\nalmost sure convergence, 48\nalmost surely, 22\nangle bracket process, 78\n\nbackwards martingale, 89\nballot problem, 91\nBC1, 35\nBC2, 36\nBinomial Model, 11\nBorel σ -algebra, 13\nBorel–Cantelli Lemma, 35\nbounded in Lp, 85\nbranching process, 6, 85\n\nChebyshev’s inequality, 51\ncompensation, 77\ncompleteness, 55\nconditional convergence theorems, 63\nconditional expectation, 7, 61\ndefining relation, 61\nexistence, 61, 97\nmean square approximation, 66\ntaking out what is known, 64\ntower property, 64\nuniqueness, 61\n\nconditional Jensen’s inequality, 64\nconditional probability, 24\n\nconvergence\n\nalmost surely, 48, 50\nin Lp, 48\nin distribution, 49\nin probability, 48, 50\n\nconvex function, 52\ncovariance, 66\n\ndefining relation (conditional expectation), 61\ndiscrete measure theory, 23\ndiscrete stochastic integral, 76\ndistribution\n\njoint, 28\n\ndistribution function, 26\nDominated Convergence Theorem, 42\nDoob’s backward martingale, 91\nDoob’s decomposition theorem, 77\nDoob’s forward convergence theorem, 85\n\nexchangeable random variables, 90\nexpectation, 43\nextinction probability, 7\n\nFatou’s Lemma, 35, 41\nreverse, 35, 41\n\nfiltered probability space, 70\nfiltration, 70\n\nnatural, 70\nFubini’s Theorem, 46\n\nGalton–Watson branching process, 6, 85\n\nH¨older’s inequality, 54\nhitting time, 71\n\ni.i.d., 34\nindependence, 31\nintegrable function, 39\n\nJensen’s inequality, 52\n\nconditional version, 64\n\nKolmogorov 0-1 Law, 34\n\nlaw of the iterated logarithm, 48\nLebesgue–Stieltjes measure, 26\nliminf, 17\n\n100\n\n\fJan Obł´oj\n\nsets, 35\n\nlimsup, 17\n\nsets, 35\n\nMarkov’s inequality, 51\nmartingale, 8, 73\n\nbackwards, 89\nstopped, 78\n\nmartingale convergence theorem, 85\nmartingale difference, 74\nmartingale transform, 76\nmaximal inequality, 81\nmeasurable function, 15\nmeasurable space, 12\nmeasure, 21\n\nabsolutely continuous, 22\nequivalent, 22\nimage, 27, 42\nmarginal, 28\nmonotone convergence properties, 21\nproduct, 29\npushforward, 27\nrestriction of, 24\nsum of, 24\nmeasure space, 21\nMinkowski’s inequality, 54\nmodes of convergence, 48\nMonotone Convergence Theorem, 39\n\nnatural filtration, 70\nnull set, 22\n\nOption pricing, 11\nOptional Stopping Theorem, 79\noptional time, 70\northogonal, 67\northogonal projection, 67\n\npredictable process, 76\nprobability kernel, 46\nprocess\n\nstopped, 72\n\nproduct σ -algebra, 13, 16\nproduct measure, 29\nproduct space, 13, 16\nprojection\n\northogonal, 67\n\nRadon-Nikodym Theorem, 40, 97\n\nMT 2024, B8.1: Probability, Measure and Martingales\n\nrandom variable, 15\nindependent, 33\nreverse Fatou’s Lemma, 41\n\nscalar product, 67\nScheff´e’s Lemma, 42\nset function, 21\nsimple function, 17\n\ncanonical form, 17\n\nstopped process, 72\nstopping time, 70\n\nfirst hitting, 71\n\nStrong law of large numbers, 90\nsubmartingale, 73\nsupermartingale, 73\n\ntail σ -algebra, 34\ntaking out what is known, 64\ntower property, 7, 64\n\nuncorrelated, 67\nuniform integrability, 55\n\nand L1 convergence, 57\nuniqueness of extension, 23\nupcrossing, 83\nupcrossing lemma, 83\n\nVitali’s Convergence Theorem, 57\n\nPage 101"
]